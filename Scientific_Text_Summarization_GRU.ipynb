{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRPciZ1jatuQ",
        "outputId": "cc8977c7-cca4-4257-91c8-c6f2061b8b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "MkSGRGyNeCK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "VZSyswqzLoUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = pd.read_csv('train.csv')\n",
        "dataset_test = pd.read_csv('test.csv')\n",
        "dataset_val = pd.read_csv('val.csv')"
      ],
      "metadata": {
        "id": "6peBtjZ0ecMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tF4F3oxBefD2",
        "outputId": "b1fe5840-4991-46b8-961b-3a746f8aaf2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 source  \\\n",
              "0     ['Due to the success of deep learning to solvi...   \n",
              "1     ['The backpropagation (BP) algorithm is often ...   \n",
              "2     ['We introduce the 2-simplicial Transformer, a...   \n",
              "3     ['We present Tensor-Train RNN (TT-RNN), a nove...   \n",
              "4     ['Recent efforts on combining deep models with...   \n",
              "...                                                 ...   \n",
              "1987  ['Semi-supervised learning, i.e. jointly learn...   \n",
              "1988  ['Model-free reinforcement learning (RL) has b...   \n",
              "1989  ['We introduce a neural architecture to perfor...   \n",
              "1990  ['Machine learned large-scale retrieval system...   \n",
              "1991  ['The ability to autonomously explore and navi...   \n",
              "\n",
              "                 source_labels  \\\n",
              "0           [0, 0, 0, 0, 1, 0]   \n",
              "1     [0, 0, 0, 1, 0, 0, 0, 0]   \n",
              "2                       [0, 1]   \n",
              "3           [0, 0, 0, 1, 0, 0]   \n",
              "4        [0, 1, 0, 0, 0, 0, 0]   \n",
              "...                        ...   \n",
              "1987     [0, 0, 0, 1, 0, 0, 0]   \n",
              "1988     [0, 0, 0, 0, 1, 0, 0]   \n",
              "1989              [1, 0, 0, 0]   \n",
              "1990        [0, 0, 0, 1, 0, 0]   \n",
              "1991     [0, 0, 0, 0, 0, 0, 1]   \n",
              "\n",
              "                                           rouge_scores    paper_id  \\\n",
              "0     [0.30188679695129395, 0.3720930218696594, 0.60...   SysEexbRb   \n",
              "1     [0.0, 0.0, 0.1304347813129425, 0.1428571343421...  SygvZ209F7   \n",
              "2              [0.3333333432674408, 0.8888888955116272]  rkecJ6VFvr   \n",
              "3     [0.06666666269302368, 0.06451612710952759, 0.0...   HJJ0w--0W   \n",
              "4     [0.277777761220932, 0.5714285373687744, 0.0952...   HyH9lbZAW   \n",
              "...                                                 ...         ...   \n",
              "1987  [0.07999999821186066, 0.11538460850715637, 0.1...  rJel41BtDH   \n",
              "1988  [0.09302324801683426, 0.08695651590824127, 0.0...   Skw0n-W0Z   \n",
              "1989  [0.46666666865348816, 0.0714285671710968, 0.0,...  rJgFtkhEtr   \n",
              "1990  [0.277777761220932, 0.0, 0.2857142686843872, 0...  SJxPVcSonN   \n",
              "1991  [0.10169491171836853, 0.0937499925494194, 0.16...  BJgMFxrYPB   \n",
              "\n",
              "                                                 target  \n",
              "0     ['We provide necessary and sufficient analytic...  \n",
              "1     ['Biologically plausible learning algorithms, ...  \n",
              "2     ['We introduce the 2-simplicial Transformer an...  \n",
              "3     ['Accurate forecasting over very long time hor...  \n",
              "4     ['We propose a variational message-passing alg...  \n",
              "...                                                 ...  \n",
              "1987  ['Pseudo-labeling has shown to be a weak alter...  \n",
              "1988  ['We show that a special goal-condition value ...  \n",
              "1989  ['A novel neural architecture for efficient am...  \n",
              "1990  ['We propose a novel two-tower shared-bottom m...  \n",
              "1991  ['We address the task of autonomous exploratio...  \n",
              "\n",
              "[1992 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e28d8ce-b18b-4ba0-8d05-7b5fd50fd8c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Due to the success of deep learning to solvi...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0.30188679695129395, 0.3720930218696594, 0.60...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>['We provide necessary and sufficient analytic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['The backpropagation (BP) algorithm is often ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[0.0, 0.0, 0.1304347813129425, 0.1428571343421...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>['Biologically plausible learning algorithms, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['We introduce the 2-simplicial Transformer, a...</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[0.3333333432674408, 0.8888888955116272]</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>['We introduce the 2-simplicial Transformer an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['We present Tensor-Train RNN (TT-RNN), a nove...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.06666666269302368, 0.06451612710952759, 0.0...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>['Accurate forecasting over very long time hor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Recent efforts on combining deep models with...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.5714285373687744, 0.0952...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>['We propose a variational message-passing alg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>['Semi-supervised learning, i.e. jointly learn...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[0.07999999821186066, 0.11538460850715637, 0.1...</td>\n",
              "      <td>rJel41BtDH</td>\n",
              "      <td>['Pseudo-labeling has shown to be a weak alter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>['Model-free reinforcement learning (RL) has b...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.09302324801683426, 0.08695651590824127, 0.0...</td>\n",
              "      <td>Skw0n-W0Z</td>\n",
              "      <td>['We show that a special goal-condition value ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>['We introduce a neural architecture to perfor...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0.46666666865348816, 0.0714285671710968, 0.0,...</td>\n",
              "      <td>rJgFtkhEtr</td>\n",
              "      <td>['A novel neural architecture for efficient am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>['Machine learned large-scale retrieval system...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.0, 0.2857142686843872, 0...</td>\n",
              "      <td>SJxPVcSonN</td>\n",
              "      <td>['We propose a novel two-tower shared-bottom m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>['The ability to autonomously explore and navi...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[0.10169491171836853, 0.0937499925494194, 0.16...</td>\n",
              "      <td>BJgMFxrYPB</td>\n",
              "      <td>['We address the task of autonomous exploratio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1992 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e28d8ce-b18b-4ba0-8d05-7b5fd50fd8c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e28d8ce-b18b-4ba0-8d05-7b5fd50fd8c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e28d8ce-b18b-4ba0-8d05-7b5fd50fd8c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcp0h5dDbdA2",
        "outputId": "03b70c89-ae74-40e7-91c1-82f487a9448d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "source           0\n",
              "source_labels    0\n",
              "rouge_scores     0\n",
              "paper_id         0\n",
              "target           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train['source'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_train['source']]\n",
        "dataset_train['target'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_train['target']]\n",
        "dataset_train['source'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_train['source']]\n",
        "dataset_train['target'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_train['target']]"
      ],
      "metadata": {
        "id": "OGKH4eDktRLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train['source'] = [i.lower() for i in dataset_train['source']]\n",
        "dataset_train['target'] = [i.lower() for i in dataset_train['target']]"
      ],
      "metadata": {
        "id": "2MRSwrVdmcgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sX4CgzSftmVN",
        "outputId": "e128cb97-e9b2-4be7-ee19-d2951433f339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 source  \\\n",
              "0     due to the success of deep learning to solving...   \n",
              "1     the backpropagation (bp) algorithm is often th...   \n",
              "2     we introduce the 2-simplicial transformer, an ...   \n",
              "3     we present tensor-train rnn (tt-rnn), a novel ...   \n",
              "4     recent efforts on combining deep models with p...   \n",
              "...                                                 ...   \n",
              "1987  semi-supervised learning, i.e. jointly learnin...   \n",
              "1988  model-free reinforcement learning (rl) has bee...   \n",
              "1989  we introduce a neural architecture to perform ...   \n",
              "1990  machine learned large-scale retrieval systems ...   \n",
              "1991  the ability to autonomously explore and naviga...   \n",
              "\n",
              "                 source_labels  \\\n",
              "0           [0, 0, 0, 0, 1, 0]   \n",
              "1     [0, 0, 0, 1, 0, 0, 0, 0]   \n",
              "2                       [0, 1]   \n",
              "3           [0, 0, 0, 1, 0, 0]   \n",
              "4        [0, 1, 0, 0, 0, 0, 0]   \n",
              "...                        ...   \n",
              "1987     [0, 0, 0, 1, 0, 0, 0]   \n",
              "1988     [0, 0, 0, 0, 1, 0, 0]   \n",
              "1989              [1, 0, 0, 0]   \n",
              "1990        [0, 0, 0, 1, 0, 0]   \n",
              "1991     [0, 0, 0, 0, 0, 0, 1]   \n",
              "\n",
              "                                           rouge_scores    paper_id  \\\n",
              "0     [0.30188679695129395, 0.3720930218696594, 0.60...   SysEexbRb   \n",
              "1     [0.0, 0.0, 0.1304347813129425, 0.1428571343421...  SygvZ209F7   \n",
              "2              [0.3333333432674408, 0.8888888955116272]  rkecJ6VFvr   \n",
              "3     [0.06666666269302368, 0.06451612710952759, 0.0...   HJJ0w--0W   \n",
              "4     [0.277777761220932, 0.5714285373687744, 0.0952...   HyH9lbZAW   \n",
              "...                                                 ...         ...   \n",
              "1987  [0.07999999821186066, 0.11538460850715637, 0.1...  rJel41BtDH   \n",
              "1988  [0.09302324801683426, 0.08695651590824127, 0.0...   Skw0n-W0Z   \n",
              "1989  [0.46666666865348816, 0.0714285671710968, 0.0,...  rJgFtkhEtr   \n",
              "1990  [0.277777761220932, 0.0, 0.2857142686843872, 0...  SJxPVcSonN   \n",
              "1991  [0.10169491171836853, 0.0937499925494194, 0.16...  BJgMFxrYPB   \n",
              "\n",
              "                                                 target  \n",
              "0     we provide necessary and sufficient analytical...  \n",
              "1     biologically plausible learning algorithms, pa...  \n",
              "2     we introduce the 2-simplicial transformer and ...  \n",
              "3     accurate forecasting over very long time horiz...  \n",
              "4     we propose a variational message-passing algor...  \n",
              "...                                                 ...  \n",
              "1987  pseudo-labeling has shown to be a weak alterna...  \n",
              "1988  we show that a special goal-condition value fu...  \n",
              "1989  a novel neural architecture for efficient amor...  \n",
              "1990  we propose a novel two-tower shared-bottom mod...  \n",
              "1991  we address the task of autonomous exploration ...  \n",
              "\n",
              "[1992 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-370e3f92-da54-4fc3-9c59-2eb672c113a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>due to the success of deep learning to solving...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0.30188679695129395, 0.3720930218696594, 0.60...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>we provide necessary and sufficient analytical...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the backpropagation (bp) algorithm is often th...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[0.0, 0.0, 0.1304347813129425, 0.1428571343421...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>biologically plausible learning algorithms, pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>we introduce the 2-simplicial transformer, an ...</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[0.3333333432674408, 0.8888888955116272]</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>we introduce the 2-simplicial transformer and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we present tensor-train rnn (tt-rnn), a novel ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.06666666269302368, 0.06451612710952759, 0.0...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>accurate forecasting over very long time horiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recent efforts on combining deep models with p...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.5714285373687744, 0.0952...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>we propose a variational message-passing algor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>semi-supervised learning, i.e. jointly learnin...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[0.07999999821186066, 0.11538460850715637, 0.1...</td>\n",
              "      <td>rJel41BtDH</td>\n",
              "      <td>pseudo-labeling has shown to be a weak alterna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>model-free reinforcement learning (rl) has bee...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.09302324801683426, 0.08695651590824127, 0.0...</td>\n",
              "      <td>Skw0n-W0Z</td>\n",
              "      <td>we show that a special goal-condition value fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>we introduce a neural architecture to perform ...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0.46666666865348816, 0.0714285671710968, 0.0,...</td>\n",
              "      <td>rJgFtkhEtr</td>\n",
              "      <td>a novel neural architecture for efficient amor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>machine learned large-scale retrieval systems ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.0, 0.2857142686843872, 0...</td>\n",
              "      <td>SJxPVcSonN</td>\n",
              "      <td>we propose a novel two-tower shared-bottom mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>the ability to autonomously explore and naviga...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[0.10169491171836853, 0.0937499925494194, 0.16...</td>\n",
              "      <td>BJgMFxrYPB</td>\n",
              "      <td>we address the task of autonomous exploration ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1992 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-370e3f92-da54-4fc3-9c59-2eb672c113a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-370e3f92-da54-4fc3-9c59-2eb672c113a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-370e3f92-da54-4fc3-9c59-2eb672c113a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def cleaning(text,num):\n",
        "  str = text.lower()\n",
        "  str = re.sub('\"','', str)\n",
        "\n",
        "  str = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in str.split(\" \")])\n",
        "  str = re.sub(r\"'s\\b\",\"\",str)\n",
        "  str = re.sub(\"[^a-zA-Z]\", \" \", str)\n",
        "  str = re.sub('[m]{2,}', 'mm', str)\n",
        "  if(num==0):\n",
        "    str = re.sub(r'\\.',' . ',str)\n",
        "  if(num==0):\n",
        "      tokens = [w for w in str.split() if not w in stop_words]\n",
        "\n",
        "  else:\n",
        "      tokens=str.split()\n",
        "  long_words=[]\n",
        "  for i in tokens:\n",
        "      if len(i)>1:                                                 #removing short words\n",
        "          long_words.append(i)\n",
        "  return (\" \".join(long_words)).strip()"
      ],
      "metadata": {
        "id": "wJCJid3Ztto_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "FOkSEryKyJgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_source = []\n",
        "for t in dataset_train['source']:\n",
        "    clean_source.append(cleaning(t,0))\n",
        "\n",
        "clean_target = []\n",
        "for t in dataset_train['target']:\n",
        "    clean_target.append(cleaning(t,0))"
      ],
      "metadata": {
        "id": "4mM7YJB0yM15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train['source'] = clean_source\n",
        "dataset_train['target'] = clean_target\n",
        "\n",
        "dataset_train.replace('', np.nan, inplace=True)\n",
        "dataset_train.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "P7LuuEkqyQ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "coEH1oAEyQy-",
        "outputId": "24decbc2-749f-4384-f6f2-acb028a4581a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 source  \\\n",
              "0     due success deep learning solving variety chal...   \n",
              "1     backpropagation bp algorithm often thought bio...   \n",
              "2     introduce simplicial transformer extension tra...   \n",
              "3     present tensor train rnn tt rnn novel family n...   \n",
              "4     recent efforts combining deep models probabili...   \n",
              "...                                                 ...   \n",
              "1987  semi supervised learning jointly learning labe...   \n",
              "1988  model free reinforcement learning rl proven po...   \n",
              "1989  introduce neural architecture perform amortize...   \n",
              "1990  machine learned large scale retrieval systems ...   \n",
              "1991  ability autonomously explore navigate physical...   \n",
              "\n",
              "                 source_labels  \\\n",
              "0           [0, 0, 0, 0, 1, 0]   \n",
              "1     [0, 0, 0, 1, 0, 0, 0, 0]   \n",
              "2                       [0, 1]   \n",
              "3           [0, 0, 0, 1, 0, 0]   \n",
              "4        [0, 1, 0, 0, 0, 0, 0]   \n",
              "...                        ...   \n",
              "1987     [0, 0, 0, 1, 0, 0, 0]   \n",
              "1988     [0, 0, 0, 0, 1, 0, 0]   \n",
              "1989              [1, 0, 0, 0]   \n",
              "1990        [0, 0, 0, 1, 0, 0]   \n",
              "1991     [0, 0, 0, 0, 0, 0, 1]   \n",
              "\n",
              "                                           rouge_scores    paper_id  \\\n",
              "0     [0.30188679695129395, 0.3720930218696594, 0.60...   SysEexbRb   \n",
              "1     [0.0, 0.0, 0.1304347813129425, 0.1428571343421...  SygvZ209F7   \n",
              "2              [0.3333333432674408, 0.8888888955116272]  rkecJ6VFvr   \n",
              "3     [0.06666666269302368, 0.06451612710952759, 0.0...   HJJ0w--0W   \n",
              "4     [0.277777761220932, 0.5714285373687744, 0.0952...   HyH9lbZAW   \n",
              "...                                                 ...         ...   \n",
              "1987  [0.07999999821186066, 0.11538460850715637, 0.1...  rJel41BtDH   \n",
              "1988  [0.09302324801683426, 0.08695651590824127, 0.0...   Skw0n-W0Z   \n",
              "1989  [0.46666666865348816, 0.0714285671710968, 0.0,...  rJgFtkhEtr   \n",
              "1990  [0.277777761220932, 0.0, 0.2857142686843872, 0...  SJxPVcSonN   \n",
              "1991  [0.10169491171836853, 0.0937499925494194, 0.16...  BJgMFxrYPB   \n",
              "\n",
              "                                                 target  \n",
              "0     provide necessary sufficient analytical forms ...  \n",
              "1     biologically plausible learning algorithms par...  \n",
              "2     introduce simplicial transformer show architec...  \n",
              "3     accurate forecasting long time horizons using ...  \n",
              "4     propose variational message passing algorithm ...  \n",
              "...                                                 ...  \n",
              "1987  pseudo labeling shown weak alternative semi su...  \n",
              "1988  show special goal condition value function tra...  \n",
              "1989  novel neural architecture efficient amortized ...  \n",
              "1990  propose novel two tower shared bottom model ar...  \n",
              "1991  address task autonomous exploration navigation...  \n",
              "\n",
              "[1992 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7335ca2f-0592-4aa4-a9a4-faa81cc61f7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>source_labels</th>\n",
              "      <th>rouge_scores</th>\n",
              "      <th>paper_id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>due success deep learning solving variety chal...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[0.30188679695129395, 0.3720930218696594, 0.60...</td>\n",
              "      <td>SysEexbRb</td>\n",
              "      <td>provide necessary sufficient analytical forms ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>backpropagation bp algorithm often thought bio...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[0.0, 0.0, 0.1304347813129425, 0.1428571343421...</td>\n",
              "      <td>SygvZ209F7</td>\n",
              "      <td>biologically plausible learning algorithms par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>introduce simplicial transformer extension tra...</td>\n",
              "      <td>[0, 1]</td>\n",
              "      <td>[0.3333333432674408, 0.8888888955116272]</td>\n",
              "      <td>rkecJ6VFvr</td>\n",
              "      <td>introduce simplicial transformer show architec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>present tensor train rnn tt rnn novel family n...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.06666666269302368, 0.06451612710952759, 0.0...</td>\n",
              "      <td>HJJ0w--0W</td>\n",
              "      <td>accurate forecasting long time horizons using ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recent efforts combining deep models probabili...</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.5714285373687744, 0.0952...</td>\n",
              "      <td>HyH9lbZAW</td>\n",
              "      <td>propose variational message passing algorithm ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>semi supervised learning jointly learning labe...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[0.07999999821186066, 0.11538460850715637, 0.1...</td>\n",
              "      <td>rJel41BtDH</td>\n",
              "      <td>pseudo labeling shown weak alternative semi su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>model free reinforcement learning rl proven po...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.09302324801683426, 0.08695651590824127, 0.0...</td>\n",
              "      <td>Skw0n-W0Z</td>\n",
              "      <td>show special goal condition value function tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>introduce neural architecture perform amortize...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0.46666666865348816, 0.0714285671710968, 0.0,...</td>\n",
              "      <td>rJgFtkhEtr</td>\n",
              "      <td>novel neural architecture efficient amortized ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>machine learned large scale retrieval systems ...</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0.277777761220932, 0.0, 0.2857142686843872, 0...</td>\n",
              "      <td>SJxPVcSonN</td>\n",
              "      <td>propose novel two tower shared bottom model ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>ability autonomously explore navigate physical...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 1]</td>\n",
              "      <td>[0.10169491171836853, 0.0937499925494194, 0.16...</td>\n",
              "      <td>BJgMFxrYPB</td>\n",
              "      <td>address task autonomous exploration navigation...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1992 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7335ca2f-0592-4aa4-a9a4-faa81cc61f7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7335ca2f-0592-4aa4-a9a4-faa81cc61f7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7335ca2f-0592-4aa4-a9a4-faa81cc61f7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_word_count = []\n",
        "target_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in dataset_train['source']:\n",
        "      temp=i.split()\n",
        "      source_word_count.append(len(temp))\n",
        "\n",
        "for j in dataset_train['target']:\n",
        "  temp1=j.split()\n",
        "  target_word_count.append(len(temp1))"
      ],
      "metadata": {
        "id": "LMX6AIiB1KfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(source_word_count)\n",
        "plt.title('Source Distribution')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Number of Source Sentences')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(target_word_count)\n",
        "plt.title('Target Distribution')\n",
        "plt.xlabel('Word Count')\n",
        "plt.ylabel('Number of Target Sentence')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "bznzRhgK3abl",
        "outputId": "22748c6b-30f6-4039-f529-ac0743559915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test['source'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_test['source']]\n",
        "dataset_test['target'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_test['target']]\n",
        "dataset_test['source'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_test['source']]\n",
        "dataset_test['target'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_test['target']]\n",
        "dataset_val['source'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_val['source']]\n",
        "dataset_val['target'] = [i.lstrip('[').rstrip(']\\n ') for i in dataset_val['target']]\n",
        "dataset_val['source'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_val['source']]\n",
        "dataset_val['target'] = [i.lstrip('\\'').rstrip('\\'') for i in dataset_val['target']]"
      ],
      "metadata": {
        "id": "wfYnQp5-6y_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test['source'] = [i.lower() for i in dataset_test['source']]\n",
        "dataset_test['target'] = [i.lower() for i in dataset_test['target']]\n",
        "dataset_val['source'] = [i.lower() for i in dataset_val['source']]\n",
        "dataset_val['target'] = [i.lower() for i in dataset_val['target']]"
      ],
      "metadata": {
        "id": "RKGILcY67cIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_source_test = []\n",
        "for t in dataset_test['source']:\n",
        "    clean_source_test.append(cleaning(t,0))\n",
        "\n",
        "clean_target_test = []\n",
        "for t in dataset_test['target']:\n",
        "    clean_target_test.append(cleaning(t,0))\n",
        "\n",
        "clean_source_val = []\n",
        "for t in dataset_val['source']:\n",
        "    clean_source_val.append(cleaning(t,0))\n",
        "\n",
        "clean_target_val = []\n",
        "for t in dataset_val['target']:\n",
        "    clean_target_val.append(cleaning(t,0))"
      ],
      "metadata": {
        "id": "viOe_eaH7gHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test['source'] = clean_source_test\n",
        "dataset_test['target'] = clean_target_test\n",
        "dataset_val['source'] = clean_source_val\n",
        "dataset_val['target'] = clean_target_val\n",
        "\n",
        "dataset_test.replace('', np.nan, inplace=True)\n",
        "dataset_test.dropna(axis=0,inplace=True)\n",
        "dataset_val.replace('', np.nan, inplace=True)\n",
        "dataset_val.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "lCSwH3Fp7i3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = dataset_train['source'], dataset_train['target']\n",
        "X_test, Y_test = dataset_test['source'], dataset_test['target']"
      ],
      "metadata": {
        "id": "CvbZcxF_FBeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train))\n",
        "print(len(Y_train))\n",
        "print(len(X_test))\n",
        "print(len(Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHcDCJTlGEsu",
        "outputId": "95f44401-03ef-4d93-e779-bdb8ab685832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1992\n",
            "1992\n",
            "618\n",
            "618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n"
      ],
      "metadata": {
        "id": "z7wmrW6ALqV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(text, summary, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    text=np.array(text)\n",
        "    summary=np.array(summary)\n",
        "    pairs = [[text[i],summary[i]] for i in range(len(text))]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(summary)\n",
        "        output_lang = Lang(text)\n",
        "    else:\n",
        "        input_lang = Lang(text)\n",
        "        output_lang = Lang(summary)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "laIuDMHZLu9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name,\"--------------------\", input_lang.n_words)\n",
        "    #print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n"
      ],
      "metadata": {
        "id": "8PH-nIEkLwVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, pairs = prepareData(X_train, Y_train , False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8BwnaAELyxZ",
        "outputId": "47132ebd-21a5-43c5-d842-a72b5bc00864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 1992 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "['due success deep learning solving variety challenging machine learning tasks rising interest understanding loss functions training neural networks theoretical aspect particularly properties critical points landscape around importance determine convergence performance optimization algorithms paper provide necessary sufficient characterization analytical forms critical points well global minimizers square loss functions linear neural networks show analytical forms critical points characterize values corresponding loss functions well necessary sufficient conditions achieve global minimum furthermore exploit analytical forms critical points characterize landscape properties loss functions linear neural networks shallow relu networks one particular conclusion loss function linear networks spurious local minimum loss function one hidden layer nonlinear networks relu activation function local minimum global minimum'\n",
            " 'backpropagation bp algorithm often thought biologically implausible brain one main reasons bp requires symmetric weight matrices feedforward feedback pathways address weight transport problem grossberg two biologically plausible algorithms proposed liao et al lillicrap et al relax bp weight symmetry requirements demonstrate comparable learning capabilities bp small datasets however recent study bartunov et al finds although feedback alignment fa variants target propagation tp perform well mnist cifar perform significantly worse bp imagenet additionally evaluate sign symmetry ss algorithm liao et al differs bp fa feedback feedforward weights share magnitudes share signs examined performance sign symmetry feedback alignment imagenet ms coco datasets using different network architectures resnet alexnet imagenet retinanet ms coco surprisingly networks trained sign symmetry attain classification performance approaching bp trained networks results complement study bartunov et al establish new benchmark future biologically plausible learning algorithms difficult datasets complex architectures'\n",
            " 'introduce simplicial transformer extension transformer includes form higher dimensional attention generalising dot product attention uses attention update entity representations tensor products value vectors show architecture useful inductive bias logical reasoning context deep reinforcement learning'\n",
            " ...\n",
            " 'introduce neural architecture perform amortized approximate bayesian inference latent random permutations two sets objects method involves approximating permanents matrices pairwise probabilities using recent ideas functions defined sets sampled permutation comes probability estimate quantity unavailable mcmc approaches illustrate method sets points mnist images'\n",
            " 'machine learned large scale retrieval systems require large amount training data representing query item relevance however collecting users explicit feedback costly paper propose leverage user logs implicit feedback auxiliary objectives improve relevance modeling retrieval systems specifically adopt two tower neural net architecture model query item relevance given collaborative content information introducing auxiliary tasks trained much richer implicit user feedback data improve quality resolution learned representations queries items applying learned representations industrial retrieval system delivered significant improvements'\n",
            " 'ability autonomously explore navigate physical space fundamental requirement virtually mobile autonomous agent household robotic vacuums autonomous vehicles traditional slam based approaches exploration navigation largely focus leveraging scene geometry fail model dynamic objects agents semantic constraints wet floors doorways learning based rl agents attractive alternative incorporate semantic geometric information notoriously sample inefficient difficult generalize novel settings difficult interpret paper combine best worlds modular approach em learns spatial representation scene trained effective coupled traditional geometric planners specifically design agent learns predict spatial affordance map elucidates parts scene navigable active self supervised experience gathering contrast simulation environments assume static world evaluate approach vizdoom simulator using large scale randomly generated maps containing variety dynamic actors hazards show learned affordance maps used augment traditional approaches exploration navigation providing significant improvements performance'] -------------------- 11477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK5oesvKREBt",
        "outputId": "53db3cd1-a2cf-4130-ea0a-ad8f82831929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['backpropagation bp algorithm often thought biologically implausible brain one main reasons bp requires symmetric weight matrices feedforward feedback pathways address weight transport problem grossberg two biologically plausible algorithms proposed liao et al lillicrap et al relax bp weight symmetry requirements demonstrate comparable learning capabilities bp small datasets however recent study bartunov et al finds although feedback alignment fa variants target propagation tp perform well mnist cifar perform significantly worse bp imagenet additionally evaluate sign symmetry ss algorithm liao et al differs bp fa feedback feedforward weights share magnitudes share signs examined performance sign symmetry feedback alignment imagenet ms coco datasets using different network architectures resnet alexnet imagenet retinanet ms coco surprisingly networks trained sign symmetry attain classification performance approaching bp trained networks results complement study bartunov et al establish new benchmark future biologically plausible learning algorithms difficult datasets complex architectures',\n",
              " 'biologically plausible learning algorithms particularly sign symmetry work well imagenet']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "metadata": {
        "id": "nd8NFp3FONF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "zrts86z2NZ2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "metadata": {
        "id": "TafB8WADNduD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "HKNaFpEeNfkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 257"
      ],
      "metadata": {
        "id": "rk2y-fViZWbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "POZIhZ-fDOC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "    #print('bbbbbbb-->>> input length', input_length)\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        #print(\"priting before error\")\n",
        "        #print(encoder_output.size())\n",
        "        #print(encoder_outputs.size())\n",
        "        temp = encoder_output[0, 0]\n",
        "        #print(temp)\n",
        "        encoder_outputs[ei] = temp\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    #use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    #Without teacher forcing: use its own predictions as the next input\n",
        "\n",
        "    #print('aaaaa-->>>')\n",
        "\n",
        "    for di in range(target_length):\n",
        "      decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "      decoder_input, decoder_hidden, encoder_outputs)\n",
        "      topv, topi = decoder_output.topk(1)\n",
        "\n",
        "      decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "      loss += criterion(decoder_output, target_tensor[di])\n",
        "\n",
        "      if decoder_input.item() == EOS_token:\n",
        "             break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "eRt_M9KNNutz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "l_8OiFmkN1rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "NLyTlybCN3cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    print(\"Training....\")\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        if iter% 1000 == 0:\n",
        "            print(iter,\"/\",n_iters + 1)\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        input_length = input_tensor.size(0)\n",
        "        if(input_length > 150):\n",
        "          #print(input_length)\n",
        "          continue\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "bF0DS9RMN55n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        #print('cccccc->>>>')\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "_3VnxUVBN8bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=5):\n",
        "    text=list()\n",
        "    headline=list()\n",
        "    pred_headline=list()\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "\n",
        "        if(len(pair[0].split())>=150):\n",
        "          continue\n",
        "        else:\n",
        "          if(i%1000==0):\n",
        "            print(i*100/n,\"% complete\")\n",
        "\n",
        "          #print('>', pair[0])\n",
        "          text.append(pair[0])\n",
        "          #print('=', pair[1])\n",
        "          headline.append(pair[1])\n",
        "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "          output_sentence = ' '.join(output_words)\n",
        "          pred_headline.append(output_sentence)\n",
        "          #print('<', output_sentence)\n",
        "          #print('')\n",
        "    return(text,headline,pred_headline)"
      ],
      "metadata": {
        "id": "x1GvKUl3OEWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 300\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 150000, print_every=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2MjJ_hUOHAK",
        "outputId": "d8491217-b4cb-4a64-ced5-2a675dd2f3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training....\n",
            "1000 / 150001\n",
            "1m 24s (- 209m 24s) (1000 0%) 3.1793\n",
            "2000 / 150001\n",
            "2m 33s (- 188m 54s) (2000 1%) 3.3808\n",
            "3000 / 150001\n",
            "3m 45s (- 183m 57s) (3000 2%) 3.5918\n",
            "4000 / 150001\n",
            "4m 57s (- 181m 3s) (4000 2%) 3.5703\n",
            "5000 / 150001\n",
            "6m 7s (- 177m 44s) (5000 3%) 3.3091\n",
            "6000 / 150001\n",
            "7m 18s (- 175m 28s) (6000 4%) 3.3046\n",
            "7000 / 150001\n",
            "8m 29s (- 173m 35s) (7000 4%) 3.4620\n",
            "8000 / 150001\n",
            "9m 42s (- 172m 17s) (8000 5%) 3.4083\n",
            "9000 / 150001\n",
            "10m 54s (- 170m 49s) (9000 6%) 3.3354\n",
            "10000 / 150001\n",
            "12m 8s (- 169m 56s) (10000 6%) 3.2677\n",
            "11000 / 150001\n",
            "12000 / 150001\n",
            "14m 36s (- 168m 1s) (12000 8%) 6.3670\n",
            "13000 / 150001\n",
            "14000 / 150001\n",
            "17m 6s (- 166m 13s) (14000 9%) 5.7971\n",
            "15000 / 150001\n",
            "18m 23s (- 165m 30s) (15000 10%) 2.8228\n",
            "16000 / 150001\n",
            "19m 39s (- 164m 39s) (16000 10%) 2.7073\n",
            "17000 / 150001\n",
            "20m 56s (- 163m 50s) (17000 11%) 2.6440\n",
            "18000 / 150001\n",
            "22m 13s (- 163m 0s) (18000 12%) 2.5205\n",
            "19000 / 150001\n",
            "23m 32s (- 162m 18s) (19000 12%) 2.4343\n",
            "20000 / 150001\n",
            "24m 49s (- 161m 24s) (20000 13%) 2.3129\n",
            "21000 / 150001\n",
            "26m 6s (- 160m 19s) (21000 14%) 2.3041\n",
            "22000 / 150001\n",
            "27m 22s (- 159m 13s) (22000 14%) 2.1668\n",
            "23000 / 150001\n",
            "28m 39s (- 158m 14s) (23000 15%) 2.1436\n",
            "24000 / 150001\n",
            "29m 58s (- 157m 20s) (24000 16%) 2.1050\n",
            "25000 / 150001\n",
            "31m 17s (- 156m 25s) (25000 16%) 2.0233\n",
            "26000 / 150001\n",
            "32m 37s (- 155m 34s) (26000 17%) 1.9789\n",
            "27000 / 150001\n",
            "33m 57s (- 154m 41s) (27000 18%) 1.8906\n",
            "28000 / 150001\n",
            "35m 18s (- 153m 50s) (28000 18%) 1.7944\n",
            "29000 / 150001\n",
            "36m 36s (- 152m 44s) (29000 19%) 1.7314\n",
            "30000 / 150001\n",
            "37m 52s (- 151m 29s) (30000 20%) 1.6708\n",
            "31000 / 150001\n",
            "39m 10s (- 150m 21s) (31000 20%) 1.6953\n",
            "32000 / 150001\n",
            "40m 27s (- 149m 12s) (32000 21%) 1.7130\n",
            "33000 / 150001\n",
            "41m 45s (- 148m 2s) (33000 22%) 1.5940\n",
            "34000 / 150001\n",
            "43m 2s (- 146m 49s) (34000 22%) 1.5854\n",
            "35000 / 150001\n",
            "44m 20s (- 145m 42s) (35000 23%) 1.5443\n",
            "36000 / 150001\n",
            "45m 37s (- 144m 29s) (36000 24%) 1.4755\n",
            "37000 / 150001\n",
            "46m 55s (- 143m 19s) (37000 24%) 1.4569\n",
            "38000 / 150001\n",
            "48m 11s (- 142m 3s) (38000 25%) 1.4320\n",
            "39000 / 150001\n",
            "49m 31s (- 140m 57s) (39000 26%) 1.4446\n",
            "40000 / 150001\n",
            "50m 47s (- 139m 41s) (40000 26%) 1.3795\n",
            "41000 / 150001\n",
            "52m 7s (- 138m 33s) (41000 27%) 1.3515\n",
            "42000 / 150001\n",
            "53m 26s (- 137m 24s) (42000 28%) 1.3010\n",
            "43000 / 150001\n",
            "54m 47s (- 136m 19s) (43000 28%) 1.3464\n",
            "44000 / 150001\n",
            "56m 6s (- 135m 10s) (44000 29%) 1.2805\n",
            "45000 / 150001\n",
            "57m 28s (- 134m 7s) (45000 30%) 1.2996\n",
            "46000 / 150001\n",
            "58m 50s (- 133m 2s) (46000 30%) 1.2504\n",
            "47000 / 150001\n",
            "48000 / 150001\n",
            "61m 28s (- 130m 38s) (48000 32%) 2.4961\n",
            "49000 / 150001\n",
            "62m 48s (- 129m 28s) (49000 32%) 1.2501\n",
            "50000 / 150001\n",
            "64m 7s (- 128m 15s) (50000 33%) 1.1838\n",
            "51000 / 150001\n",
            "65m 24s (- 126m 57s) (51000 34%) 1.1332\n",
            "52000 / 150001\n",
            "66m 43s (- 125m 45s) (52000 34%) 1.1656\n",
            "53000 / 150001\n",
            "68m 2s (- 124m 31s) (53000 35%) 1.1866\n",
            "54000 / 150001\n",
            "69m 23s (- 123m 20s) (54000 36%) 1.1598\n",
            "55000 / 150001\n",
            "70m 42s (- 122m 7s) (55000 36%) 1.1786\n",
            "56000 / 150001\n",
            "72m 1s (- 120m 53s) (56000 37%) 1.1513\n",
            "57000 / 150001\n",
            "73m 20s (- 119m 39s) (57000 38%) 1.1278\n",
            "58000 / 150001\n",
            "74m 40s (- 118m 27s) (58000 38%) 1.1088\n",
            "59000 / 150001\n",
            "76m 0s (- 117m 14s) (59000 39%) 1.1089\n",
            "60000 / 150001\n",
            "77m 21s (- 116m 1s) (60000 40%) 1.1326\n",
            "61000 / 150001\n",
            "78m 43s (- 114m 52s) (61000 40%) 1.1370\n",
            "62000 / 150001\n",
            "80m 5s (- 113m 41s) (62000 41%) 1.1387\n",
            "63000 / 150001\n",
            "81m 26s (- 112m 27s) (63000 42%) 1.1184\n",
            "64000 / 150001\n",
            "82m 43s (- 111m 10s) (64000 42%) 1.0744\n",
            "65000 / 150001\n",
            "84m 2s (- 109m 53s) (65000 43%) 1.1589\n",
            "66000 / 150001\n",
            "85m 23s (- 108m 40s) (66000 44%) 1.1618\n",
            "67000 / 150001\n",
            "86m 41s (- 107m 23s) (67000 44%) 1.1314\n",
            "68000 / 150001\n",
            "88m 2s (- 106m 10s) (68000 45%) 1.1967\n",
            "69000 / 150001\n",
            "89m 25s (- 104m 58s) (69000 46%) 1.2510\n",
            "70000 / 150001\n",
            "90m 44s (- 103m 42s) (70000 46%) 1.2196\n",
            "71000 / 150001\n",
            "92m 5s (- 102m 28s) (71000 47%) 1.2457\n",
            "72000 / 150001\n",
            "93m 26s (- 101m 14s) (72000 48%) 1.2007\n",
            "73000 / 150001\n",
            "94m 47s (- 99m 59s) (73000 48%) 1.2742\n",
            "74000 / 150001\n",
            "96m 8s (- 98m 44s) (74000 49%) 1.2849\n",
            "75000 / 150001\n",
            "97m 26s (- 97m 26s) (75000 50%) 1.3091\n",
            "76000 / 150001\n",
            "98m 46s (- 96m 10s) (76000 50%) 1.3293\n",
            "77000 / 150001\n",
            "100m 7s (- 94m 55s) (77000 51%) 1.4211\n",
            "78000 / 150001\n",
            "79000 / 150001\n",
            "102m 47s (- 92m 23s) (79000 52%) 2.8315\n",
            "80000 / 150001\n",
            "104m 8s (- 91m 7s) (80000 53%) 1.4812\n",
            "81000 / 150001\n",
            "105m 29s (- 89m 52s) (81000 54%) 1.5386\n",
            "82000 / 150001\n",
            "106m 49s (- 88m 35s) (82000 54%) 1.5184\n",
            "83000 / 150001\n",
            "108m 9s (- 87m 18s) (83000 55%) 1.5920\n",
            "84000 / 150001\n",
            "109m 29s (- 86m 1s) (84000 56%) 1.6597\n",
            "85000 / 150001\n",
            "110m 49s (- 84m 45s) (85000 56%) 1.7340\n",
            "86000 / 150001\n",
            "112m 9s (- 83m 28s) (86000 57%) 1.9575\n",
            "87000 / 150001\n",
            "113m 29s (- 82m 11s) (87000 57%) 1.9351\n",
            "88000 / 150001\n",
            "114m 50s (- 80m 54s) (88000 58%) 2.0137\n",
            "89000 / 150001\n",
            "116m 7s (- 79m 35s) (89000 59%) 2.0789\n",
            "90000 / 150001\n",
            "117m 27s (- 78m 18s) (90000 60%) 2.1193\n",
            "91000 / 150001\n",
            "118m 45s (- 76m 59s) (91000 60%) 2.2327\n",
            "92000 / 150001\n",
            "120m 4s (- 75m 41s) (92000 61%) 2.2655\n",
            "93000 / 150001\n",
            "94000 / 150001\n",
            "122m 37s (- 73m 3s) (94000 62%) 6.7196\n",
            "95000 / 150001\n",
            "123m 49s (- 71m 41s) (95000 63%) 5.1621\n",
            "96000 / 150001\n",
            "125m 1s (- 70m 19s) (96000 64%) 4.7001\n",
            "97000 / 150001\n",
            "126m 13s (- 68m 58s) (97000 64%) 4.5255\n",
            "98000 / 150001\n",
            "127m 24s (- 67m 36s) (98000 65%) 4.1951\n",
            "99000 / 150001\n",
            "100000 / 150001\n",
            "129m 47s (- 64m 53s) (100000 66%) 7.8975\n",
            "101000 / 150001\n",
            "130m 59s (- 63m 33s) (101000 67%) 3.6364\n",
            "102000 / 150001\n",
            "132m 10s (- 62m 12s) (102000 68%) 3.6004\n",
            "103000 / 150001\n",
            "133m 20s (- 60m 50s) (103000 68%) 3.1719\n",
            "104000 / 150001\n",
            "134m 32s (- 59m 30s) (104000 69%) 3.4493\n",
            "105000 / 150001\n",
            "135m 44s (- 58m 10s) (105000 70%) 3.4083\n",
            "106000 / 150001\n",
            "136m 55s (- 56m 50s) (106000 70%) 3.3128\n",
            "107000 / 150001\n",
            "108000 / 150001\n",
            "139m 15s (- 54m 9s) (108000 72%) 6.4119\n",
            "109000 / 150001\n",
            "140m 27s (- 52m 50s) (109000 72%) 3.2889\n",
            "110000 / 150001\n",
            "111000 / 150001\n",
            "142m 49s (- 50m 10s) (111000 74%) 6.3502\n",
            "112000 / 150001\n",
            "144m 0s (- 48m 51s) (112000 74%) 3.1329\n",
            "113000 / 150001\n",
            "145m 12s (- 47m 32s) (113000 75%) 3.2579\n",
            "114000 / 150001\n",
            "146m 24s (- 46m 13s) (114000 76%) 3.1163\n",
            "115000 / 150001\n",
            "147m 34s (- 44m 54s) (115000 76%) 3.0515\n",
            "116000 / 150001\n",
            "148m 44s (- 43m 35s) (116000 77%) 2.9390\n",
            "117000 / 150001\n",
            "149m 55s (- 42m 17s) (117000 78%) 2.9914\n",
            "118000 / 150001\n",
            "119000 / 150001\n",
            "152m 18s (- 39m 40s) (119000 79%) 5.9927\n",
            "120000 / 150001\n",
            "153m 30s (- 38m 22s) (120000 80%) 2.9774\n",
            "121000 / 150001\n",
            "154m 43s (- 37m 5s) (121000 80%) 2.9174\n",
            "122000 / 150001\n",
            "155m 55s (- 35m 47s) (122000 81%) 2.9427\n",
            "123000 / 150001\n",
            "157m 6s (- 34m 29s) (123000 82%) 2.9708\n",
            "124000 / 150001\n",
            "158m 18s (- 33m 11s) (124000 82%) 2.9842\n",
            "125000 / 150001\n",
            "159m 31s (- 31m 54s) (125000 83%) 2.9962\n",
            "126000 / 150001\n",
            "160m 43s (- 30m 36s) (126000 84%) 2.9674\n",
            "127000 / 150001\n",
            "161m 55s (- 29m 19s) (127000 84%) 2.8957\n",
            "128000 / 150001\n",
            "163m 9s (- 28m 2s) (128000 85%) 3.1366\n",
            "129000 / 150001\n",
            "164m 21s (- 26m 45s) (129000 86%) 2.9316\n",
            "130000 / 150001\n",
            "165m 34s (- 25m 28s) (130000 86%) 2.9072\n",
            "131000 / 150001\n",
            "166m 46s (- 24m 11s) (131000 87%) 2.9272\n",
            "132000 / 150001\n",
            "167m 59s (- 22m 54s) (132000 88%) 2.9382\n",
            "133000 / 150001\n",
            "134000 / 150001\n",
            "170m 24s (- 20m 20s) (134000 89%) 5.9123\n",
            "135000 / 150001\n",
            "171m 37s (- 19m 4s) (135000 90%) 2.9512\n",
            "136000 / 150001\n",
            "172m 51s (- 17m 47s) (136000 90%) 3.0449\n",
            "137000 / 150001\n",
            "174m 2s (- 16m 30s) (137000 91%) 2.9174\n",
            "138000 / 150001\n",
            "175m 14s (- 15m 14s) (138000 92%) 2.9305\n",
            "139000 / 150001\n",
            "176m 27s (- 13m 57s) (139000 92%) 2.9216\n",
            "140000 / 150001\n",
            "177m 39s (- 12m 41s) (140000 93%) 2.9337\n",
            "141000 / 150001\n",
            "178m 51s (- 11m 24s) (141000 94%) 2.9419\n",
            "142000 / 150001\n",
            "180m 3s (- 10m 8s) (142000 94%) 2.9481\n",
            "143000 / 150001\n",
            "181m 15s (- 8m 52s) (143000 95%) 2.9600\n",
            "144000 / 150001\n",
            "182m 28s (- 7m 36s) (144000 96%) 2.9085\n",
            "145000 / 150001\n",
            "183m 40s (- 6m 20s) (145000 96%) 2.8057\n",
            "146000 / 150001\n",
            "184m 53s (- 5m 3s) (146000 97%) 3.0465\n",
            "147000 / 150001\n",
            "186m 5s (- 3m 47s) (147000 98%) 2.8889\n",
            "148000 / 150001\n",
            "187m 17s (- 2m 31s) (148000 98%) 2.9545\n",
            "149000 / 150001\n",
            "188m 29s (- 1m 15s) (149000 99%) 2.9536\n",
            "150000 / 150001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text,headline,pred_headline=evaluateRandomly(encoder1, attn_decoder1,15000)\n",
        "\n",
        "pred_df_LSTM=pd.DataFrame()\n",
        "\n",
        "pred_df_LSTM['text']=text\n",
        "pred_df_LSTM['headline']=headline\n",
        "pred_df_LSTM['pred_headline']=pred_headline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSUEobbkOe84",
        "outputId": "e2648fd4-5ddf-46e9-b784-4e812738920b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 % complete\n",
            "6.666666666666667 % complete\n",
            "13.333333333333334 % complete\n",
            "20.0 % complete\n",
            "26.666666666666668 % complete\n",
            "33.333333333333336 % complete\n",
            "40.0 % complete\n",
            "46.666666666666664 % complete\n",
            "53.333333333333336 % complete\n",
            "60.0 % complete\n",
            "66.66666666666667 % complete\n",
            "80.0 % complete\n",
            "86.66666666666667 % complete\n",
            "93.33333333333333 % complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10,110):\n",
        "  print(\"original Summary>>>\",pred_df_LSTM.iloc[i]['headline'])\n",
        "  print(\"Predicted Summary>>>\",pred_df_LSTM.iloc[i]['pred_headline'])\n",
        "  print('-----------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPEzaY87fLSu",
        "outputId": "a2f9951c-3b76-4fb5-f112-6e303f4acea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original Summary>>> introduce php model hierarchical representation neural programs algorithm learning phps mixture strong weak supervision\n",
            "Predicted Summary>>> introduce php model hierarchical representation neural programs algorithm learning phps mixture strong weak supervision \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> loopgan extends cycle length cyclegan enable unaligned sequential transformation two time steps\n",
            "Predicted Summary>>> loopgan extends cycle length cyclegan enable unaligned sequential transformation two time steps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present kg reinforcement learning agent builds dynamic knowledge graph exploring generates natural language using template based action space outperforming current agents wide set text based games\n",
            "Predicted Summary>>> present kg reinforcement learning agent builds dynamic knowledge graph exploring generates natural language using template based action space outperforming current agents agents wide set based text based games games games \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> semi supervised cross lingual document classification\n",
            "Predicted Summary>>> semi supervised cross lingual document classification \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> robust bayesian estimation via maximum mean discrepancy\n",
            "Predicted Summary>>> robust bayesian estimation via maximum mean discrepancy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel tensor based method graph convolutional networks dynamic graphs\n",
            "Predicted Summary>>> propose novel tensor based method graph convolutional networks dynamic graphs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed architecture solve morphological agreement task\n",
            "Predicted Summary>>> proposed architecture solve morphological agreement task \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> information theoretical approach unsupervised learning unsupervised learning hybrid discrete continuous representations\n",
            "Predicted Summary>>> information theoretical approach unsupervised learning unsupervised learning hybrid discrete continuous representations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> state art model based global reasoning image super resolution\n",
            "Predicted Summary>>> state art model based global reasoning image super resolution \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> self ensembling based algorithm visual domain adaptation state art results visda image classification domain adaptation challenge\n",
            "Predicted Summary>>> self ensembling based algorithm visual domain adaptation state art results visda image classification domain adaptation challenge \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> recent distribution detection method helps measure confidence rnn predictions nlp tasks\n",
            "Predicted Summary>>> recent distribution detection method helps measure confidence rnn predictions nlp tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using deep neural networks clever algorithms capture human mental visual concepts\n",
            "Predicted Summary>>> using deep neural networks clever algorithms capture human mental visual concepts \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose cr nas reallocate engaged computation resources different resolution spatial position\n",
            "Predicted Summary>>> propose cr nas reallocate engaged computation resources different resolution spatial position \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose stochastic differentiable forward dynamics predictor able sample multiple physically plausible trajectories initial input state show used train model free policies efficiently\n",
            "Predicted Summary>>> propose stochastic differentiable forward dynamics predictor able sample multiple physically plausible trajectories initial input state show used train model free policies efficiently \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative adversarial network training continual learning problem\n",
            "Predicted Summary>>> generative adversarial network training continual learning problem \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method based adversarial training strategy learn discriminative features unbiased invariant confounder incorporating loss function encourages vanished correlation bias learned features\n",
            "Predicted Summary>>> propose method based adversarial training strategy learn discriminative features unbiased invariant confounder incorporating loss function encourages vanished correlation bias learned features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> specific gradient based meta learning algorithm maml equivalent inference procedure hierarchical bayesian model use connection improve maml via methods approximate inference curvature estimation\n",
            "Predicted Summary>>> specific gradient based meta learning algorithm maml equivalent inference procedure hierarchical bayesian model use connection improve maml via methods approximate inference curvature estimation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose message passing encoder decode networks fast accurate way modelling label dependencies multi label classification\n",
            "Predicted Summary>>> propose message passing encoder decode networks fast accurate way modelling label dependencies multi label classification \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel method create dense descriptors time time embeddings make simple models understand temporal structures\n",
            "Predicted Summary>>> novel method create dense descriptors time time embeddings make simple models understand temporal structures \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compute saliency using strong generative model efficiently marginalize plausible alternative inputs revealing concentrated pixel areas preserve label information\n",
            "Predicted Summary>>> compute saliency using strong generative model efficiently marginalize plausible alternative inputs revealing concentrated pixel areas preserve label information \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> logit regularization methods help explain improve state art adversarial defenses\n",
            "Predicted Summary>>> logit regularization methods help explain improve state art adversarial defenses \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present meta critic auxiliary critic module policy actor critic methods meta learned online single task learning\n",
            "Predicted Summary>>> present meta critic auxiliary critic module policy actor critic methods meta learned online single task learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning hierarchical policies unsegmented demonstrations using directed information\n",
            "Predicted Summary>>> learning hierarchical policies unsegmented demonstrations using directed information \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel high performing architecture end end named entity recognition relation extraction fast train\n",
            "Predicted Summary>>> novel high performing architecture end end named entity recognition relation extraction fast train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep semantic framework textual search engine document retrieval\n",
            "Predicted Summary>>> deep semantic framework textual search engine document retrieval \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose primal dual subgradient method training gans method effectively alleviates mode collapse\n",
            "Predicted Summary>>> propose primal dual subgradient method training gans method effectively alleviates mode collapse \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new variational hashing based collaborative filtering approach optimized novel self mask variant hamming distance outperforms state art ndcg\n",
            "Predicted Summary>>> propose new variational hashing based collaborative filtering approach optimized novel self mask variant hamming distance outperforms state art ndcg \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present state space lstm models combination state space models lstms propose inference algorithm based sequential monte carlo\n",
            "Predicted Summary>>> present state space lstm models combination state space models lstms propose inference algorithm based sequential monte carlo \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> higher momentum parameter beta helps escaping saddle points faster\n",
            "Predicted Summary>>> higher momentum parameter beta helps escaping saddle points faster \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel framework evaluate interpretability neural network\n",
            "Predicted Summary>>> propose novel framework evaluate interpretability neural network \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> systematically examines well explain hidden features deep network terms logical rules\n",
            "Predicted Summary>>> systematically examines well explain hidden features deep network terms logical rules \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide pac bayes based generalization guarantee uncompressed deterministic deep networks generalizing noise resilience network training data test data\n",
            "Predicted Summary>>> provide pac bayes based generalization guarantee uncompressed deterministic deep networks generalizing noise resilience network training data test data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reactor combines multiple algorithmic architectural contributions produce agent higher sample efficiency prioritized dueling dqn giving better run time performance\n",
            "Predicted Summary>>> reactor combines multiple algorithmic architectural contributions produce agent higher sample efficiency prioritized dueling dqn giving better run time performance performance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn task agnostic world graph abstraction environment show using structured exploration significantly accelerate downstream task specific rl\n",
            "Predicted Summary>>> learn task agnostic world graph abstraction environment show using structured exploration significantly accelerate downstream task specific rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proteins amino acid sequences machine learning deep learning recurrent neural network rnn long short term memory lstm gated recurrent unit gru deep neural networks\n",
            "Predicted Summary>>> proteins amino acid sequences machine learning deep learning recurrent neural network rnn long short term memory lstm gated recurrent unit gru neural networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non asymptotic analysis sgd svrg showing strength algorithm convergence speed computational cost parametrized parametrized settings\n",
            "Predicted Summary>>> non asymptotic analysis sgd svrg showing strength algorithm convergence speed computational cost parametrized parametrized settings \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel state space time series model capability capture structure change points anomaly points better forecasting performance exist change points anomalies time series\n",
            "Predicted Summary>>> propose novel state space time series model capability capture structure change points anomaly points better forecasting performance change change points time series \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> incorporating model latent variables encode future content improves long term prediction accuracy critical better planning model based rl\n",
            "Predicted Summary>>> incorporating model latent variables encode future content improves long term prediction accuracy critical better planning model based rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advocate random features theory biological neural networks focusing sparsely connected networks\n",
            "Predicted Summary>>> advocate random features theory biological neural networks focusing sparsely connected networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train variational models quantized networks computational determinism enables using cross platform data compression\n",
            "Predicted Summary>>> train variational models quantized networks computational determinism enables using cross platform data data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> evaluate new ml learning algorithms biological plausibility abstract based mathematical operations needed\n",
            "Predicted Summary>>> evaluate new ml learning algorithms biological plausibility abstract based mathematical operations needed \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> effectively choose initialization activation function deep neural networks\n",
            "Predicted Summary>>> effectively choose initialization activation function deep neural networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper solves lexical ambiguity problem caused homonym neural translation bert\n",
            "Predicted Summary>>> paper solves lexical ambiguity problem caused homonym neural translation bert \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions\n",
            "Predicted Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces new dynamic feature representation approach provide efficient way inference deep neural networks\n",
            "Predicted Summary>>> paper introduces new dynamic feature representation approach provide efficient way inference deep neural networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed architecture solve morphological agreement task\n",
            "Predicted Summary>>> proposed architecture solve morphological agreement task \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose train invertible neural network class perform class class continual learning\n",
            "Predicted Summary>>> propose train invertible neural network class perform class class continual learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> achieving strong adversarial robustness comparable adversarial training without training adversarial examples\n",
            "Predicted Summary>>> achieving strong adversarial robustness comparable adversarial training without training adversarial examples \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactively generating image incrementally growing scene graphs multiple steps using gans preserving contents image generated previous steps\n",
            "Predicted Summary>>> interactively generating image incrementally growing scene graphs multiple steps using gans preserving contents image generated previous steps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generating text using sentence embeddings skip thought vectors help generative adversarial networks\n",
            "Predicted Summary>>> generating text using sentence embeddings skip thought vectors help generative adversarial networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes method forcing cnns leverage spatial attention learning object centric representations perform better various respects\n",
            "Predicted Summary>>> paper proposes method forcing cnns leverage spatial attention learning object centric representations perform better various respects \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper describes strategic intrinsically motivated learning algorithm tackles learning complex motor policies\n",
            "Predicted Summary>>> paper describes strategic intrinsically motivated learning algorithm tackles learning complex motor policies \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative memory model combines slow learning neural networks fast adapting linear gaussian model memory\n",
            "Predicted Summary>>> generative memory model combines slow learning neural networks fast adapting linear gaussian model memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop new deep generative model semi supervised learning propose new max min cross entropy training cnns\n",
            "Predicted Summary>>> develop new deep generative model semi supervised learning propose new max min cross entropy training cnns \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper provides game based abstraction scheme compute provably sound policies pomdps\n",
            "Predicted Summary>>> paper provides game based abstraction scheme compute provably sound policies pomdps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents theoretical framework models data distribution explicitly deep locally connected relu network\n",
            "Predicted Summary>>> paper presents theoretical framework models data distribution explicitly deep locally connected relu network \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> side tuning adapts pre trained network training lightweight side network fused unchanged pre trained network using simple additive process\n",
            "Predicted Summary>>> side tuning adapts pre trained network training lightweight side network fused unchanged pre trained network using simple additive process \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aiming boosting existing pruning mimic method\n",
            "Predicted Summary>>> work aiming boosting existing pruning mimic method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual connections really perform iterative inference\n",
            "Predicted Summary>>> residual connections really perform iterative inference \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use reinforcement learning query reformulation two tasks surprisingly find training multiple agents diversity reformulations important specialisation\n",
            "Predicted Summary>>> use reinforcement learning query reformulation two tasks surprisingly find training multiple agents diversity reformulations important specialisation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> accelerating cnn training pipeline accelerators stale weights\n",
            "Predicted Summary>>> accelerating cnn training pipeline accelerators stale weights \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze recurrent networks trained sentiment classification find exhibit approximate line attractor dynamics solving task\n",
            "Predicted Summary>>> analyze recurrent networks trained sentiment classification find exhibit approximate line attractor dynamics solving task \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate variant variational autoencoders superstructure discrete latent variables top latent features\n",
            "Predicted Summary>>> investigate variant variational autoencoders superstructure discrete latent variables top latent features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> add method deep learning detect outliers prediction time\n",
            "Predicted Summary>>> add method deep learning detect outliers prediction time \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order learning proposed applied regression problems computer vision \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable differentiable neural module implements reasoning symbolic kbs\n",
            "Predicted Summary>>> scalable differentiable neural module implements reasoning symbolic kbs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hebbian plastic weights behave compressed episodic memory storage neural networks combination task specific synaptic consolidation improve ability alleviate catastrophic forgetting continual learning\n",
            "Predicted Summary>>> hebbian plastic weights behave compressed episodic memory storage neural networks combination task specific synaptic consolidation improve ability ability catastrophic forgetting catastrophic forgetting forgetting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> nuqsgd closes gap theoretical guarantees qsgd empirical performance qsgdinf\n",
            "Predicted Summary>>> nuqsgd closes gap theoretical guarantees qsgd empirical performance qsgdinf \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unify extended kalman filter ekf state space approach power expectation propagation pep solving intractable moment matching integrals pep via linearisation leads globally iterated extension ekf\n",
            "Predicted Summary>>> unify extended kalman filter ekf state space approach power expectation propagation pep solving intractable moment matching integrals pep via leads leads globally \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper provides game based abstraction scheme compute provably sound policies pomdps\n",
            "Predicted Summary>>> paper provides game based abstraction scheme compute provably sound policies pomdps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> finding shed lights preventing cancer progression\n",
            "Predicted Summary>>> finding shed lights preventing cancer progression \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> obfuscate code using seq seq networks execute using obfuscated code key pair\n",
            "Predicted Summary>>> obfuscate code using seq seq networks execute using obfuscated code key pair \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem alleviating instability issue gan training procedure via new architecture design theoretical guarantees\n",
            "Predicted Summary>>> study problem alleviating instability issue gan training procedure via new architecture design theoretical guarantees \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose noisy dr ssc noisy dimension reduction sparse subspace clustering efficiently partition noisy data accordance underlying subspace structure\n",
            "Predicted Summary>>> propose noisy dr ssc noisy dimension reduction sparse subspace clustering efficiently partition noisy data accordance underlying subspace structure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce online explanation consider cognitive requirement human understanding generated explanation agent\n",
            "Predicted Summary>>> introduce online explanation consider cognitive requirement human understanding generated explanation agent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed method end end neural svm optimized shot learning\n",
            "Predicted Summary>>> proposed method end end neural svm optimized shot learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> high object detection accuracy obtained training domain specific compact models training short\n",
            "Predicted Summary>>> high object detection accuracy obtained training domain specific compact models training short short \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable differentiable neural module implements reasoning symbolic kbs\n",
            "Predicted Summary>>> scalable differentiable neural module implements reasoning symbolic kbs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reinforcement learning adaptive sampling optimized compilation deep neural networks\n",
            "Predicted Summary>>> reinforcement learning adaptive sampling optimized compilation deep neural networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose reinforcement learning based variable swapping recomputation algorithm reduce memory cost\n",
            "Predicted Summary>>> propose reinforcement learning based variable swapping recomputation algorithm reduce memory cost \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unify support estimation family adversarial imitation learning algorithms support guided adversarial imitation learning robust stable imitation learning framework\n",
            "Predicted Summary>>> unify support estimation family adversarial imitation learning algorithms support guided adversarial imitation learning robust stable imitation learning framework \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> create unbiased estimator log probability latent variable models extending models larger scope applications\n",
            "Predicted Summary>>> create unbiased estimator log probability latent variable models extending models larger scope applications \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining auxiliary adversarial training interrogate help physical understanding\n",
            "Predicted Summary>>> combining auxiliary adversarial training interrogate help physical understanding \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel combination adversarial training provable defenses produces model state art accuracy certified robustness cifar\n",
            "Predicted Summary>>> propose novel combination adversarial training provable defenses produces model state art accuracy certified robustness cifar \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method extracts uncertainties features layer dnns combines detecting ood samples solving classification tasks\n",
            "Predicted Summary>>> propose method extracts uncertainties features layer dnns combines detecting ood samples solving classification tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deploy text classification sentiment analysis applications english chinese mw cnn accelerator chip device application scenarios\n",
            "Predicted Summary>>> deploy text classification sentiment analysis applications english chinese mw cnn accelerator chip device application scenarios \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> marthe new method fit task specific learning rate schedules perspective hyperparameter optimization\n",
            "Predicted Summary>>> marthe new method fit task specific learning rate schedules perspective hyperparameter optimization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first propose fully automated target directed atomic importance estimator based graph neural networks new concept reverse self attention\n",
            "Predicted Summary>>> first propose fully automated target directed atomic importance estimator based graph neural networks new concept reverse self attention \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improving deep transfer learning regularization using attention based feature maps\n",
            "Predicted Summary>>> improving deep transfer learning regularization using attention based feature maps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> variable capacity input word embeddings sota wikitext billion word benchmarks\n",
            "Predicted Summary>>> variable capacity input word embeddings sota wikitext billion word benchmarks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method unsupervised representation learning graphs relying maximizing mutual information local global representations graph state art results competitive supervised learning\n",
            "Predicted Summary>>> new method unsupervised representation learning graphs relying maximizing mutual information local global representations graph state art results competitive supervised learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient dictionary learning minimization via novel analysis non convex non smooth geometry\n",
            "Predicted Summary>>> efficient dictionary learning minimization via novel analysis non convex non smooth geometry \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze gradient propagation deep rnns analysis propose new multi layer deep rnn\n",
            "Predicted Summary>>> analyze gradient propagation deep rnns analysis propose new multi layer deep rnn \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop method stable offline reinforcement learning logged data key regularize rl policy towards learned advantage weighted model data\n",
            "Predicted Summary>>> develop method stable offline reinforcement learning logged data key regularize rl policy towards learned advantage model model data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents gan based framework learning distribution high dimensional incomplete data\n",
            "Predicted Summary>>> paper presents gan based framework learning distribution high dimensional incomplete data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> synthesize complex extended human motions using auto conditioned lstm network\n",
            "Predicted Summary>>> synthesize complex extended human motions using auto conditioned lstm network \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> automated mice training neuroscience online iterative latent strategy inference behavior prediction\n",
            "Predicted Summary>>> automated mice training neuroscience online iterative latent strategy inference behavior prediction \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> data dependent factorization dimensions multi scale architecture based contribution total log likelihood\n",
            "Predicted Summary>>> data dependent factorization dimensions multi scale architecture based contribution total log likelihood \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present method interpreting black box models using instance wise backward selection identify minimal subsets features alone suffice justify particular decision made model\n",
            "Predicted Summary>>> present method interpreting black box models using instance wise backward selection identify minimal subsets features alone suffice justify particular decision particular model \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> comparative study generative models continual learning scenarios\n",
            "Predicted Summary>>> comparative study generative models continual learning scenarios \n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,1500):\n",
        "  print(\"original Summary>>>\",pred_df_LSTM.iloc[i]['headline'])\n",
        "  print(\"Predicted Summary>>>\",pred_df_LSTM.iloc[i]['pred_headline'])\n",
        "  print('-----------------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1JmSEK99S8q",
        "outputId": "ecb2cf74-79e7-4f84-9031-22b0dd3132ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original Summary>>> developed search framework consistency penalty mitigate delusional bias\n",
            "Predicted Summary>>> developed rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose cnn neuron ranking two different methods show consistency producing result allows interpret network deems important compress network keeping relevant nodes\n",
            "Predicted Summary>>> propose rl variational semantic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach curriculum learning incrementally learning labels adaptively smoothing labels mis classified samples boost average performance decreases standard deviation\n",
            "Predicted Summary>>> propose active incrementally \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel bit format eliminates need loss scaling stochastic rounding low precision techniques\n",
            "Predicted Summary>>> propose eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> end end trainable model compression method optimizing accuracy jointly expected model size\n",
            "Predicted Summary>>> propose trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate recurrent neural network successfully learns task combining long term memory sequential recall\n",
            "Predicted Summary>>> introduce proposes generation generation generation entropy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> image classification via iteratively querying reference image candidate class rnn use cnn compare input image\n",
            "Predicted Summary>>> propose top sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> models representation learning dynamic graphs latent hidden process bridging two observed processes topological evolution interactions dynamic graphs\n",
            "Predicted Summary>>> propose first training used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new auto encoder based wasserstein distance improves sampling properties vae\n",
            "Predicted Summary>>> propose proposes modules modules modules modules modules modules modules modules modules modules modules modules modules \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approach perform htn planning using external procedures evaluate predicates runtime semantic attachments\n",
            "Predicted Summary>>> propose htn external htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train generative model shapes natural images fully unsupervised way\n",
            "Predicted Summary>>> train tasks shapes tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> revisit idea master slave architecture multi agent deep reinforcement learning outperforms state arts\n",
            "Predicted Summary>>> propose proposes asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> stable domain adversarial training approach robust comprehensive domain adaptation\n",
            "Predicted Summary>>> propose domain architecture \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tailoring predictions sequence models ldss rnns via explicit latent code\n",
            "Predicted Summary>>> propose emerge represent end represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> embed sg mcmc samplers inside variational approximation\n",
            "Predicted Summary>>> embed sg sg sg sg sg sg sg sg sg sg sg sg sg sg sg sg sg \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> rederive wide class inference procedures global information bottleneck objective\n",
            "Predicted Summary>>> rederive gan transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel multi task framework learns table detection semantic component recognition cell type classification spreadsheet tables promising results\n",
            "Predicted Summary>>> propose new transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> loopgan extends cycle length cyclegan enable unaligned sequential transformation two time steps\n",
            "Predicted Summary>>> loopgan extends used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose soft actor critic policy actor critic deep rl algorithm based maximum entropy reinforcement learning framework\n",
            "Predicted Summary>>> actor actor entropy actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new class optimizers accelerated non convex optimization via nonlinear gradient transformation\n",
            "Predicted Summary>>> propose class class class class class class class accelerated class \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual connections really perform iterative inference\n",
            "Predicted Summary>>> propose problem learning training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural sparsity enhanced topic model based vae\n",
            "Predicted Summary>>> propose sparsity enhanced image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient dictionary learning minimization via novel analysis non convex non smooth geometry\n",
            "Predicted Summary>>> paper novel minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel multi task framework learns table detection semantic component recognition cell type classification spreadsheet tables promising results\n",
            "Predicted Summary>>> propose new transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show make predictions using deep networks without training deep networks\n",
            "Predicted Summary>>> paper analyze set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show multi channel attention weight contains semantic feature solve natural language inference task\n",
            "Predicted Summary>>> propose bayesian channel \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first posing solving sample efficiency optimization problem non parameterized policy space solving supervised regression problem find parameterized policy near optimal non parameterized policy\n",
            "Predicted Summary>>> use proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show successfully perform backdoor attacks without changing training labels\n",
            "Predicted Summary>>> propose new backdoor \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theory algorithmic framework prediction distributional shift including causal effect estimation domain adaptation\n",
            "Predicted Summary>>> propose algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new sparse structured attention mechanism tvmax promotes sparsity encourages weight related adjacent locations\n",
            "Predicted Summary>>> propose matrix matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel cluster based algorithm curriculum learning proposed solve robust training generative models\n",
            "Predicted Summary>>> propose theoretical policy policy learning algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose use lattices represent objects prove fundamental result train networks use\n",
            "Predicted Summary>>> propose describes search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used networks used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used search used together \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduced novel gradient estimator using stein method compared methods learning implicit models approximate inference image generation\n",
            "Predicted Summary>>> scalable proposes used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theory algorithmic framework prediction distributional shift including causal effect estimation domain adaptation\n",
            "Predicted Summary>>> propose algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic algorithmic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop simple general approach avoiding interference gradients different tasks improves performance multi task learning supervised reinforcement learning domains\n",
            "Predicted Summary>>> develop novel method general \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose self adversarial learning sal paradigm improves generator self play fashion improving gans performance text generation\n",
            "Predicted Summary>>> propose self gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose physics aware difference graph networks designed effectively learn spatial differences modeling sparsely observed dynamics\n",
            "Predicted Summary>>> train novel variational difference \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose distill large dataset small set synthetic data train networks close original performance\n",
            "Predicted Summary>>> distill distill set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper finds algorithms directly use lossless compressed representations deep feedforward networks perform inference without full decompression\n",
            "Predicted Summary>>> propose new tasks trainable tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> recurrent neural networks cybersecurity use cases\n",
            "Predicted Summary>>> propose architecture cybersecurity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce diagnostic task variation shot learning introduce dataset\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes even \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use deep reinforcement learning design physical attributes robot jointly control policy\n",
            "Predicted Summary>>> analyze reinforcement represent represent represent represent represent represent represent represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop new deep generative model semi supervised learning propose new max min cross entropy training cnns\n",
            "Predicted Summary>>> propose optimization networks method space method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposing novel method based guided attention enforce sparisty deep neural networks\n",
            "Predicted Summary>>> proposing proposing optimal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present local ensembles method detecting extrapolation trained models approximates variance ensemble using local second order information\n",
            "Predicted Summary>>> extend novel method variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> side tuning adapts pre trained network training lightweight side network fused unchanged pre trained network using simple additive process\n",
            "Predicted Summary>>> side trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> insight reason adversarial vulnerability effective defense method adversarial attacks\n",
            "Predicted Summary>>> insight reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> preserving differential privacy adversarial learning provable robustness adversarial examples\n",
            "Predicted Summary>>> paper could networks could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could could\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactive technique improve brushing dense trajectory datasets taking account shape brush\n",
            "Predicted Summary>>> interactive brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present end end design methodology efficient deep learning deployment\n",
            "Predicted Summary>>> build proposes design \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new deep architecture varpsom extension time series data vartpsom achieve superior clustering performance compared current deep clustering methods static temporal data\n",
            "Predicted Summary>>> propose method adversarial static \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve saturating activations sigmoid tanh htanh etc binarized neural network bias initialization\n",
            "Predicted Summary>>> paper saturating activations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose meta learning framework learns transferable policy weak supervision solve synthesis tasks different logical specifications grammars\n",
            "Predicted Summary>>> work gradient \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new sparse structured attention mechanism tvmax promotes sparsity encourages weight related adjacent locations\n",
            "Predicted Summary>>> propose matrix used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> primal dual graph neural network model semi supervised learning\n",
            "Predicted Summary>>> propose primal transfer bias \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> systematically examines well explain hidden features deep network terms logical rules\n",
            "Predicted Summary>>> systematically examines search examines well well \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show possibility pruning find small sub network significantly higher convergence rate full model\n",
            "Predicted Summary>>> propose method gan transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarially regularized autoencoders learn smooth representations discrete structures allowing interesting results text generation unaligned style transfer semi supervised learning latent space interpolation arithmetic\n",
            "Predicted Summary>>> propose proposes transfer train transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use theory compressed sensing prove lstms least well linear text classification bag grams\n",
            "Predicted Summary>>> identify propose architecture sensing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate machine learning able model experiments quantum physics\n",
            "Predicted Summary>>> demonstrate train transfer networks demonstrate transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarially trained hierarchical generative model robust semantically learned latent representation\n",
            "Predicted Summary>>> adversarially adversarially trained used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions\n",
            "Predicted Summary>>> propose rl method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve saturating activations sigmoid tanh htanh etc binarized neural network bias initialization\n",
            "Predicted Summary>>> paper saturating activations saturating activations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform massive experimental studies characterizing relationships jacobian norms linear regions generalization\n",
            "Predicted Summary>>> perform studies transfer studies transfer studies transfer studies tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generates never seen data training desired condition\n",
            "Predicted Summary>>> generates proposes seen seen \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose convolutional tensor train lstm learns higher order convolutional lstm efficiently using convolutional tensor train decomposition\n",
            "Predicted Summary>>> propose adaptive generalized order order order order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarially trained hierarchical generative model robust semantically learned latent representation\n",
            "Predicted Summary>>> adversarially trained used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove deep neural networks exponentially efficient shallow ones approximating sparse multivariate polynomials\n",
            "Predicted Summary>>> prove theoretical first \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce searnn novel algorithm rnn training inspired learning search approach structured prediction order avoid limitations mle training\n",
            "Predicted Summary>>> address searnn memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe neuro ai interface technique evaluate generative adversarial networks\n",
            "Predicted Summary>>> describe neuro neuro neuro neuro neuro neuro neuro neuro neuro neuro neuro \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new pretraining method establishes new state art results glue race squad benchmarks fewer parameters compared bert large\n",
            "Predicted Summary>>> novel pretraining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gen rkm novel framework generative models using restricted kernel machines multi view generation uncorrelated feature learning\n",
            "Predicted Summary>>> gen rkm machines rkm rkm machines rkm machines rkm rkm machines rkm machines rkm machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural sparsity enhanced topic model based vae\n",
            "Predicted Summary>>> propose sparsity solve image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non consensual pornographic images imagenet dataset\n",
            "Predicted Summary>>> propose consensual pornographic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hypothesize vulnerability image models small adversarial perturbation naturally occurring result high dimensional geometry data manifold explore theoretically prove hypothesis simple synthetic dataset\n",
            "Predicted Summary>>> hypothesize adversarial text adversarial text adversarial text method perturbation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes novel actor critic method uses hessians critic update actor\n",
            "Predicted Summary>>> propose proposes actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduce discrete hierarchy categorical latent variables train using concrete gumbel softmax relaxation derive upper bound absolute difference unbiased biased objective\n",
            "Predicted Summary>>> propose novel categorical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extend autoregressive flows realnvp discrete data\n",
            "Predicted Summary>>> propose search search search search memory search first search first search first search first search first search first search first search first search first search first search memory search memory search memory search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search memory search first search first search first search first search first search first search first search first search first search gan search first search first search first search first search first search first search first search gan search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search first search gan search first search first search first search first search gan search first search first search\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce dcn deep residual coattention mixed objective rl achieves state art performance stanford question answering dataset\n",
            "Predicted Summary>>> propose provides create method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> graph neural network assisted monte carlo tree search approach traveling salesman problem\n",
            "Predicted Summary>>> propose rl algorithm monte optimization tree \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> derive new pac bayesian bound unbounded loss functions negative log likelihood\n",
            "Predicted Summary>>> propose used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used transfer used used used used used bound used used used used used used used used bound used used bound used bound used used used bound used bound used bound used bound used used used bound used used used used bound used bound used used used bound used bound used used used used bound used bound used used used used bound used used used used used bound used used bound used used used used used used used used used used used used used used bound used bound used used used used used used bound used bound used bound used bound used bound used used used bound used used bound used bound used used used used used bound used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> outputs modern nlp apis nonsensical text provide strong signals model internals allowing adversaries steal apis\n",
            "Predicted Summary>>> outputs modern nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> important consider optimization function space parameter space introduce learning rule reduces distance traveled function space like sgd limits distance traveled parameter space\n",
            "Predicted Summary>>> propose new optimization distance tasks distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose imitation learning method learn diverse quality demonstrations collected demonstrators different level expertise\n",
            "Predicted Summary>>> propose studies domain latent problems \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove first ever convergence proof asynchronous accelerated algorithm attains speedup\n",
            "Predicted Summary>>> prove asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dynamic precision technique train deep neural networks\n",
            "Predicted Summary>>> propose theoretical method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> coupled rule exemplar supervision implication loss helps jointly learn denoise rules imply labels\n",
            "Predicted Summary>>> coupled rule rule \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed simple yet effective baseline learning noisy labels\n",
            "Predicted Summary>>> propose generation generation learning generation models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> experimental paper proves amount redundant weights freezed third epoch slight drop accuracy\n",
            "Predicted Summary>>> experimental proves search proves \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> targeted communication multi agent cooperative reinforcement learning\n",
            "Predicted Summary>>> propose characterizes characterizes used tasks communication used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generating text using sentence embeddings skip thought vectors help generative adversarial networks\n",
            "Predicted Summary>>> generating thought vectors \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> rearranging terms maximum mean discrepancy yields much better loss function discriminator generative adversarial nets\n",
            "Predicted Summary>>> rearranging propose alternative maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose algorithm automatically adjusts parameters simulation engine generate training data neural network validation accuracy maximized\n",
            "Predicted Summary>>> propose novel \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce gaussian process prior weights neural network explore ability model input dependent weights benefits various tasks including uncertainty estimation generalization low sample setting\n",
            "Predicted Summary>>> propose matrix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reinforcment practices machine translation performance gains might come better predictions\n",
            "Predicted Summary>>> reinforcment practices practices \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> weakly supervised learning based clustering framework performs comparable fully supervised learning models exploiting unique class count\n",
            "Predicted Summary>>> use new memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning functionally decomposed hierarchies continuous navigation tasks\n",
            "Predicted Summary>>> propose rl deep decomposed \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find deep networks generalize poorly reliant single directions generalize well evaluate impact dropout batch normalization well class selectivity single direction reliance\n",
            "Predicted Summary>>> propose single single single single single single search tasks directions learned search directions learned search learned search directions learned search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use mixture density networks full conditional density estimation spatial offset regression apply human pose estimation task\n",
            "Predicted Summary>>> propose proposes regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> artificial neural networks trained gradient descent capable recapitulating realistic neural activity anatomical organization biological circuit\n",
            "Predicted Summary>>> artificial domain transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce doc dial end end framework generating conversational data grounded business documents via crowdsourcing train automated dialogue agents\n",
            "Predicted Summary>>> use structure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural model predicting multi aspect sentiments generating probabilistic multi dimensional mask simultaneously model outperforms strong baselines generates masks strong feature predictors meaningful interpretable\n",
            "Predicted Summary>>> paper search train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose adversarial training approach problem clarification question generation uses answer question model reward\n",
            "Predicted Summary>>> paper overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes overcomes representations overcomes representations overcomes representations overcomes overcomes overcomes overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine search reinforcement learning speed machine learning code\n",
            "Predicted Summary>>> identify search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search dense search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use dynamic rewards train event extractors\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provably recover lowest layer deep neural network assuming lowest layer uses high threshold activation network well behaved polynomial\n",
            "Predicted Summary>>> propose recover layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining ideas traditional algorithms design reinforcement learning introduce novel framework learning algorithms solve online combinatorial optimization problems\n",
            "Predicted Summary>>> solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> regularizing adversarial learning information bottleneck applied imitation learning inverse reinforcement learning generative adversarial networks\n",
            "Predicted Summary>>> regularizing recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> enable ordinary cnns shot learning exploiting visual concepts interpretable visual cues learnt within cnns\n",
            "Predicted Summary>>> simplex propose ordinary \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new method combines transfer based scored black box adversarial attack improving success rate query efficiency black box adversarial attack across different network architectures\n",
            "Predicted Summary>>> method new gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactive technique improve brushing dense trajectory datasets taking account shape brush\n",
            "Predicted Summary>>> interactive brushing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use cultural transmission encourage compositionality languages emerge interactions neural agents\n",
            "Predicted Summary>>> propose cultural transmission \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extended single trial space time tensor decomposition based non negative matrix factorization efficiently discount pre stimulus baseline activity improves decoding performance data non negligible baselines\n",
            "Predicted Summary>>> propose proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> regularizing adversarial learning information bottleneck applied imitation learning inverse reinforcement learning generative adversarial networks\n",
            "Predicted Summary>>> regularizing recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised reinforcement learning method learning policy robustly achieve perceptually specified goals\n",
            "Predicted Summary>>> identify adversarial recurrent tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compare many tasks task combinations pretraining sentence level bilstms nlp tasks language modeling best single pretraining task simple baselines also well\n",
            "Predicted Summary>>> compare tasks pretraining tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel shot learning method generate query specific classification weights via information maximization\n",
            "Predicted Summary>>> goal tasks problem sorting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents empirical analysis role different types image representations probes properties representations task image captioning\n",
            "Predicted Summary>>> propose variants \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find movement function space proportional movement parameter space optimization propose new natural gradient style optimizer address\n",
            "Predicted Summary>>> find movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> convolutional autoencoders generalized mesh surfaces encoding reconstructing extreme facial expressions\n",
            "Predicted Summary>>> propose novel gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> mmo inspired research game platform studying emergent behaviors large populations complex environment\n",
            "Predicted Summary>>> mmo complex platform populations behaviors platform populations platform platform platform behaviors behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform platform platform behaviors platform behaviors platform behaviors platform platform platform behaviors platform platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors platform behaviors\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce alternative gan design based random routes generator serve tool generative models interpretability\n",
            "Predicted Summary>>> propose gan even even \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> secret transfer method rl based transfer credit assignment\n",
            "Predicted Summary>>> propose rl transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> benchmarks biologically plausible learning algorithms complex datasets architectures\n",
            "Predicted Summary>>> benchmarks biologically plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible used plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible used plausible plausible plausible plausible plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible dynamics plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used plausible used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explore neural architecture search language tasks recurrent cell search challenging nmt attention mechanism search works result attention search translation transferable reading comprehension\n",
            "Predicted Summary>>> explore tasks tasks tasks tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose end end model building process universally applicable wide variety authorship verification corpora outperforms state art little modification fine tuning\n",
            "Predicted Summary>>> propose proposes building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building building\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> applicability inverse reinforcement learning often hampered expense collecting expert demonstrations paper seeks broaden applicability incorporating prior task information meta learning\n",
            "Predicted Summary>>> propose memory used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose procedures evaluating strengthening contextual embedding alignment show improve multilingual bert zero shot xnli transfer provide useful insights model\n",
            "Predicted Summary>>> propose hexaconv adversarial models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new stream adversarial training approach called robust local features adversarial training rlfat significantly improves adversarially robust generalization standard generalization\n",
            "Predicted Summary>>> propose proposes robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust robust\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> graphon good search space neural architecture search empirically produces good networks\n",
            "Predicted Summary>>> graphon space search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show shortcut connections placed patterns minimize layer distances backpropagation design networks achieve log distances using log connections\n",
            "Predicted Summary>>> propose shortcut placed shortcut distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose novel neural language model called parsing reading predict networks prpn simultaneously induce syntactic structure unannotated sentences leverage inferred structure learn better language model\n",
            "Predicted Summary>>> use completion noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce contextual decompositions interpretation algorithm lstms capable extracting word phrase interaction level importance score\n",
            "Predicted Summary>>> propose contextual contextual contextual contextual contextual contextual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> short paper briefly introduce advantages using ai planning cloud migration preliminary prototype well chal lenges requires attention planning schedul ing society\n",
            "Predicted Summary>>> paper briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theoretical analysis nonlinear wide autoencoder\n",
            "Predicted Summary>>> propose use encoder transfer method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve specific sr issue low quality jpg images functional sub models\n",
            "Predicted Summary>>> propose rl search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provably recover span deep multi layered neural network latent structure empirically apply efficient span recovery algorithms attack networks obfuscating inputs\n",
            "Predicted Summary>>> paper theoretical image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new dnn architecture deep learning tabular data\n",
            "Predicted Summary>>> propose use dnn method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> social agents learn talk natural language towards goal\n",
            "Predicted Summary>>> propose domain transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed cooperative training novel training algorithm generative modeling discrete data\n",
            "Predicted Summary>>> paper cooperative \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve tasks involving vision guided humanoid locomotion reusing locomotion behavior motion capture data\n",
            "Predicted Summary>>> propose involving involving \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new framework using dual space generating images corresponding multiclass labels number class large\n",
            "Predicted Summary>>> propose proposes dual training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop theoretical foundations expressive power gnns design provably powerful gnn\n",
            "Predicted Summary>>> propose scaling shot \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop efficient methods train neural embedding models dot product structure reformulating objective function terms generalized gram matrices maintaining estimates matrices\n",
            "Predicted Summary>>> propose study \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> faster method generating node embeddings employs number permutations node immediate neighborhood context generate representation\n",
            "Predicted Summary>>> faster immediate generate generating generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> general framework distilling bayesian posterior expectations deep neural networks\n",
            "Predicted Summary>>> propose method posterior \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training agents adaptive computation based information bottleneck promote generalization\n",
            "Predicted Summary>>> propose adaptive tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new auto encoder incorporated multiway delay embedding transform toward interpreting deep image prior\n",
            "Predicted Summary>>> propose problem new used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve reconstruction time quality experimental mask based lensless imager using end end learning approach incorporates knowledge imaging model\n",
            "Predicted Summary>>> paper method architecture mask \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural simulation universal turing machine\n",
            "Predicted Summary>>> propose proposes estimates policy noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper combines monte carlo tree search opt local search variable neighborhood mode solve tsp effectively\n",
            "Predicted Summary>>> propose several method tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> children use mutual exclusivity bias learn new words standard neural nets show opposite bias hindering learning naturalistic scenarios lifelong learning\n",
            "Predicted Summary>>> children general method cases \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed method end end neural svm optimized shot learning\n",
            "Predicted Summary>>> propose memory transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> jiffy convolutional approach learning distance metric multivariate time series outperforms existing methods terms nearest neighbor classification accuracy\n",
            "Predicted Summary>>> jiffy learning distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose imitation learning method learn diverse quality demonstrations collected demonstrators different level expertise\n",
            "Predicted Summary>>> propose studies domain latent problems \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show autoregressive flows used improve sequential latent variable models\n",
            "Predicted Summary>>> propose generator tasks networks used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce stochastic training method training binary neural network binary weights activations\n",
            "Predicted Summary>>> propose analyze networks solve solve solve solve solve solve solve solve solve solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose scalable method approximate eigenvectors laplacian reinforcement learning context show learned representations improve performance rl agent\n",
            "Predicted Summary>>> propose scalable step \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study adversarial machine learning attacks multiple object tracking mechanisms first time\n",
            "Predicted Summary>>> propose proposes adversarial object object object \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop analyze new derivative free optimization algorithm momentum importance sampling applications continuous control\n",
            "Predicted Summary>>> propose autonomous set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method transform dna sequences images using space filling hilbert curves enhance strengths cnns\n",
            "Predicted Summary>>> demonstrate dna set dna dna set tasks dna set dependencies set dependencies set dependencies set dependencies set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method make use multiple passages information open domain qa\n",
            "Predicted Summary>>> propose layer multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce approach allow agents learn ppddl action models incrementally multiple planning problems framework reinforcement learning\n",
            "Predicted Summary>>> propose presents \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> image classification via iteratively querying reference image candidate class rnn use cnn compare input image\n",
            "Predicted Summary>>> propose top sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence sentence \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> general framework creating covariant graph neural networks\n",
            "Predicted Summary>>> propose truly creating \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new simple dynamic system introduced generates pretty patterns properties proved possibilities explored\n",
            "Predicted Summary>>> propose variants optimization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using branched attention learned combination weights outperforms baseline transformer machine translation tasks\n",
            "Predicted Summary>>> propose branched method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> autoencoders text new method using discrete latent space\n",
            "Predicted Summary>>> propose new text text text text text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present bayesian inference model infer contrastive explanations ltl specifications describing two sets plan traces differ\n",
            "Predicted Summary>>> propose novel transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new loss function pca linear autoencoders provably yields ordered exact eigenvectors\n",
            "Predicted Summary>>> work proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> progressively growing available action space great curriculum learning agents\n",
            "Predicted Summary>>> progressively growing growing growing tasks action \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theoretical analysis nonlinear wide autoencoder\n",
            "Predicted Summary>>> propose encoder transfer method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce amortized proximal optimization apo method adapt variety optimization hyperparameters online training including learning rates damping coefficients gradient variance exponents\n",
            "Predicted Summary>>> train memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents empirical analysis role different types image representations probes properties representations task image captioning\n",
            "Predicted Summary>>> propose variants learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel interpretation mixup belonging class highly analogous adversarial training basis introduce simple generalization outperforms mixup\n",
            "Predicted Summary>>> propose novel belonging tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose temporal self supervisions learning stable temporal functions gans\n",
            "Predicted Summary>>> propose gan layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> applying softmax function training leads indirect unexpected supervision features propose new training objective explicitly induce dense feature regions locally sufficient samples benefit adversarial robustness\n",
            "Predicted Summary>>> applying novel rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hmms special case rnns investigate series architectural transformations hmms rnns theoretical derivations empirical hybridization provide new insights\n",
            "Predicted Summary>>> hmms hmms transfer imitation transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gradient free method proposed non convex optimization problem\n",
            "Predicted Summary>>> propose free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free free \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> classification problems classes show gradient tends live tiny slowly evolving subspace spanned eigenvectors corresponding largest eigenvalues hessian\n",
            "Predicted Summary>>> propose method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parameter space noise allows reinforcement learning algorithms explore perturbing parameters instead actions often leading significantly improved exploration performance\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose generative method multisource domain adaptation based decomposition content style domain factors\n",
            "Predicted Summary>>> propose rl train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy learning bandit feedbacks propose new variance regularized counterfactual learning algorithm theoretical foundations superior empirical performance\n",
            "Predicted Summary>>> develop tuning tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> actor critic reinforcement learning approach multi step returns applied autonomous driving carla simulator\n",
            "Predicted Summary>>> actor step step \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tackling inverse design via genetic algorithms augmented deep neural networks\n",
            "Predicted Summary>>> propose new design design \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose architecture search method identify distribution architectures use construct bayesian ensemble outlier detection\n",
            "Predicted Summary>>> propose rl propose search propose rl method propose rl improve search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce theory explain failure gans complex datasets propose solution fix\n",
            "Predicted Summary>>> propose proposes domain failure failure failure failure failure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply copula transformation deep information bottleneck leads restored invariance properties disentangled latent space superior predictive capabilities\n",
            "Predicted Summary>>> apply copula transformation tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show successfully perform backdoor attacks without changing training labels\n",
            "Predicted Summary>>> propose new backdoor \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tackle goal conditioned tasks combining hindsight experience replay imitation learning algorithms showing faster convergence first higher final performance second\n",
            "Predicted Summary>>> tackle propose critic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose diversely stale parameters break lockings backpropoagation algorithm train cnn parallel\n",
            "Predicted Summary>>> propose diversely gans \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce information theoretic viewpoint behavior deep networks optimization processes generalization abilities\n",
            "Predicted Summary>>> introduce proposes theoretic deep viewpoint \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> instead learning parameters graphical model data learn inference network answer probabilistic queries\n",
            "Predicted Summary>>> propose problem tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> internal consistency constraints improve agents ability develop emergent protocols generalize across communicative roles\n",
            "Predicted Summary>>> propose consistency set set set set set set set set set set set set set consistency set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> exploring learnability learned neural networks\n",
            "Predicted Summary>>> propose learnability method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents method explain knowledge encoded convolutional neural network cnn quantitatively semantically\n",
            "Predicted Summary>>> paper proposes novel features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reframe generation problem one editing existing points result extrapolate better traditional gans\n",
            "Predicted Summary>>> reframe proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposal strategies adversarial defense based data dependent activation function total variation minimization training data augmentation\n",
            "Predicted Summary>>> propose toward networks train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce gaussian process prior weights neural network explore ability model input dependent weights benefits various tasks including uncertainty estimation generalization low sample setting\n",
            "Predicted Summary>>> propose matrix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use non negative rank relu activation matrices complexity measure show negatively correlates good generalization\n",
            "Predicted Summary>>> train generative \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> network pruning fine tuning pruned model gives comparable worse performance training scratch advocate rethinking existing pruning algorithms\n",
            "Predicted Summary>>> propose theoretical theoretical recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method handle image degradations different levels learning diffusion terminal time model generalize unseen degradation level different noise statistic\n",
            "Predicted Summary>>> train text evaluating text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using deep learning techniques singing voice related tasks\n",
            "Predicted Summary>>> propose several method singing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> exploit inversion scheme arbitrary deep neural networks develop new semi supervised learning framework applicable many topologies\n",
            "Predicted Summary>>> exploit method exploit \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy gradient backpropagation time using learned models functions sota results reinforcement learning benchmark environments\n",
            "Predicted Summary>>> policy backpropagation backpropagation backpropagation backpropagation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> existing deep convolutional networks image classification tasks sensitive gabor noise patterns small structured changes input cause large changes output\n",
            "Predicted Summary>>> paper several memory tasks image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired trial trial variability brain result multiple noise sources introduce variability noise knowledge distillation framework studied effect generalization robustness\n",
            "Predicted Summary>>> propose trial \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new efficient algorithm construct adversarial examples means deformations rather additive perturbations\n",
            "Predicted Summary>>> propose novel variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> suggest generalization bound could partly explain improvement generalization parametrization\n",
            "Predicted Summary>>> propose properly partly could could could could \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parameters trained neural network permuted produce completely separate model different task enabling embedding trojan horse networks inside another network\n",
            "Predicted Summary>>> propose method sample \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper studied pubn classification problem incorporate biased negative bn data negative data fully representative true underlying negative distribution positive unlabeled pu learning\n",
            "Predicted Summary>>> paper encoder problem tasks trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> isparse eliminates irrelevant insignificant network edges minimal impact network performance determining edge importance final network output\n",
            "Predicted Summary>>> isparse eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep neural networks able learn data diluted arbitrary amount noise\n",
            "Predicted Summary>>> proposed noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present effective defenses clean label poisoning attacks\n",
            "Predicted Summary>>> develop proposes defenses defenses defenses layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces coloring scheme node disambiguation graph neural networks based separability proven universal mpnn extension\n",
            "Predicted Summary>>> propose theoretical encoder coloring \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose imitation learning method learn diverse quality demonstrations collected demonstrators different level expertise\n",
            "Predicted Summary>>> propose studies domain latent problems \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> point important problems common practice using best single model performance comparing deep learning architectures propose method corrects flaws\n",
            "Predicted Summary>>> paper combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination combination \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> graph generative models based generalization message passing continuous time using ordinary differential equations\n",
            "Predicted Summary>>> train generative models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study effect embedding complexity learning domain invariant representations develop strategy mitigates sensitivity\n",
            "Predicted Summary>>> propose proposes memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> enabled novel differentiable renderer propose new metric real world implications evaluating adversarial machine learning algorithms resolving lack realism existing metric based pixel norms\n",
            "Predicted Summary>>> propose novel renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer renderer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> high object detection accuracy obtained training domain specific compact models training short\n",
            "Predicted Summary>>> high high high high tasks high high high high high high high high high high high high high high high high high high high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose hippo stable hierarchical reinforcement learning algorithm train several levels hierarchy simultaneously giving good performance skill discovery adaptation\n",
            "Predicted Summary>>> use proposes single single single \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel architecture traverses image pyramid top fashion visits informative regions along way\n",
            "Predicted Summary>>> propose architecture traverses traverses traverses method traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel ensemble retrieval based generation based open domain conversation systems\n",
            "Predicted Summary>>> ensemble introduces transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new type end end trainable attention module applies global weight balances among layers utilizing co propagating rnn cnn\n",
            "Predicted Summary>>> propose new trainable trainable trainable trainable trainable trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> spiking recurrent neural networks performing working memory task utilize long heterogeneous timescales strikingly similar observed prefrontal cortex\n",
            "Predicted Summary>>> propose method space networks like \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explore relationship normalising flows variational denoising autoencoders propose novel model generalises\n",
            "Predicted Summary>>> explore encoder flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows flows\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using annealed importance sampling co generation problem\n",
            "Predicted Summary>>> propose annealed train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> bridge gap soft computing\n",
            "Predicted Summary>>> bridge gap architectures architectures architectures architectures architectures architectures architectures architectures architectures architectures architectures architectures architectures architectures training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes novel complex masking method speech enhancement along loss function efficient phase estimation\n",
            "Predicted Summary>>> provide novel memory method masking \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce alternative gan design based random routes generator serve tool generative models interpretability\n",
            "Predicted Summary>>> propose novel even search rule tasks helps even \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural net graph based semi supervised learning revisits classics propagates labels rather feature representations\n",
            "Predicted Summary>>> propose net algorithm set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> bsuite collection carefully designed experiments investigate core capabilities rl agents\n",
            "Predicted Summary>>> bsuite new top \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents deep learning model combines self organizing maps convolutional neural networks representation learning multi omics data\n",
            "Predicted Summary>>> develop new method new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show question answer matching particularly good pre training task question similarity release dataset medical question similarity\n",
            "Predicted Summary>>> propose question question answer question question particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly question particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly question particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine matching network framework shot learning large scale multi label model genomic sequence classification\n",
            "Predicted Summary>>> propose rl way architecture real \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method leverages gradients differentiable simulators improve performance rl robotics control\n",
            "Predicted Summary>>> propose novel improve leverages leverages gradients \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing network architecture set syntax trees optimizing structure leads accurate concise regression models\n",
            "Predicted Summary>>> propose new set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present improved version universal successor features based drl method improve transfer learning agents\n",
            "Predicted Summary>>> propose version method version noise version noise noise noise noise noise noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adding new set weights lstm rotate cell memory improves performance babi tasks\n",
            "Predicted Summary>>> adding adding represent set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper analyzes problem designing adversarial attacks multiple classifiers introducing algorithms optimal linear classifiers provide state art results deep learning\n",
            "Predicted Summary>>> paper analyzes problem learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> give method generating type safe programs java like language given small amount syntactic information desired code\n",
            "Predicted Summary>>> propose proposes used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gan based method joint image per pixel annotation synthesis\n",
            "Predicted Summary>>> address proposes memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> multi view learning improves unsupervised sentence representation learning\n",
            "Predicted Summary>>> unsupervised analyze transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed cooperative training novel training algorithm generative modeling discrete data\n",
            "Predicted Summary>>> paper cooperative \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method manipulate given images using natural language descriptions\n",
            "Predicted Summary>>> propose first trained trained trained trained trained trained first first trained first first trained trained first trained first trained trained first trained first trained first first trained first trained first first trained trained trained first first trained first first trained trained trained first first first first trained trained first trained first trained first first trained first trained trained first trained trained first trained trained trained first trained first first trained first first trained first trained first trained trained first first trained first first trained first first trained trained first trained first first first trained first first first first trained first trained trained first trained trained trained first trained first trained trained first trained first trained first trained first first trained first trained first first trained trained trained trained trained first trained trained first trained first trained first trained first trained first first trained trained trained trained first trained trained first trained first first trained first trained first trained first trained first first trained first trained first first trained first trained first first trained trained first trained first trained trained first trained trained first first trained first first trained first trained first first trained trained first trained first trained trained first trained first first trained first trained trained first trained first trained first trained trained trained trained first trained first trained trained first trained first trained trained first first first first trained first trained first trained first trained trained first trained first trained first first trained first first first trained trained first first first first trained first first\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn entity representations reconstruct wikipedia categories exemplars\n",
            "Predicted Summary>>> propose method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> represent entity based histogram contexts wasserstein need\n",
            "Predicted Summary>>> represent theoretical memory transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> recovery guarantee stochastic gradient descent random initialization learning two layer neural network two hidden nodes unit norm weights relu activation functions gaussian inputs\n",
            "Predicted Summary>>> recovery guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee stochastic stochastic guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee guarantee\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning synthesize raw waveform audio gans\n",
            "Predicted Summary>>> propose raw raw waveform raw waveform waveform raw waveform raw waveform raw waveform raw waveform waveform raw waveform raw waveform raw raw raw raw waveform raw raw raw raw raw waveform raw raw raw raw raw raw raw waveform raw raw raw raw raw raw raw raw raw raw raw raw raw raw waveform raw raw raw raw raw raw raw raw raw raw raw waveform raw raw raw raw raw waveform raw raw raw raw waveform raw raw waveform raw raw raw raw waveform raw raw raw raw waveform raw raw raw raw raw waveform raw raw raw raw raw waveform raw raw raw raw raw raw raw raw waveform raw raw raw waveform raw raw raw raw waveform raw raw raw raw raw raw raw waveform raw raw raw raw raw raw waveform raw raw raw raw raw waveform raw raw raw raw raw waveform raw raw waveform raw raw raw raw raw waveform raw raw raw raw waveform raw raw waveform raw raw raw waveform raw raw raw raw waveform raw raw waveform raw raw raw raw waveform raw raw raw waveform raw raw waveform raw raw raw raw raw raw raw raw waveform raw waveform raw raw raw raw waveform raw raw raw raw raw waveform raw raw waveform raw raw waveform raw raw raw raw raw raw waveform raw raw raw raw waveform raw raw waveform raw raw raw raw raw raw waveform raw raw raw waveform raw raw raw raw waveform waveform waveform raw raw raw waveform raw raw raw raw\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> amortizing nesterov momentum robust lightweight fast deep learning training\n",
            "Predicted Summary>>> propose nesterov momentum method likelihood \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper formalises problem online algorithm selection context reinforcement learning\n",
            "Predicted Summary>>> propose formalises semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> represent computer program using set simpler programs use representation improve program synthesis techniques\n",
            "Predicted Summary>>> represent computer set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn lstm generate markup like code describing graphical user interface images\n",
            "Predicted Summary>>> cnn lstm lstm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cross lingual ability multilingual bert empirical study\n",
            "Predicted Summary>>> train tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> benchmark evaluate neural embeddings identifiers source code\n",
            "Predicted Summary>>> propose variational random variational random benchmark \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present local ensembles method detecting extrapolation trained models approximates variance ensemble using local second order information\n",
            "Predicted Summary>>> extend novel variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training agents adaptive computation based information bottleneck promote generalization\n",
            "Predicted Summary>>> propose adaptive computation tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes effective generic sequence model leverages strengths rnns multi head attention\n",
            "Predicted Summary>>> paper proposes asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose prob vec method problem embedding used personalized learning tool addition data level classification method called negative pre training cases training data set imbalanced\n",
            "Predicted Summary>>> propose prob method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find movement function space proportional movement parameter space optimization propose new natural gradient style optimizer address\n",
            "Predicted Summary>>> find movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> isparse eliminates irrelevant insignificant network edges minimal impact network performance determining edge importance final network output\n",
            "Predicted Summary>>> isparse eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cloze test dataset designed teachers assess language proficiency\n",
            "Predicted Summary>>> cloze test proficiency teachers teachers teachers teachers teachers teachers teachers teachers teachers teachers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present rl agent minerva learns walk knowledge graph answer queries\n",
            "Predicted Summary>>> propose rl rl rl minerva rl minerva rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use cross entropy loss zero shot learning soft labeling unseen classes simple effective solution achieves state art performance five zsl benchmark datasets\n",
            "Predicted Summary>>> use encoder method entropy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> system learn robotic tasks real world reinforcement learning without instrumentation\n",
            "Predicted Summary>>> propose search robotic based search tasks tasks robotic tasks robotic tasks search tasks search tasks search tasks tasks robotic tasks search tasks search tasks tasks search tasks search tasks search tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel hrl framework formulate temporal abstraction problem learning latent representation action sequence\n",
            "Predicted Summary>>> unsupervised hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl hrl\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural probabilistic motor primitives compress motion capture tracking policies one flexible model capable one shot imitation reuse low level controller\n",
            "Predicted Summary>>> propose trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explainable reinforcement learning model using novel combination mixture experts non differentiable decision tree experts\n",
            "Predicted Summary>>> explainable combination even transfer policy even policy even \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper describes methods verify recognize htn plans parsing attribute grammars\n",
            "Predicted Summary>>> propose describes transfer models representations transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> distilling single task models multi task model improves natural language understanding performance\n",
            "Predicted Summary>>> propose ill method tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents empirical analysis role different types image representations probes properties representations task image captioning\n",
            "Predicted Summary>>> propose variants \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use convolution make neural networks behave like symbolic systems\n",
            "Predicted Summary>>> propose method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train variational models quantized networks computational determinism enables using cross platform data compression\n",
            "Predicted Summary>>> train networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce new mujoco soccer environment continuous multi agent reinforcement learning research show population based training independent reinforcement learners learn cooperative behaviors\n",
            "Predicted Summary>>> propose mujoco mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco soccer mujoco \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed bayesian meta sampling method adapting model uncertainty meta learning\n",
            "Predicted Summary>>> propose diversely training identify \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactively generating image incrementally growing scene graphs multiple steps using gans preserving contents image generated previous steps\n",
            "Predicted Summary>>> propose image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image tasks image image image tasks image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper focuses synthetic generation human mobility data urban areas using gans\n",
            "Predicted Summary>>> propose focuses encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new algorithm online multi task learning learns without restarts task borders\n",
            "Predicted Summary>>> propose method networks method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> noise robust deep learning architecture\n",
            "Predicted Summary>>> propose proposes approach \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new deep latent model natural images trained unlabeled datasets utilized solve various image restoration tasks\n",
            "Predicted Summary>>> train transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> alternative gradient penalty\n",
            "Predicted Summary>>> alternative representations tasks penalty \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> goal driven approach model four mouse visual areas lm al rl based deep neural networks trained static object recognition unveil functional organization visual cortex unlike primates\n",
            "Predicted Summary>>> propose adaptive memory learning networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep architectures point clouds equivariant rotations well translations permutations\n",
            "Predicted Summary>>> propose gans distribution \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> language modeling lifelong language learning\n",
            "Predicted Summary>>> provide language \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce capacity exploit information degree arbitrary goal achieved another goal intended policy gradient methods\n",
            "Predicted Summary>>> propose proposes solve solve solve solve solve solve solve solve solve solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> define filter level pruning problem binary neural networks first time propose method solve\n",
            "Predicted Summary>>> define level level \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gans successful adversarial training use convnets show convnet generator trained simple reconstruction loss learnable noise vectors leads many desirable properties gan\n",
            "Predicted Summary>>> represent modeling adversarial distribution distribution \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new framework data dependent dnn regularization prevent dnns overfitting random data random labels\n",
            "Predicted Summary>>> propose gan used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel watermark encoder decoder neural networks perform cooperative game define watermarking scheme people need design watermarking methods\n",
            "Predicted Summary>>> propose set watermark set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> strong bias towards simple outpouts observed many simple input ouput maps parameter function map deep networks found biased way\n",
            "Predicted Summary>>> propose curiosity way way tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non asymptotic analysis sgd svrg showing strength algorithm convergence speed computational cost parametrized parametrized settings\n",
            "Predicted Summary>>> study proposes analysis \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents improved training mechanism obtaining binary networks smaller accuracy drop helps close gap full precision counterpart\n",
            "Predicted Summary>>> policy propose policy policy policy improved policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model reconciliation established framework plan explanations easily hijacked produce lies\n",
            "Predicted Summary>>> propose reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation established \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method learning better representations acts regularizer despite significant additional computation cost achieves improvements strong baselines supervised semi supervised learning tasks\n",
            "Predicted Summary>>> propose proposes training representations training despite training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce gaussian process prior weights neural network explore ability model input dependent weights benefits various tasks including uncertainty estimation generalization low sample setting\n",
            "Predicted Summary>>> propose matrix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining auxiliary adversarial training interrogate help physical understanding\n",
            "Predicted Summary>>> auxiliary proposes adversarial interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn space motor primitives unannotated robot demonstrations show primitives semantically meaningful composed new robot tasks\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate recurrent neural network successfully learns task combining long term memory sequential recall\n",
            "Predicted Summary>>> introduce proposes memory generation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> accelerating cnn training pipeline accelerators stale weights\n",
            "Predicted Summary>>> accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating architecture pipeline pipeline pipeline pipeline \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep learning structured tabular data machine learning using pre trained cnn model imagenet\n",
            "Predicted Summary>>> address novel method agnostic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> predict generalization error specify model attains across model data scales\n",
            "Predicted Summary>>> predict tasks error error \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose learn synthesizing shot classifiers many shot classifiers using one single objective function gfsl\n",
            "Predicted Summary>>> propose method shot synthesizing shot \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> autoencoders text new method using discrete latent space\n",
            "Predicted Summary>>> propose new text text text text text text text text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> augment model free policy learning sequence level surrogate reward functions count based visitation bonus demonstrate effectiveness large batch low round regime seen designing dna protein sequences\n",
            "Predicted Summary>>> augment novel tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose semantic aware neural abstractive summarization model novel automatic summarization evaluation scheme measures well model identifies topic information adversarial samples\n",
            "Predicted Summary>>> propose structure summarization networks sentences \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> found adversarial training speeds gan training also increases image quality\n",
            "Predicted Summary>>> propose novel gan also \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> exploit inversion scheme arbitrary deep neural networks develop new semi supervised learning framework applicable many topologies\n",
            "Predicted Summary>>> exploit method exploit \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train predictive models proprioceptive information show represent properties external objects\n",
            "Predicted Summary>>> propose predictive adversarial models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advance state art model compression proposing atomic compression networks acns novel architecture constructed recursive repetition small set neurons\n",
            "Predicted Summary>>> advance design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training method make deep learning algorithms work better neuromorphic computing chips uncertainty\n",
            "Predicted Summary>>> propose proposes common \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> goal driven approach model four mouse visual areas lm al rl based deep neural networks trained static object recognition unveil functional organization visual cortex unlike primates\n",
            "Predicted Summary>>> propose adaptive memory learning networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose adversarial inverse reinforcement learning algorithm capable learning reward functions transfer new unseen environments\n",
            "Predicted Summary>>> propose inverse inverse image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes novel actor critic method uses hessians critic update actor\n",
            "Predicted Summary>>> propose proposes actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor actor\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep neural networks able learn data diluted arbitrary amount noise\n",
            "Predicted Summary>>> proposed noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> case study optimal deep learning model uavs\n",
            "Predicted Summary>>> oe teaches search teaches heuristics \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide insightful understanding sequence labeling ner propose use two types cross structures bring theoretical empirical improvements\n",
            "Predicted Summary>>> propose insightful insightful \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> controlled study role environments respect properties emergent communication protocols\n",
            "Predicted Summary>>> controlled controlled role protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols protocols \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose algorithm automatically adjusts parameters simulation engine generate training data neural network validation accuracy maximized\n",
            "Predicted Summary>>> propose novel \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show posterior collapse linear vaes caused entirely marginal log likelihood elbo experiments deep vaes suggest similar phenomenon play\n",
            "Predicted Summary>>> propose new used search used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reframe generation problem one editing existing points result extrapolate better traditional gans\n",
            "Predicted Summary>>> reframe proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generating new chemical materials using novel cross domain gans\n",
            "Predicted Summary>>> novel chemical chemical method chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose cr nas reallocate engaged computation resources different resolution spatial position\n",
            "Predicted Summary>>> propose cr cr reallocate engaged reallocate resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources resources\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel marginalized average attentional network weakly supervised temporal action localization\n",
            "Predicted Summary>>> propose variant average \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide efficient convergence rate gradient descent complete orthogonal dictionary learning objective based geometric analysis\n",
            "Predicted Summary>>> train used descent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proves skinny neural networks cannot approximate certain functions matter deep\n",
            "Predicted Summary>>> propose skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed sesamebert generalized fine tuning method enables extraction global information among layers squeeze excitation enriches local information capturing neighboring contexts via gaussian blurring\n",
            "Predicted Summary>>> propose sesamebert tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove large class functions exists interval certified robust network approximating arbitrary precision\n",
            "Predicted Summary>>> propose architecture together together \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analysis attention mechanism across diverse nlp tasks\n",
            "Predicted Summary>>> propose memory used across across across across across across across \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper present task agnostic reading architecture dynamic integration explicit background knowledge neural nlu models\n",
            "Predicted Summary>>> propose novel transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate eigenvalues linear layers deep networks show distributions develop heavy tail behavior training\n",
            "Predicted Summary>>> propose eigenvalues layers layers networks generation linear \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new latent variable model learn latent embeddings high dimensional data\n",
            "Predicted Summary>>> propose neural relu train relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu relu \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> monte carlo methods quantizing pre trained models without additional training\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> stochastic gradient method momentum generalizes\n",
            "Predicted Summary>>> stochastic momentum momentum momentum momentum momentum method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> systematically analyze convergence behaviour popular gradient algorithms solving bilinear games simultaneous alternating updates\n",
            "Predicted Summary>>> systematically analyze behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour behaviour\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> loss surface neural networks disjoint union regions every local minimum global minimum corresponding region\n",
            "Predicted Summary>>> train surface disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint disjoint\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> elastic infogan modification infogan learns without supervision disentangled representations class imbalanced data\n",
            "Predicted Summary>>> propose gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training method make deep learning algorithms work better neuromorphic computing chips uncertainty\n",
            "Predicted Summary>>> propose proposes common \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural clustering without needing number clusters\n",
            "Predicted Summary>>> train clustering clustering clustering \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> integrative tensor based anomaly detection itad framework satellite system\n",
            "Predicted Summary>>> explored novel method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cross lingual ability multilingual bert empirical study\n",
            "Predicted Summary>>> train tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new model making generalizable diverse retrosynthetic reaction predictions\n",
            "Predicted Summary>>> propose text text text transfer text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hybrid model utilizing raw audio spectrogram information speech enhancement tasks\n",
            "Predicted Summary>>> hybrid rl raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw raw step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel cluster based algorithm curriculum learning proposed solve robust training generative models\n",
            "Predicted Summary>>> propose theoretical policy policy learning algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> give method generating type safe programs java like language given small amount syntactic information desired code\n",
            "Predicted Summary>>> propose proposes used method used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove generalization dnns adding lipschitz regularization term training loss resolve question posed zhang et al\n",
            "Predicted Summary>>> propose theoretical method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> network pruning fine tuning pruned model gives comparable worse performance training scratch advocate rethinking existing pruning algorithms\n",
            "Predicted Summary>>> propose theoretical theoretical recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent recurrent\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> submitted emnlp\n",
            "Predicted Summary>>> learned novel matrix networks method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> spatial information last layers necessary good classification accuracy\n",
            "Predicted Summary>>> propose last last last last last last last last last last last last last layers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> distilling single task models multi task model improves natural language understanding performance\n",
            "Predicted Summary>>> propose ill trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable method tasks trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new certified adversarial training method crown ibp achieves state art robustness inf norm adversarial perturbations\n",
            "Predicted Summary>>> policy adversarial encoder encoder training encoder training encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents method generating using ensembles effectively identify noisy examples presence annotation noise\n",
            "Predicted Summary>>> identify presents noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform massive experimental studies characterizing relationships jacobian norms linear regions generalization\n",
            "Predicted Summary>>> perform studies transfer studies tasks studies \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficiently solve multi task problems automatic curriculum generation algorithm based generative model tracks learning agent performance\n",
            "Predicted Summary>>> identify rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel meta learning model adaptively balances effect meta learning task specific learning also class specific learning within task\n",
            "Predicted Summary>>> propose novel method training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> even tradeoff infinite data limit adversarial training worse standard accuracy even convex problem\n",
            "Predicted Summary>>> even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even even\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non consensual pornographic images imagenet dataset\n",
            "Predicted Summary>>> propose consensual pornographic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> give algorithm learning two layer neural network symmetric input distribution\n",
            "Predicted Summary>>> give encoder layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate flow based generative models offer viable competitive approach generative modeling video\n",
            "Predicted Summary>>> propose theoretical used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> detecting overlapping communities graphs using graph neural networks\n",
            "Predicted Summary>>> propose overlapping communities communities tasks transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> framework studying emergent communication networked multi agent reinforcement learning setup\n",
            "Predicted Summary>>> propose studying networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents theoretical framework models data distribution explicitly deep locally connected relu network\n",
            "Predicted Summary>>> identify proposes tasks relu \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> continental philosophy inspired approach learn data\n",
            "Predicted Summary>>> continental domain inspired domain models representations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> feature map compression method converts quantized activations binary vectors followed nonlinear dimensionality reduction layers embedded dnn\n",
            "Predicted Summary>>> propose deep layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep rl algorithm solving pomdps auto encoding underlying states using variational recurrent model\n",
            "Predicted Summary>>> propose adversarial method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn temporal point processes modeling conditional density conditional intensity\n",
            "Predicted Summary>>> propose proposes algorithm algorithm algorithm algorithm model algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unified model improve model robustness multiple tasks\n",
            "Predicted Summary>>> unified unified multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> automatically extract fingering information videos piano performances used automatic fingering prediction models\n",
            "Predicted Summary>>> propose use improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved propose improved improved improved improved improved improved improved improved improved improved improved improved improved propose improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved propose improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved propose improved improved improved improved improved improved improved improved improved\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose swap distributed algorithm large batch training neural networks\n",
            "Predicted Summary>>> propose bayesian batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep architectures point clouds equivariant rotations well translations permutations\n",
            "Predicted Summary>>> propose gans distribution \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sparse mobilenets faster dense ones appropriate kernels\n",
            "Predicted Summary>>> propose mobilenets ones ones \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes method forcing cnns leverage spatial attention learning object centric representations perform better various respects\n",
            "Predicted Summary>>> propose proposes method image image image method image method image method image method image method image image method image image method image method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel training scheme efficiently obtaining order aware sentence representations\n",
            "Predicted Summary>>> propose set gans set set set set gans set set gans set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> higher momentum parameter beta helps escaping saddle points faster\n",
            "Predicted Summary>>> higher method beta beta beta beta beta beta beta beta beta beta beta beta beta beta beta beta beta \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose simple randomization technique improving generalization deep reinforcement learning across tasks various unseen visual patterns\n",
            "Predicted Summary>>> propose method tasks train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> represent entity based histogram contexts wasserstein need\n",
            "Predicted Summary>>> represent memory transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new sparse structured attention mechanism tvmax promotes sparsity encourages weight related adjacent locations\n",
            "Predicted Summary>>> propose matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method introduces empowerment regularized maximum entropy inverse reinforcement learning learn near optimal rewards policies expert demonstrations\n",
            "Predicted Summary>>> propose rl train transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> synthesizing human motions interactive tasks using mocap data hierarchical rl\n",
            "Predicted Summary>>> synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing synthesizing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> comparison detailed analysis various sentence embedding models real world task automatic summarization\n",
            "Predicted Summary>>> propose several method multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use gan based method scalably solve optimal transport\n",
            "Predicted Summary>>> propose method domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non reversible way making accept reject decisions beneficial\n",
            "Predicted Summary>>> propose transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer tasks transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply copula transformation deep information bottleneck leads restored invariance properties disentangled latent space superior predictive capabilities\n",
            "Predicted Summary>>> apply copula tasks bottleneck \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper studies weakly supervised knowledge graph alignment adversarial training frameworks\n",
            "Predicted Summary>>> propose studies transfer learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining auxiliary adversarial training interrogate help physical understanding\n",
            "Predicted Summary>>> auxiliary proposes adversarial interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study introduce novel method relies svd discover number latent dimensions\n",
            "Predicted Summary>>> train train memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> identify memorization inductive bias interpolation overparameterized fully connected convolutional auto encoders\n",
            "Predicted Summary>>> identify proposes impossible tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> derive information bottleneck framework reinforcement learning simple relevant theories tools\n",
            "Predicted Summary>>> derive novel gan gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using saturated cost partitioning select patterns preferable existing pattern selection algorithms\n",
            "Predicted Summary>>> propose saturated cost cost cost cost cost cost cost cost cost cost cost cost cost cost cost \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> simple generative approach solve word analogy problem yields insights word relationships problems estimating\n",
            "Predicted Summary>>> propose new consider \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> knowledge flow trains deep net student injecting information multiple nets teachers student independent upon training performs well learned tasks irrespective setting reinforcement supervised learning\n",
            "Predicted Summary>>> propose rl method trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains trains\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> general framework creating covariant graph neural networks\n",
            "Predicted Summary>>> propose truly \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> label efficient audio classification via multi task learning self supervision\n",
            "Predicted Summary>>> propose proposes efficiency \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neumann networks end end sample efficient learning approach solving linear inverse problems imaging compatible mse optimal approach admit extension patch based learning\n",
            "Predicted Summary>>> neumann end networks sample algorithm algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generates never seen data training desired condition\n",
            "Predicted Summary>>> generates proposes seen seen seen seen seen seen \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> considering neural network optimization process model selection problem introduce biological plausible normalization method extracts statistical regularity mdl principle tackle imbalanced limited data issue\n",
            "Predicted Summary>>> considering considering considering considering considering considering considering considering considering considering considering considering considering considering considering layer layer layer layer layer layer layer layer layer layer layer way layer layer way layer layer way layer layer layer layer layer way layer layer way layer layer way layer way layer layer way layer layer layer layer layer layer layer layer layer layer way layer layer way layer considering layer way layer way layer layer way layer layer way layer way layer way layer way layer layer layer layer layer layer layer way layer way layer layer layer layer layer layer way layer layer layer way layer way layer layer way layer layer way layer way layer layer layer layer layer layer way layer layer layer layer layer layer layer way layer layer layer layer layer layer way layer layer way layer way layer way layer layer layer layer layer layer way layer way layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> recurrent neural networks cybersecurity use cases\n",
            "Predicted Summary>>> propose architecture train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tcn multimodal semi supervised learning ablation study mechanisms interpretations latent representations\n",
            "Predicted Summary>>> paper class encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first text adversarial defense method word level improved generic based attack method synonyms substitution based attacks\n",
            "Predicted Summary>>> first adversarial identifies first first first first adversarial examples \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method incorporates wgan achieve occupancy measure matching transition learning\n",
            "Predicted Summary>>> propose incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates incorporates \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present open loop brain machine interface whose performance unconstrained traditionally used bag words approach\n",
            "Predicted Summary>>> propose novel bottleneck bottleneck bottleneck \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce large scale receipt dataset post ocr parsing tasks\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> attempt model drawing process fonts building sequential generative models vector graphics svgs highly structured representation font characters\n",
            "Predicted Summary>>> attempt drawing drawing maximum \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel structured class blind pruning technique produce highly compressed neural networks\n",
            "Predicted Summary>>> propose asn memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> specific gradient based meta learning algorithm maml equivalent inference procedure hierarchical bayesian model use connection improve maml via methods approximate inference curvature estimation\n",
            "Predicted Summary>>> develop novel transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> oe teaches anomaly detectors learn heuristics detecting unseen anomalies experiments classification density estimation calibration nlp vision settings tune test distribution samples unlike previous work\n",
            "Predicted Summary>>> oe teaches teaches teaches heuristics heuristics \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce class generative models reliably learn hamiltonian dynamics high dimensional observations learnt hamiltonian applied sequence modeling normalising flow\n",
            "Predicted Summary>>> introduce class hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian hamiltonian\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed comprehensive approach unsupervised embedding learning basis algorithm\n",
            "Predicted Summary>>> propose comprehensive generator \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised analysis data recorded peripheral nervous system denoises categorises signals\n",
            "Predicted Summary>>> paper search search search search search search search search search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel structured class blind pruning technique produce highly compressed neural networks\n",
            "Predicted Summary>>> propose asn memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces partial grounding tackle problem arises full grounding process translation pddl input task ground representation like strips infeasible due memory time constraints\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unified min max optimization framework adversarial attack defense\n",
            "Predicted Summary>>> propose min min max max max max max max max max max \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose meta learning framework learns transferable policy weak supervision solve synthesis tasks different logical specifications grammars\n",
            "Predicted Summary>>> work gradient \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new adversarial method adapting neural representations based critic detects non discriminative features\n",
            "Predicted Summary>>> propose rl means \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining ideas traditional algorithms design reinforcement learning introduce novel framework learning algorithms solve online combinatorial optimization problems\n",
            "Predicted Summary>>> solve solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning based algorithms improve upon performance classical algorithms low rank approximation problem retaining worst case guarantee\n",
            "Predicted Summary>>> propose used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> omniglot miniimagenet simple shot learning solve without using labels meta evaluation demonstrated method called centroid networks\n",
            "Predicted Summary>>> omniglot method shot used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep learning network derivatives low rank structure structure allows us use second order derivative information calculate learning rates adaptively computationally feasible manner\n",
            "Predicted Summary>>> propose branch memory noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> enhancing robustness pretrained transformer models lexical overlap bias extending input sentences training data corresponding predicate argument structures\n",
            "Predicted Summary>>> enhancing enhancing method pretrained pretrained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper discusses different methods pairing vo deep learning proposes simultaneous prediction corrections uncertainty\n",
            "Predicted Summary>>> propose provides used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> print input sentence current response sentence onto image use fine tuned imagenet cnn model predict next response word\n",
            "Predicted Summary>>> propose proposes strategies strategies strategies strategies strategies strategies strategies strategies strategies \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> wasserstein autoencoder hyperbolic latent space\n",
            "Predicted Summary>>> propose autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder autoencoder\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve specific sr issue low quality jpg images functional sub models\n",
            "Predicted Summary>>> propose rl sr search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose special weakly supervised multi label learning problem along newly tailored algorithm learns underlying classifier learning assign pseudo labels\n",
            "Predicted Summary>>> propose special \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show shortcut connections placed patterns minimize layer distances backpropagation design networks achieve log distances using log connections\n",
            "Predicted Summary>>> propose shortcut shortcut shortcut backpropagation distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances distances\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show exposure bias could much less serious currently assumed mle lm training\n",
            "Predicted Summary>>> novel exposure could set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new model making generalizable diverse retrosynthetic reaction predictions\n",
            "Predicted Summary>>> propose text text text text text text transfer text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> graph neural network able automatically learn leverage dynamic interactive graph structure\n",
            "Predicted Summary>>> propose adaptive tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural architecture search series natural language understanding tasks design search space nlu tasks apply differentiable architecture search discover new models\n",
            "Predicted Summary>>> propose aims method architecture \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aim improve upon mcmc vi novel hybrid method based idea reducing simulation bias finite length mcmc chains using gradient based optimisation\n",
            "Predicted Summary>>> aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> wave net architecture recently introduced stoller et al music source separation highly effective speech enhancement beating state art\n",
            "Predicted Summary>>> used used used used used tasks used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used tasks used tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improving label efficiency multi task learning auditory data\n",
            "Predicted Summary>>> propose proposes use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extension gans combining optimal transport primal form energy distance defined adversarially learned feature space\n",
            "Predicted Summary>>> extension extension combining optimal feature optimal feature optimal feature optimal feature optimal feature optimal feature \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate large pruned models large sparse outperform smaller dense small dense counterparts identical memory footprint\n",
            "Predicted Summary>>> propose large large layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> weakly supervised text based video moment retrieval\n",
            "Predicted Summary>>> propose search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search text search text search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed nesterov iterative fast gradient sign method ni fgsm scale invariant attack method sim boost transferability adversarial examples image classification\n",
            "Predicted Summary>>> propose nesterov \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel network called recurrent identity network rin allows plain recurrent network overcome vanishing gradient problem training deep models without use gates\n",
            "Predicted Summary>>> propose recurrent tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose approach learn sparse high dimensional representations fast search incorporating surrogate number operations directly loss function\n",
            "Predicted Summary>>> propose use new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep boosting algorithm developed learn discriminative ensemble classifier seamlessly combining set base deep cnns\n",
            "Predicted Summary>>> deep method algorithm tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose alternative measure determining effectiveness adversarial attacks nlp models according distance measure based method like incremental gain control theory\n",
            "Predicted Summary>>> present alternative measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure measure\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural logic machine nlm neural symbolic architecture inductive learning logic reasoning\n",
            "Predicted Summary>>> propose proposes logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural architecture search series natural language understanding tasks design search space nlu tasks apply differentiable architecture search discover new models\n",
            "Predicted Summary>>> propose aims architecture method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose stochastic differentiable forward dynamics predictor able sample multiple physically plausible trajectories initial input state show used train model free policies efficiently\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training dnns interface black box functions intermediate labels using estimator sub network replaced black box training\n",
            "Predicted Summary>>> propose rl training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces partial grounding tackle problem arises full grounding process translation pddl input task ground representation like strips infeasible due memory time constraints\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train natural media painting agent using environment model based painting agent present novel approach train constrained painting agent follows command encoded observation\n",
            "Predicted Summary>>> train natural train train natural train natural train natural train train natural train natural train natural train natural train natural train natural train tasks train tasks natural tasks natural train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> strokenet novel architecture agent trained draw strokes differentiable simulation environment could effectively exploit power back propagation\n",
            "Predicted Summary>>> strokenet domain architecture trained domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient lifelong learning algorithm provides better trade accuracy time memory complexity compared algorithms\n",
            "Predicted Summary>>> propose lifelong lifelong lifelong lifelong lifelong tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> redistributing growing weights according momentum magnitude enables training sparse networks random initializations reach dense performance levels weights accelerating training\n",
            "Predicted Summary>>> propose momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> topology based graph convolutional network gcn\n",
            "Predicted Summary>>> topology object topology object topology \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present attribution technique leveraging sparsity inducing norms achieve interpretability\n",
            "Predicted Summary>>> train sparsity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> domain adaptation method structured output via learning patch level discriminative feature representations\n",
            "Predicted Summary>>> propose domain adaptation domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose dual actor critic algorithm derived principled way lagrangian dual form bellman optimality equation algorithm achieves state art performances across several benchmarks\n",
            "Predicted Summary>>> propose theoretical used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> identify prototypical outlier examples machine learning quantifiably different make use improve many aspects neural networks\n",
            "Predicted Summary>>> identify prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proves universal approximability quantized relu neural networks puts forward complexity bound given arbitrary error\n",
            "Predicted Summary>>> paper analyze tasks deep networks privacy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> make theoretical justification concept straight estimator\n",
            "Predicted Summary>>> theoretical concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> contrary previous beliefs training performance deep networks measured appropriately predictive test performance consistent classical machine learning theory\n",
            "Predicted Summary>>> contrary rl method training beliefs training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose model variational autoencoders text modeling without weakening decoder improves quality text generation interpretability acquired representations\n",
            "Predicted Summary>>> propose theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> practical adaptive algorithms gradient based meta learning provable guarantees\n",
            "Predicted Summary>>> use proposes set recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed system prevent impersonators facial disguises completing fraudulent transaction using pre trained dcnn\n",
            "Predicted Summary>>> introduce novel impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generalized bert continuous cross modal inputs state art self supervised video representations\n",
            "Predicted Summary>>> generalized train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using branched attention learned combination weights outperforms baseline transformer machine translation tasks\n",
            "Predicted Summary>>> propose branched method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> recurrent neural network cell extended long short term memory multi task rnn model sequence sequence problems\n",
            "Predicted Summary>>> propose provides trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> oe teaches anomaly detectors learn heuristics detecting unseen anomalies experiments classification density estimation calibration nlp vision settings tune test distribution samples unlike previous work\n",
            "Predicted Summary>>> oe teaches heuristics heuristics heuristics heuristics \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn dense vector representations arbitrary types features labeled unlabeled datasets\n",
            "Predicted Summary>>> method labeled labeled labeled dense labeled labeled dense labeled dense labeled dense labeled labeled labeled dense labeled labeled dense labeled dense labeled labeled labeled dense labeled dense labeled dense labeled dense labeled labeled dense labeled labeled dense labeled dense labeled dense labeled dense labeled labeled labeled dense labeled labeled labeled dense labeled labeled dense labeled labeled labeled dense labeled labeled labeled labeled dense labeled labeled dense labeled dense labeled dense labeled labeled dense labeled dense labeled dense labeled dense labeled labeled labeled dense labeled dense labeled labeled labeled \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents method explain knowledge encoded convolutional neural network cnn quantitatively semantically\n",
            "Predicted Summary>>> paper proposes novel features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed sesamebert generalized fine tuning method enables extraction global information among layers squeeze excitation enriches local information capturing neighboring contexts via gaussian blurring\n",
            "Predicted Summary>>> propose sesamebert tuning tuning tuning tuning tuning tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improving deep transfer learning regularization using attention based feature maps\n",
            "Predicted Summary>>> use proposes noise noise noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adapt family combinatorial games tunable difficulty optimal policy expressible linear network developing rich environment reinforcement learning showing contrasts performance supervised learning analyzing multiagent learning generalization\n",
            "Predicted Summary>>> propose combinatorial combinatorial combinatorial combinatorial combinatorial combinatorial combinatorial \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use mixture density networks full conditional density estimation spatial offset regression apply human pose estimation task\n",
            "Predicted Summary>>> propose proposes regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression regression\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new model making generalizable diverse retrosynthetic reaction predictions\n",
            "Predicted Summary>>> propose text method text text text text text text text text text text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel rnn model outperforms significantly current frontier models variety sequential tasks\n",
            "Predicted Summary>>> method tasks transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new class inference models iteratively encode gradients estimate approximate posterior distributions\n",
            "Predicted Summary>>> propose augmented memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce online explanation consider cognitive requirement human understanding generated explanation agent\n",
            "Predicted Summary>>> propose proposes online \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed unified generative adversarial networks gan framework learn noise aware knowledge graph embedding\n",
            "Predicted Summary>>> propose tuning data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient video classification using frame based conditional gating module selecting dominant frames followed temporal modeling classifier\n",
            "Predicted Summary>>> propose search used used search used search used search used search used used search used search used used search used search used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used based used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> data driven learning algorithm based unrolling alternating minimization optimization sparse graph recovery\n",
            "Predicted Summary>>> propose minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing networks minimizing minimizing minimizing minimizing minimizing minimizing minimizing human human human \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parametric manifold learning neural networks geometric framework\n",
            "Predicted Summary>>> propose use networks model \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> ensuring models learned federated fashion reveal client participation\n",
            "Predicted Summary>>> ensuring autonomous learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned policy learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> optimization algorithm explores various batch sizes based probability automatically exploits successful batch size minimizes validation loss\n",
            "Predicted Summary>>> propose method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents dynamic evaluation methodology adaptive sequence modelling\n",
            "Predicted Summary>>> develop used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new state art imagenet mobile setting\n",
            "Predicted Summary>>> propose statistical statistical statistical statistical well well well statistical well well statistical well well well statistical well well statistical well well well well statistical well statistical well well well well well well well well statistical well statistical well well well statistical well statistical well statistical well well well well well statistical well well well statistical well statistical well statistical well well well well well well well well well statistical well statistical well well well statistical well well well well well well well statistical well well well statistical well well statistical well well well well well well well well well well statistical well well statistical well well well well statistical well well statistical well well well statistical well statistical well statistical well well statistical well well well well statistical well well well well well statistical well well well well well statistical well well statistical well well statistical well statistical well well well statistical well well well well statistical well well well well well well well statistical well statistical well well well statistical well well well well well well well well well statistical well well statistical well statistical well well well well statistical well well well well statistical well well well statistical well statistical well statistical well well well well well statistical well statistical well statistical well well well well well well well well well statistical well statistical well statistical well well well well statistical well well well well well statistical well well well well well statistical well well well well well well well well statistical well well well\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show autoregressive flows used improve sequential latent variable models\n",
            "Predicted Summary>>> propose extension tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new adversarial method adapting neural representations based critic detects non discriminative features\n",
            "Predicted Summary>>> propose rl transfer means tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop vaes encoder takes model parameter vector input rapid inference many models\n",
            "Predicted Summary>>> propose vaes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes new objective function replace kl term one emulates maximum mean discrepancy mmd objective\n",
            "Predicted Summary>>> propose proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show exposure bias could much less serious currently assumed mle lm training\n",
            "Predicted Summary>>> novel exposure could set exposure set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> filter level sparsity emerges implicitly cnns trained adaptive gradient descent approaches due various phenomena extent sparsity inadvertently affected different seemingly unrelated hyperparameters\n",
            "Predicted Summary>>> empirical sparsity sparsity sparsity sparsity sparsity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unified min max optimization framework adversarial attack defense\n",
            "Predicted Summary>>> propose min min max max max max max max max max \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents scalable solution continuous visual speech recognition\n",
            "Predicted Summary>>> propose presents continuous transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose expansion based approach task free continual learning first time model consists set neural network experts expands number experts bayesian nonparametric principle\n",
            "Predicted Summary>>> propose expansion free feature \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop simple general approach avoiding interference gradients different tasks improves performance multi task learning supervised reinforcement learning domains\n",
            "Predicted Summary>>> develop novel method general \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose generative neural network approach temporally coherent point clouds\n",
            "Predicted Summary>>> propose used search used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> models representation learning dynamic graphs latent hidden process bridging two observed processes topological evolution interactions dynamic graphs\n",
            "Predicted Summary>>> propose first training used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study multi layer generalization magnitude based pruning\n",
            "Predicted Summary>>> propose rl layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> look negative transfer domain adaptation point view derive adversarial learning algorithm\n",
            "Predicted Summary>>> look transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> coupling semi supervised learning self supervised learning explicitly modeling self supervised task conditioned semi supervised one\n",
            "Predicted Summary>>> coupling bayesian semi \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> implementing evaluating episodic memory rl\n",
            "Predicted Summary>>> implementing clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering used clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering clustering\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> programs structure represented graphs graph neural networks learn find bugs graphs\n",
            "Predicted Summary>>> programs novel structure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> accelerate secure dnn inference trusted execution environments factor selectively outsourcing computation linear layers faster yet untrusted co processor\n",
            "Predicted Summary>>> accelerate reward tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper describes strategic intrinsically motivated learning algorithm tackles learning complex motor policies\n",
            "Predicted Summary>>> train describes describes describes transfer noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce nlprolog system performs rule based reasoning natural language leveraging pretrained sentence embeddings fine tuning evolution strategies apply two multi hop question answering tasks\n",
            "Predicted Summary>>> propose method models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel multi task framework learns table detection semantic component recognition cell type classification spreadsheet tables promising results\n",
            "Predicted Summary>>> propose new transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarial examples fool youtube copyright detection system\n",
            "Predicted Summary>>> propose adversarial step youtube \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep learning network derivatives low rank structure structure allows us use second order derivative information calculate learning rates adaptively computationally feasible manner\n",
            "Predicted Summary>>> propose branch memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> formal verification specification model prediction undersensitivity using interval bound propagation\n",
            "Predicted Summary>>> formal verification specification \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> regularizing optimization trajectory fisher information old tasks reduces catastrophic forgetting greatly\n",
            "Predicted Summary>>> regularizing trajectory fisher fisher fisher fisher fisher fisher fisher fisher fisher fisher fisher fisher fisher fisher \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve training stability semi supervised generative adversarial networks collaborative training\n",
            "Predicted Summary>>> propose rl transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce new memory architecture navigation previously unseen environments inspired landmark based navigation animals\n",
            "Predicted Summary>>> introduce memory memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method inferring model estimating entropy rate predicting continuous time discrete event processes\n",
            "Predicted Summary>>> propose proposes entropy entropy inferring \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> distill language models representations syntax unsupervised metric learning\n",
            "Predicted Summary>>> propose distill tasks task tasks task tasks task tasks task tasks task tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose convolutional tensor train lstm learns higher order convolutional lstm efficiently using convolutional tensor train decomposition\n",
            "Predicted Summary>>> propose adaptive generalized order order order \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> omniglot miniimagenet simple shot learning solve without using labels meta evaluation demonstrated method called centroid networks\n",
            "Predicted Summary>>> omniglot method shot used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> see abstract revision paper identical except page supplementary material serve stand along technical report version paper\n",
            "Predicted Summary>>> see abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose differentiable architecture search algorithm convolutional recurrent networks achieving competitive performance state art using orders magnitude less computation resources\n",
            "Predicted Summary>>> propose search memory uses search method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> asal pool based active learning method generates high entropy samples retrieves matching samples pool sub linear time\n",
            "Predicted Summary>>> propose active entropy samples \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parametrization width seems help deep reinforcement learning supervised learning\n",
            "Predicted Summary>>> propose new used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present first verification neural network perception tasks produces correct output within specified tolerance every input interest\n",
            "Predicted Summary>>> propose verification neural perception networks perception \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel manifold regularization strategy based adversarial training significantly improve performance semi supervised learning\n",
            "Predicted Summary>>> propose use networks brain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn lstm generate markup like code describing graphical user interface images\n",
            "Predicted Summary>>> cnn lstm lstm lstm lstm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> differentiable multi hop access textual knowledge base indexed contextual representations\n",
            "Predicted Summary>>> use used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable differentiable neural module implements reasoning symbolic kbs\n",
            "Predicted Summary>>> propose scalable differentiable method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> federated averaging already meta learning algorithm datacenter trained methods significantly harder personalize\n",
            "Predicted Summary>>> propose averaging transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dynamically generate filters conditioned input image cnns forward pass\n",
            "Predicted Summary>>> dynamically method used conditioned conditioned transfer used conditioned \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> ensuring models learned federated fashion reveal client participation\n",
            "Predicted Summary>>> ensuring policy learned learned learned learned learned learned policy learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose differentially private laplacian smoothing stochastic gradient descent train machine learning models better utility maintain differential privacy guarantees\n",
            "Predicted Summary>>> paper differentially private models private \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aims provide quantitative answers relative importance concepts interest via concept activation vectors cav particular framework enables non machine learning experts express concepts interest test hypotheses using examples set pictures illustrate concept show cav learned given relatively small set examples hypothesis testing cav answer whether particular concept gender important predicting given class doctor sets concepts interpreting networks cav require retraining modification network\n",
            "Predicted Summary>>> train theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> case study optimal deep learning model uavs\n",
            "Predicted Summary>>> oe teaches heuristics \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine hard handcrafted constraints deep prior weak constraint perform seismic imaging reap information posterior distribution leveraging multiplicity data\n",
            "Predicted Summary>>> combine posterior handcrafted \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compositional attribute based planning generalizes long test tasks despite trained short simple tasks\n",
            "Predicted Summary>>> propose attribute tasks attribute tasks tasks attribute tasks attribute tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tcn multimodal semi supervised learning ablation study mechanisms interpretations latent representations\n",
            "Predicted Summary>>> paper class domain encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder tasks encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach curriculum learning incrementally learning labels adaptively smoothing labels mis classified samples boost average performance decreases standard deviation\n",
            "Predicted Summary>>> propose active incrementally incrementally \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarially trained hierarchical generative model robust semantically learned latent representation\n",
            "Predicted Summary>>> adversarially adversarially trained used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn quantize speech signal apply algorithms requiring discrete inputs audio data bert\n",
            "Predicted Summary>>> propose quantize variational algorithm algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose macer provable defense algorithm trains robust models maximizing certified radius use adversarial training performs better existing provable defenses\n",
            "Predicted Summary>>> propose macer represent class represent class represent class represent class represent tasks represent set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model based meta rl algorithm enables real robot adapt online dynamic environments\n",
            "Predicted Summary>>> prove gans domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using dsl grammar reinforcement learning improve synthesis programs complex control flow\n",
            "Predicted Summary>>> good dsl algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel adversarial learning framework structured prediction discriminative models used refine structured prediction models inference stage\n",
            "Predicted Summary>>> unsupervised proposes unsupervised used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose new encoder decoder model based tensor product representations natural formal language generation called tp\n",
            "Predicted Summary>>> propose novel memory variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> trellis networks new sequence modeling architecture bridges recurrent convolutional models sets new state art word character level language modeling\n",
            "Predicted Summary>>> propose recurrent architecture recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> wave net architecture recently introduced stoller et al music source separation highly effective speech enhancement beating state art\n",
            "Predicted Summary>>> used used used used used used used used used tasks used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel algorithm solving reinforcement learning bandit structured prediction problems sparse loss feedback\n",
            "Predicted Summary>>> propose studies encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce method computing intrinsic reward curiosity using metrics derived sampling latent variable model used estimate dynamics\n",
            "Predicted Summary>>> propose rl used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generalized transformation based gradient model variational inference\n",
            "Predicted Summary>>> propose transformation transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> self attention layer perform convolution often learns practice\n",
            "Predicted Summary>>> represent proposes end frames \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze gradient propagation deep rnns analysis propose new multi layer deep rnn\n",
            "Predicted Summary>>> propose sparsity trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose adversarial inverse reinforcement learning algorithm capable learning reward functions transfer new unseen environments\n",
            "Predicted Summary>>> propose inverse solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> construct kronecker factored laplace approximation neural networks leads efficient matrix normal distribution weights\n",
            "Predicted Summary>>> propose kronecker kronecker kronecker factored \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem alleviating instability issue gan training procedure via new architecture design theoretical guarantees\n",
            "Predicted Summary>>> goal instability \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parameters trained neural network permuted produce completely separate model different task enabling embedding trojan horse networks inside another network\n",
            "Predicted Summary>>> propose method sample architectures \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> robust bayesian deep learning algorithm infer complex posteriors latent variables\n",
            "Predicted Summary>>> propose adversarial bayesian \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show posterior collapse linear vaes caused entirely marginal log likelihood elbo experiments deep vaes suggest similar phenomenon play\n",
            "Predicted Summary>>> propose new used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> effective regularization optimization strategies lstm based language models achieves sota ptb wt\n",
            "Predicted Summary>>> propose strategies regularization strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel autoencoding model augmented adversarial reconstruction loss intoduce new metric content based assessment reconstructions\n",
            "Predicted Summary>>> propose new optimization autoencoding optimization autoencoding optimization autoencoding optimization algorithm optimization autoencoding optimization autoencoding optimization autoencoding optimization algorithm optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization algorithm optimization algorithm optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding algorithm optimization autoencoding optimization autoencoding optimization autoencoding optimization autoencoding optimization algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> spatial information last layers necessary good classification accuracy\n",
            "Predicted Summary>>> propose rl last last last last last last last layers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first text adversarial defense method word level improved generic based attack method synonyms substitution based attacks\n",
            "Predicted Summary>>> first adversarial identifies examples \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes use spectral element methods fast accurate training neural ordinary differential equations system identification\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> stable domain adversarial training approach robust comprehensive domain adaptation\n",
            "Predicted Summary>>> propose domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> integrative tensor based anomaly detection itad framework satellite system\n",
            "Predicted Summary>>> explored proposes adversarial trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate recurrent neural network successfully learns task combining long term memory sequential recall\n",
            "Predicted Summary>>> introduce proposes memory train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique automatically labeling large unlabeled datasets train source models transfer learning experimental evaluation\n",
            "Predicted Summary>>> propose augmented transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> spoken term detection using structured prediction deep networks implementing new loss function maximizes auc ranks according predefined threshold\n",
            "Predicted Summary>>> propose search propose search global search gan search behavior \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper formalises problem online algorithm selection context reinforcement learning\n",
            "Predicted Summary>>> propose formalises semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces neuromodulation artificial neural networks\n",
            "Predicted Summary>>> paper deep neuromodulation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> applying program synthesis tasks image completion generation within deep learning framework\n",
            "Predicted Summary>>> applying tasks completion tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel approach solve data driven model based optimization problems passive active settings scale high dimensional input spaces\n",
            "Predicted Summary>>> propose architecture method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> toy dataset based critical percolation planar graph provides analytical window training dynamics deep neural networks\n",
            "Predicted Summary>>> toy proposes deep percolation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarially trained hierarchical generative model robust semantically learned latent representation\n",
            "Predicted Summary>>> adversarially trained used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> stochastic variational video prediction real world settings\n",
            "Predicted Summary>>> propose novel video set real techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce analyze phenomenon hallucinations nmt spurious translations unrelated source text propose methods reduce frequency\n",
            "Predicted Summary>>> propose eliminates phenomenon \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposal strategies adversarial defense based data dependent activation function total variation minimization training data augmentation\n",
            "Predicted Summary>>> propose toward networks train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approach improving prediction accuracy learning deep features neighboring scene images satellite scene image analysis\n",
            "Predicted Summary>>> unsupervised proposes task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task task unsupervised \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel unified architecture restores video frames single motion blurred image end end manner\n",
            "Predicted Summary>>> unified proposes navigation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theory connecting hessian solution generalization power model\n",
            "Predicted Summary>>> propose connecting connecting connecting connecting connecting connecting connecting system system system system system system system system \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> feedforward layer incorporate structured smoothness deep learning model\n",
            "Predicted Summary>>> propose new used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method learning image representations good disentangling factors variation obtaining faithful reconstructions\n",
            "Predicted Summary>>> propose alternative adversarial representations tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present improved version universal successor features based drl method improve transfer learning agents\n",
            "Predicted Summary>>> propose version method version \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose latent question reformulation network lqr net multi hop parallel attentive network designed question answering tasks require reasoning capabilities\n",
            "Predicted Summary>>> propose rl method lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr lqr\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> derive new pac bayesian bound unbounded loss functions negative log likelihood\n",
            "Predicted Summary>>> propose used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new algorithm training neural networks compares favorably popular adaptive methods\n",
            "Predicted Summary>>> propose proposes matching \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present lsh softmax softmax approximation layer sub linear learning inference strong theoretical guarantees showcase applicability efficiency evaluating real world task language modeling\n",
            "Predicted Summary>>> propose proposes nlp layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarial attacks unsupervised node embeddings based eigenvalue perturbation theory\n",
            "Predicted Summary>>> propose sparsity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactive technique improve brushing dense trajectory datasets taking account shape brush\n",
            "Predicted Summary>>> interactive brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose generic framework allows exploiting low rank structure planning deep reinforcement learning\n",
            "Predicted Summary>>> propose generic generic algorithm layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> context adaptive entropy model use end end optimized image compression significantly improves compression performance\n",
            "Predicted Summary>>> investigate adaptive optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present method adapting hyperparameters probabilistic models using optimal transport applications robotics\n",
            "Predicted Summary>>> present method transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn model pruning method using ista rescaling trick enforce sparsity scaling parameters batch normalization\n",
            "Predicted Summary>>> cnn pruning pruning pruning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extracting finite state machine recurrent neural network via quantization purpose interpretability experiments atari\n",
            "Predicted Summary>>> propose sparsity sparsity solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired capsnet propose novel architecture graph embeddings basis node features extracted gnn\n",
            "Predicted Summary>>> use capsnet transfer tasks transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using gans priors efficient bayesian inference complex fields\n",
            "Predicted Summary>>> propose bayesian fields fields fields fields fields \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method manipulate given images using natural language descriptions\n",
            "Predicted Summary>>> propose first trained trained first first first trained first first trained first first trained first first trained first trained first first trained first trained first trained first trained first trained trained first first trained first trained trained trained first first trained trained first trained trained trained first trained first trained trained first trained trained first first trained first trained first trained trained trained first trained first first trained first trained trained first first trained first first trained first trained trained trained first trained trained first trained first first trained first trained first trained trained trained first trained trained trained first first trained first trained first trained first first first first first trained first trained first trained first trained trained trained first trained trained trained first trained trained trained trained first trained trained first first trained first trained trained first trained first trained first first trained first trained trained trained trained first first first trained trained first trained trained first first trained first first trained trained trained first first trained trained first trained trained first first trained first first first trained trained first trained first trained first trained trained first first first trained trained trained first trained trained first trained first first first first trained trained trained first trained first trained trained first first trained trained first first trained first first first trained first first trained first trained first trained first trained trained trained first first trained first first trained first trained trained first trained trained first first trained trained trained first first trained first trained trained first\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train gans differential privacy generate artificial privacy preserving datasets\n",
            "Predicted Summary>>> use use privacy privacy privacy privacy privacy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide pac bayes based generalization guarantee uncompressed deterministic deep networks generalizing noise resilience network training data test data\n",
            "Predicted Summary>>> provide defensive gans training test \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show exposure bias could much less serious currently assumed mle lm training\n",
            "Predicted Summary>>> novel exposure could set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present state space lstm models combination state space models lstms propose inference algorithm based sequential monte carlo\n",
            "Predicted Summary>>> propose proposes transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> built physical simulation rodent trained solve set tasks analyzed resulting networks\n",
            "Predicted Summary>>> propose first physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> framework studying emergent communication networked multi agent reinforcement learning setup\n",
            "Predicted Summary>>> propose studying networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked networked \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> decoding pixels still work representation learning images\n",
            "Predicted Summary>>> decoding pixels pixels pixels pixels pixels \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sequence model dynamically adjusts amount computation input\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce dcn deep residual coattention mixed objective rl achieves state art performance stanford question answering dataset\n",
            "Predicted Summary>>> propose provides \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> coupling semi supervised learning self supervised learning explicitly modeling self supervised task conditioned semi supervised one\n",
            "Predicted Summary>>> coupling bayesian semi \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method efficient multi objective neural architecture search based lamarckian inheritance evolutionary algorithms\n",
            "Predicted Summary>>> propose rl heuristics search semi \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> causally correct partial models generate whole observation remain causally correct stochastic environments\n",
            "Predicted Summary>>> causally provides learning provides \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sample efficient algorithms adapt text speech model new voice style state art performance\n",
            "Predicted Summary>>> propose computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational computational\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> batch normalization reduces adversarial robustness well general robustness many cases particularly noise corruptions\n",
            "Predicted Summary>>> propose novel robustness \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> isolate one factor rl generalization analyzing case agent overfits observations show architectural implicit regularizations occur regime\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new form attention works well distant supervision setting multitask learning approach add sentence level annotations\n",
            "Predicted Summary>>> adding form well tasks well set well set well set well set well set well set well set well set well set well set well set well well well well well well well set well well set well set well set well set well set well set well set well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well set well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explore problem compositional generalization propose means endowing neural network architectures ability compose solve problems\n",
            "Predicted Summary>>> propose problem means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means means \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve reconstruction time quality experimental mask based lensless imager using end end learning approach incorporates knowledge imaging model\n",
            "Predicted Summary>>> paper method architecture mask \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper formalises problem online algorithm selection context reinforcement learning\n",
            "Predicted Summary>>> propose formalises semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi semi\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show gradients unable capture shifts saliency due adversarial perturbations present alternative adversarial defense using learnt saliency models effective black box white box attacks\n",
            "Predicted Summary>>> propose alternative used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> knowledge first study show neural representations space including grid like cells border cells observed brain could emerge training recurrent neural network perform navigation tasks\n",
            "Predicted Summary>>> propose first cells cells cells cells cells cells cells cells representations cells cells cells cells cells cells \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural net graph based semi supervised learning revisits classics propagates labels rather feature representations\n",
            "Predicted Summary>>> propose net algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train neural network agents develop language compositional properties raw pixel input\n",
            "Predicted Summary>>> train properties \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents defogger model learns predict future hidden information partial observations applied starcraft dataset\n",
            "Predicted Summary>>> propose presents policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces cloudlstm new branch recurrent neural models tailored forecasting data streams generated geospatial point cloud sources\n",
            "Predicted Summary>>> propose cloudlstm recurrent networks cloudlstm cloudlstm cloudlstm recurrent cloudlstm recurrent cloudlstm recurrent cloudlstm cloudlstm cloudlstm recurrent cloudlstm recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> joint method learning cross lingual embeddings state art performance cross lingual tasks mono lingual quality\n",
            "Predicted Summary>>> unified proposes unified \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> attempt model drawing process fonts building sequential generative models vector graphics svgs highly structured representation font characters\n",
            "Predicted Summary>>> attempt method drawing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> probing robustness redundancy deep neural networks reveals capacity constraining features help explain non overfitting\n",
            "Predicted Summary>>> paper novel structure networks level \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find movement function space proportional movement parameter space optimization propose new natural gradient style optimizer address\n",
            "Predicted Summary>>> find movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce isrlu activation function continuously differentiable faster elu related isru replaces tanh sigmoid\n",
            "Predicted Summary>>> propose isrlu used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used tasks used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> employ linear homomorphic compression schemes represent sufficient statistics conditional random field model coreference allows us scale inference improve speed order magnitude\n",
            "Predicted Summary>>> employ introduces represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> create unbiased estimator log probability latent variable models extending models larger scope applications\n",
            "Predicted Summary>>> create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create log create\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative model temporal data builds online belief state operates latent space jumpy predictions rollouts states\n",
            "Predicted Summary>>> propose method online \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce stochastic training method training binary neural network binary weights activations\n",
            "Predicted Summary>>> propose analyze networks solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> practical adaptive algorithms gradient based meta learning provable guarantees\n",
            "Predicted Summary>>> use proposes set recurrent set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> suggest smart batch selection technique called ada boundary\n",
            "Predicted Summary>>> suggest smart used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> short paper briefly introduce advantages using ai planning cloud migration preliminary prototype well chal lenges requires attention planning schedul ing society\n",
            "Predicted Summary>>> paper briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly briefly\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning label representation deep networks\n",
            "Predicted Summary>>> propose general transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> design incremental sequence action parsers text sql task achieve sota results improve using non deterministic oracles allow multiple correct action sequences\n",
            "Predicted Summary>>> design sequence networks action method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study natural emergence sparsity activations gradients layers dense lstm language model course training\n",
            "Predicted Summary>>> propose sparsity emergence emergence emergence tasks emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence emergence \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> distilling single task models multi task model improves natural language understanding performance\n",
            "Predicted Summary>>> propose ill method tasks trainable tasks tasks tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable tasks trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use sparsity improve computational complexity variance reduction methods\n",
            "Predicted Summary>>> propose proposes computational computational computational set computational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> considering neural network optimization process model selection problem introduce biological plausible normalization method extracts statistical regularity mdl principle tackle imbalanced limited data issue\n",
            "Predicted Summary>>> considering considering considering considering considering considering considering considering layer layer layer way layer layer layer layer layer layer layer layer way layer way layer layer layer way layer layer way layer layer layer layer layer layer layer layer way layer way layer layer layer layer layer way layer layer layer layer layer way layer layer way layer way layer layer layer layer layer layer layer layer layer layer layer layer way layer layer layer layer layer way layer layer layer layer way layer way layer layer layer layer layer layer way layer layer way layer considering layer way layer layer layer layer layer way layer way layer layer layer layer way layer layer layer way layer layer layer way layer layer layer layer layer layer layer considering layer layer layer layer way layer way layer layer layer way layer layer layer way layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> instead learning parameters graphical model data learn inference network answer probabilistic queries\n",
            "Predicted Summary>>> propose problem tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform counting visual question answering model produces interpretable outputs counting directly detected objects\n",
            "Predicted Summary>>> counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unify extended kalman filter ekf state space approach power expectation propagation pep solving intractable moment matching integrals pep via linearisation leads globally iterated extension ekf\n",
            "Predicted Summary>>> solve solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe biologically plausible learning algorithm fixed point recurrent networks without tied weights\n",
            "Predicted Summary>>> propose plausible space \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural networks trained modify connectivity improving online learning performance challenging tasks\n",
            "Predicted Summary>>> propose analyze analyze analyze analyze analyze networks functions functions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present agent uses beta vae extract visual features attention mechanism ignore irrelevant features visual observations enable robust transfer visual domains\n",
            "Predicted Summary>>> operations proposes models sgd \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use dynamic rewards train event extractors\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> view exploration rl problem matching marginal distribution states\n",
            "Predicted Summary>>> propose proposes training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> argumentation frameworks used represent causality plans models utilized explanations\n",
            "Predicted Summary>>> argumentation used used used represent used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel architecture shot classification capable dealing uncertainty\n",
            "Predicted Summary>>> propose proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> suggest sufficient number bits representing weights dnns optimum bits conservative solving real problems\n",
            "Predicted Summary>>> propose sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient sufficient \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> ideas future ickeps\n",
            "Predicted Summary>>> ideas future ickeps \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use empirical tools mode connectivity svcca investigate neural network training heuristics learning rate restarts warmup knowledge distillation\n",
            "Predicted Summary>>> investigate svcca svcca \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem learning optimizing physical simulations via differentiable programming using proposed diffsim programming language compiler\n",
            "Predicted Summary>>> propose problem train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new simple dynamic system introduced generates pretty patterns properties proved possibilities explored\n",
            "Predicted Summary>>> propose variants domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> quantum inspired kernel convolution network exhibiting interference phenomena useful compared real value counterpart\n",
            "Predicted Summary>>> inspired cnn inspired inspired inspired exhibiting exhibiting exhibiting exhibiting exhibiting exhibiting exhibiting exhibiting exhibiting exhibiting inspired \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel deep network architecture dynamically decide network capacity trains lifelong learning scenario\n",
            "Predicted Summary>>> propose optimisation generator search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduced novel simple efficient data augmentation method boosts performances existing gans training data limited diverse\n",
            "Predicted Summary>>> introduced novel search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> large scale multi task architecture solves imagenet translation together shows transfer learning\n",
            "Predicted Summary>>> propose tasks multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose learning transfer learn tl improve transfer learning target dataset judicious extraction information source dataset\n",
            "Predicted Summary>>> propose memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explored novel method compositional set embeddings perceive represent single class entire set classes associated input data\n",
            "Predicted Summary>>> explored presents gans end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new combination evolution strategy deep reinforcement learning takes best worlds\n",
            "Predicted Summary>>> propose proposes solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical study provides novel perspective shot learning fine tuning method shows comparable accuracy complex state art methods several classification tasks\n",
            "Predicted Summary>>> gan gan used maximum gan maximum \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show minimizing cross entropy loss using gradient method could lead poor margin features dataset lie low dimensional subspace\n",
            "Predicted Summary>>> propose minimizing dataset entropy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose expansion based approach task free continual learning first time model consists set neural network experts expands number experts bayesian nonparametric principle\n",
            "Predicted Summary>>> propose expansion feature feature feature learned learned \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose hypothesis gradient descent generalizes based per example gradients interact\n",
            "Predicted Summary>>> unsupervised hypothesis augment unsupervised per \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> self attention layer perform convolution often learns practice\n",
            "Predicted Summary>>> represent proposes end frames frames represent end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual ebm text whose formulation equivalent discriminating human machine generated text study generalization behavior\n",
            "Predicted Summary>>> residual ebm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> developed search framework consistency penalty mitigate delusional bias\n",
            "Predicted Summary>>> developed rl rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> large batch size training using adversarial training second order information\n",
            "Predicted Summary>>> propose proposes batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> humans loop revise documents accord counterfactual labels resulting resource helps reduce reliance spurious associations\n",
            "Predicted Summary>>> humans loop layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine search reinforcement learning speed machine learning code\n",
            "Predicted Summary>>> identify search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe neuro ai interface technique evaluate generative adversarial networks\n",
            "Predicted Summary>>> describe neuro neuro neuro neuro neuro neuro neuro neuro neuro \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present generative model compositional word embeddings captures syntactic relations provide empirical verification evaluation\n",
            "Predicted Summary>>> propose method domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extend state art technique directly incorporate flops part optimization objective show given desired flops requirement different neural networks successfully trained\n",
            "Predicted Summary>>> extend proposes domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper provides full characterization permutation invariant equivariant linear layers graph data\n",
            "Predicted Summary>>> unsupervised provides provides provides provides provides provides characterization provides characterization characterization characterization provides characterization characterization provides characterization characterization provides characterization provides characterization provides provides provides characterization provides characterization provides characterization provides characterization provides characterization provides characterization provides characterization provides characterization characterization provides characterization provides characterization provides characterization characterization provides characterization provides characterization characterization provides characterization provides provides characterization characterization provides provides characterization provides characterization provides characterization provides characterization provides characterization provides provides characterization provides characterization characterization provides characterization characterization provides characterization provides characterization provides characterization provides characterization characterization provides characterization characterization provides provides provides characterization provides characterization provides characterization provides characterization provides provides characterization provides characterization provides characterization provides characterization characterization characterization provides characterization characterization provides characterization characterization provides characterization characterization characterization characterization characterization characterization provides provides characterization characterization characterization provides characterization provides characterization characterization provides characterization characterization provides characterization characterization provides characterization provides provides characterization provides characterization provides characterization provides characterization characterization provides provides characterization provides characterization provides characterization provides characterization provides characterization provides provides characterization provides characterization provides characterization provides characterization provides characterization provides provides characterization provides provides characterization provides provides characterization provides characterization characterization provides characterization provides characterization provides characterization provides characterization provides characterization provides characterization characterization provides characterization provides characterization provides characterization provides characterization provides characterization characterization characterization provides characterization provides characterization provides characterization provides characterization provides characterization provides provides characterization provides provides characterization characterization provides characterization provides provides characterization provides characterization characterization characterization provides characterization characterization provides characterization provides characterization characterization provides characterization provides characterization provides provides characterization characterization provides characterization characterization\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised spectral clustering using deep neural networks\n",
            "Predicted Summary>>> unsupervised novel clustering \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose bayesian hypernetworks framework approximate bayesian inference neural networks\n",
            "Predicted Summary>>> propose pretraining system \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show possible fastly approximate wasserstein distances computation finding appropriate embedding euclidean distance emulates wasserstein distance\n",
            "Predicted Summary>>> propose fastly fastly fastly fastly fastly fastly approximate approximate approximate approximate approximate \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> routing procedures necessary capsnets\n",
            "Predicted Summary>>> routing necessary tasks necessary \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient video classification using frame based conditional gating module selecting dominant frames followed temporal modeling classifier\n",
            "Predicted Summary>>> propose search used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used based used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning functionally decomposed hierarchies continuous navigation tasks\n",
            "Predicted Summary>>> propose rl deep decomposed \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep neural networks able learn data diluted arbitrary amount noise\n",
            "Predicted Summary>>> proposed noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose distill large dataset small set synthetic data train networks close original performance\n",
            "Predicted Summary>>> distill synthetic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> suggest sufficient number bits representing weights dnns optimum bits conservative solving real problems\n",
            "Predicted Summary>>> propose sufficient method sufficient \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cognitive brain machine interface show direct link attentional effects perceptual accuracy neural gain eeg ssvep power human brain\n",
            "Predicted Summary>>> propose architecture analyze memory rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule classification rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule classification rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule classification rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule classification rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule rule classification rule rule rule rule classification \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> rederive wide class inference procedures global information bottleneck objective\n",
            "Predicted Summary>>> rederive transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> user level differential privacy recurrent neural network language models possible sufficiently large dataset\n",
            "Predicted Summary>>> paper new differential matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> input structuring along chaos stability\n",
            "Predicted Summary>>> introduce structuring along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along structuring along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along along\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural module approach continual learning using unified visual environment large action space\n",
            "Predicted Summary>>> propose continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hebbian plastic weights behave compressed episodic memory storage neural networks combination task specific synaptic consolidation improve ability alleviate catastrophic forgetting continual learning\n",
            "Predicted Summary>>> hebbian plastic storage plastic storage storage storage plastic storage storage \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extract contextual embeddings shelf supervised model helps downstream nlp models low resource settings\n",
            "Predicted Summary>>> extract contextual contextual contextual contextual contextual contextual contextual contextual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> systematically analyze convergence behaviour popular gradient algorithms solving bilinear games simultaneous alternating updates\n",
            "Predicted Summary>>> systematically analyze behaviour \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents two techniques incorporate high level structure generating procedural text sequence images\n",
            "Predicted Summary>>> propose proposes gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining graph neural networks rnn graph generative model propose novel architecture able learn sequence evolving graphs predict graph topology evolution future timesteps\n",
            "Predicted Summary>>> propose memory image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extend quantum svms semi supervised setting deal likely problem many missing class labels huge datasets\n",
            "Predicted Summary>>> extend novel optimal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> fast iterative algorithm balance energy network staying functional equivalence class\n",
            "Predicted Summary>>> propose balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance balance\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes new method neural network learning online bandit settings marginalizing last layer\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper suggesting method transform style images using deep neural networks\n",
            "Predicted Summary>>> propose suggesting method transform \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> synthesize complex extended human motions using auto conditioned lstm network\n",
            "Predicted Summary>>> propose novel method graphs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural network codec based transform coding clustering enables low complexity high efficient transparent compression neural networks\n",
            "Predicted Summary>>> provide policy policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> conditional entropy bottleneck information theoretic objective function learning optimal representations\n",
            "Predicted Summary>>> propose create entropy create create \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adaptation rl agent target environment unknown dynamics fast safe transfer prior experience variety environments select risk averse actions adaptation\n",
            "Predicted Summary>>> propose adaptation method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose active multitask learning algorithm achieves knowledge transfer tasks\n",
            "Predicted Summary>>> propose active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> verify deterministic probabilistic properties neural networks using non convex relaxations visible transformations specified generative models\n",
            "Predicted Summary>>> verify generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use hypernetwork predict optimal weights given hyperparameters jointly train everything together\n",
            "Predicted Summary>>> predict jointly optimal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique automatically labeling large unlabeled datasets train source models transfer learning experimental evaluation\n",
            "Predicted Summary>>> propose augmented transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> finding shed lights preventing cancer progression\n",
            "Predicted Summary>>> finding shed lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights lights\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study adversarial machine learning attacks multiple object tracking mechanisms first time\n",
            "Predicted Summary>>> propose proposes adversarial object \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> semi supervised multi modal classification framework tcn outperforms various benchmarks\n",
            "Predicted Summary>>> use proposes used used used policy used policy used policy used policy used policy used used policy used policy used policy used policy used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> integrative tensor based anomaly detection itad framework satellite system\n",
            "Predicted Summary>>> explored novel adversarial trainable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach graph classification based spectral graph convolutional networks extension multigraphs learnable relations hierarchical structure show state art results chemical social image datasets\n",
            "Predicted Summary>>> propose matrix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advance state art model compression proposing atomic compression networks acns novel architecture constructed recursive repetition small set neurons\n",
            "Predicted Summary>>> advance design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design design\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reinforcement learning based conversational search assistant provides contextual assistance subjective search like digital assets\n",
            "Predicted Summary>>> propose search search search conversational search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> models generate singing voices without lyrics scores take accompaniment input output singing voices\n",
            "Predicted Summary>>> propose new singing singing singing singing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual connections really perform iterative inference\n",
            "Predicted Summary>>> propose problem learning training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces marginattack stronger faster zero confidence adversarial attack\n",
            "Predicted Summary>>> propose new adversarial gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use deep rl learn policy directs search genetic algorithm better optimize execution cost computation graphs show improved results real world tensorflow graphs\n",
            "Predicted Summary>>> propose proposes matrix set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> non parametric method measure error moments regressors without ground truth used biased regressors\n",
            "Predicted Summary>>> propose introduces propose domain domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning optimal mapping deepnn distributions along theoretical guarantees\n",
            "Predicted Summary>>> propose mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping image mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping image mapping mapping mapping mapping mapping image mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping mapping\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised learning approach separating two structured signals superposition\n",
            "Predicted Summary>>> propose proposes approach \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use unrolled simulator end end differentiable model protein structure show sometimes hierarchically generalize unseen fold topologies\n",
            "Predicted Summary>>> use unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled networks unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show creatively designed trained rnn architectures decode well known sequential codes achieve close optimal performances\n",
            "Predicted Summary>>> propose creatively deep measure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> decompose gap marginal log likelihood evidence lower bound study effect approximate posterior true posterior distribution vaes\n",
            "Predicted Summary>>> decompose likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> actor critic reinforcement learning approach multi step returns applied autonomous driving carla simulator\n",
            "Predicted Summary>>> actor step step \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using deep learning techniques singing voice related tasks\n",
            "Predicted Summary>>> propose several method singing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> regularizing adversarial learning information bottleneck applied imitation learning inverse reinforcement learning generative adversarial networks\n",
            "Predicted Summary>>> regularizing exploration \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> convolution neural network multi view stereo matching whose design inspired best practices traditional geometry based approaches\n",
            "Predicted Summary>>> paper proposes set based sorting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> frechet distance train test distribution correlates change performance functions invariant shift\n",
            "Predicted Summary>>> frechet \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> previous vaes text cannot learn controllable latent representation images well fix enable first success towards controlled text generation without supervision\n",
            "Predicted Summary>>> propose rl train search controllable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing network architecture set syntax trees optimizing structure leads accurate concise regression models\n",
            "Predicted Summary>>> propose use set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> structured latent variable approach adds discrete control states within standard autoregressive neural paradigm provide arbitrary grounding internal model decisions without sacrificing representational power neural models\n",
            "Predicted Summary>>> propose autoregressive robust \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use unrolled simulator end end differentiable model protein structure show sometimes hierarchically generalize unseen fold topologies\n",
            "Predicted Summary>>> use unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled networks unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn task agnostic world graph abstraction environment show using structured exploration significantly accelerate downstream task specific rl\n",
            "Predicted Summary>>> propose differentiable memory transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compute saliency using strong generative model efficiently marginalize plausible alternative inputs revealing concentrated pixel areas preserve label information\n",
            "Predicted Summary>>> propose rl multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce doc dial end end framework generating conversational data grounded business documents via crowdsourcing train automated dialogue agents\n",
            "Predicted Summary>>> use structure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose pocketflow automated framework model compression acceleration facilitate deep learning models deployment mobile devices\n",
            "Predicted Summary>>> propose novel automated automated automated automated automated \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> formulation black box reinforcement learning method find likely failure system acting complex scenarios\n",
            "Predicted Summary>>> propose eliminates layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approach combine variational inference bayesian optimisation solve complicated inverse problems\n",
            "Predicted Summary>>> propose method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical analysis explanation particle based gradient estimators approximate inference deep generative models\n",
            "Predicted Summary>>> empirical empirical particle \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> methods learn contextual acoustic word embeddings end end speech recognition model perform competitively text based word embeddings\n",
            "Predicted Summary>>> policy acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic acoustic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce large scale receipt dataset post ocr parsing tasks\n",
            "Predicted Summary>>> propose proposes transfer set recurrent transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study low low signal noise classification scenarios objects correlate class label occupy tiny proportion entire image medical hyperspectral imaging\n",
            "Predicted Summary>>> propose low encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method deal rare words computing embedding definitions\n",
            "Predicted Summary>>> present deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal deal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> differentiable multi hop access textual knowledge base indexed contextual representations\n",
            "Predicted Summary>>> use used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method binarize weights activations deep neural network efficient computation memory usage performs better state art\n",
            "Predicted Summary>>> use binarize distribution \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training convex combinations random training examples labels improves generalization deep neural networks\n",
            "Predicted Summary>>> propose combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations combinations\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use deep rl learn policy directs search genetic algorithm better optimize execution cost computation graphs show improved results real world tensorflow graphs\n",
            "Predicted Summary>>> propose proposes matrix set matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose pocketflow automated framework model compression acceleration facilitate deep learning models deployment mobile devices\n",
            "Predicted Summary>>> propose first automated automated automated automated automated automated automated automated automated automated automated automated automated automated automated \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> benchmark evaluate neural embeddings identifiers source code\n",
            "Predicted Summary>>> propose variational random variational random benchmark \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents method stochastically generating video frames given key frames using direct convolutions\n",
            "Predicted Summary>>> propose presents frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extension gans combining optimal transport primal form energy distance defined adversarially learned feature space\n",
            "Predicted Summary>>> extension extension combining optimal feature feature feature feature feature feature feature feature feature feature feature feature feature optimal feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature optimal feature optimal feature optimal feature \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> multi relational graph embedding riemannian manifolds transe like loss function\n",
            "Predicted Summary>>> paper proposes tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> control variate based stochastic training algorithm graph convolutional networks receptive field two neighbors per node\n",
            "Predicted Summary>>> use variate \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes new objective function replace kl term one emulates maximum mean discrepancy mmd objective\n",
            "Predicted Summary>>> propose proposes proposes proposes proposes proposes proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired capsnet propose novel architecture graph embeddings basis node features extracted gnn\n",
            "Predicted Summary>>> use capsnet transfer tasks transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> devise mechanism called competition among pixels allows approximately complete saliency methods pass sanity checks\n",
            "Predicted Summary>>> devise proposes competition competition pixels training among competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduced algorithm learn connectivity deep multi branch networks approach evaluated image categorization consistently yields accuracy gains state art models use fixed connectivity\n",
            "Predicted Summary>>> propose branch concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept method concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> global geolocation inferencing strategy novel meshing strategy demonstrating incorporating additional information used improve overall performance geolocation inference model\n",
            "Predicted Summary>>> propose geolocation inferencing set geolocation representations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper develops principled method continual learning deep models\n",
            "Predicted Summary>>> propose develops continual continual continual continual continual continual continual continual continual continual continual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose bayesian quantized networks learn posterior distribution quantized parameters\n",
            "Predicted Summary>>> propose proposes memory quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce analyze phenomenon hallucinations nmt spurious translations unrelated source text propose methods reduce frequency\n",
            "Predicted Summary>>> propose adaptive phenomenon \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> iterative temporal differencing fixed random feedback alignment support spike time dependent plasticity vanilla backpropagation deep learning\n",
            "Predicted Summary>>> propose method random \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> auxiliary prediction task speed learning language emergence setups\n",
            "Predicted Summary>>> auxiliary represent represent represent represent represent represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present rl agent minerva learns walk knowledge graph answer queries\n",
            "Predicted Summary>>> propose rl rl minerva rl rl minerva rl minerva \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> side tuning adapts pre trained network training lightweight side network fused unchanged pre trained network using simple additive process\n",
            "Predicted Summary>>> side tuning trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel state space time series model capability capture structure change points anomaly points better forecasting performance exist change points anomalies time series\n",
            "Predicted Summary>>> propose method domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes novel lightweight transformer character level language modeling utilizing group wise operations\n",
            "Predicted Summary>>> paper proposes wise set wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise wise\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactively generating image incrementally growing scene graphs multiple steps using gans preserving contents image generated previous steps\n",
            "Predicted Summary>>> propose image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image tasks image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image image\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> better deep reinforcement learning algorithm approximate counterfactual regret minimization\n",
            "Predicted Summary>>> propose gans tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present local ensembles method detecting extrapolation trained models approximates variance ensemble using local second order information\n",
            "Predicted Summary>>> extend preferences method variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train gans differential privacy generate artificial privacy preserving datasets\n",
            "Predicted Summary>>> use sparsity use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new agi architecture trans sapient performance high level overview omega agi architecture basis data science automation system submitted workshop\n",
            "Predicted Summary>>> propose agi \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> modern deep cnns invariant translations scalings realistic image transformations lack invariance related subsampling operation biases contained image datasets\n",
            "Predicted Summary>>> propose real used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> slowmo improves optimization generalization performance communication efficient decentralized algorithms without sacrificing speed\n",
            "Predicted Summary>>> slowmo used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used tasks used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train natural media painting agent using environment model based painting agent present novel approach train constrained painting agent follows command encoded observation\n",
            "Predicted Summary>>> train natural train train train natural train natural train train natural train natural train train natural train natural train natural train natural train train natural train train natural train natural train natural train natural train train natural train natural train natural train train train train train natural train natural train natural train natural train natural train natural train natural train train natural train train natural train natural train natural train train natural train train natural train train train train train train natural train train train train natural train natural train natural train train natural train train natural train natural train train natural train natural train natural train train tasks natural train natural train natural train natural train natural train natural train natural train natural natural natural natural train natural train natural train natural train natural train natural train natural train natural train natural train natural train natural train natural natural train natural train natural train natural train natural train natural train natural train natural natural train natural train natural train natural train natural natural natural train natural train natural train natural train natural train natural natural natural natural train natural natural train natural train natural natural train natural train natural natural train natural train natural train natural natural train natural natural natural natural train natural train natural train natural train natural train natural train natural train natural train natural train natural train natural train natural natural natural train natural train natural train natural train natural train natural train natural train natural train natural train natural natural train\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform counting visual question answering model produces interpretable outputs counting directly detected objects\n",
            "Predicted Summary>>> counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting counting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show key achieving good performance idms lies learning latent representations encode information shared equivalent experiences generalized unseen scenarios\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> used cvae type model structure learn directly generate slates whole pages recommendation systems\n",
            "Predicted Summary>>> introduce cvae cvae cvae cvae cvae \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new architecture termed dual adversarial transfer network datnet addressing low resource named entity recognition ner achieve new state art performances conll twitter ner\n",
            "Predicted Summary>>> propose algorithm propose adversarial algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn neural network uniformizes input distribution leads competitive indexing performance high dimensional space\n",
            "Predicted Summary>>> propose first analyze trained trained trained trained trained trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> accelerating cnn training pipeline accelerators stale weights\n",
            "Predicted Summary>>> accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating accelerating pipeline \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes use spectral element methods fast accurate training neural ordinary differential equations system identification\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine kernel method connectionist models show resulting deep architectures trained layer wise transparent learning dynamics\n",
            "Predicted Summary>>> propose kernel kernel kernel connectionist kernel kernel method kernel layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> devise novel depthwise separable graph convolution dsgc generic spatial domain data highly compatible depthwise separable convolution\n",
            "Predicted Summary>>> devise convolution separable goal tasks separable separable separable separable separable separable separable separable separable separable separable separable separable separable separable separable goal separable separable separable goal separable separable separable separable goal separable separable separable separable separable separable separable goal separable separable separable separable separable goal separable separable separable separable separable goal separable separable separable separable separable separable separable goal separable separable separable separable separable separable separable separable goal separable separable separable separable separable separable separable separable separable separable separable separable separable separable separable separable goal separable separable goal separable separable separable separable separable separable separable separable separable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired neuroscience research solve three key weakness widely cited recurrent attention model simply adding two terms objective function\n",
            "Predicted Summary>>> variational provides \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper explores using wearable sensory augmenting technology facilitate first hand perspective taking like cat like whiskers\n",
            "Predicted Summary>>> propose introduces variational transfer latent wearable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed algorithm use unlabeled data training rather uses selectively\n",
            "Predicted Summary>>> propose proposes proposes algorithm unlabeled \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning compositional koopman operators efficient system identification model based control\n",
            "Predicted Summary>>> proposed koopman koopman koopman koopman koopman koopman \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gan based extreme image compression method using less half bits sota engineered codec preserving visual quality\n",
            "Predicted Summary>>> propose scaling scaling \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel dynamic ridesharing framework form trips optimizes operational value service provider user value passengers factoring users social preferences decision making process\n",
            "Predicted Summary>>> propose proposes architecture goal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce isrlu activation function continuously differentiable faster elu related isru replaces tanh sigmoid\n",
            "Predicted Summary>>> propose isrlu used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used tasks used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactive technique improve brushing dense trajectory datasets taking account shape brush\n",
            "Predicted Summary>>> interactive brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> order forecast multivariate stationary time series learn embeddings containing contextual features within rnn apply framework public transportation data\n",
            "Predicted Summary>>> propose forecast using set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigation combining recurrent neural networks experience replay leading state art agent atari dmlab using single set hyper parameters\n",
            "Predicted Summary>>> investigation combining investigation combining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel way incorporate conditional image information discriminator gans using feature fusion used structured prediction tasks\n",
            "Predicted Summary>>> propose algorithmic bayesian \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> convolutional architecture learning data dependent weights autoregressive forecasting time series\n",
            "Predicted Summary>>> propose vaes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural simulation universal turing machine\n",
            "Predicted Summary>>> propose proposes estimates policy noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose model agnostic way leverage bert text generation achieve improvements transformer tasks datasets\n",
            "Predicted Summary>>> propose domain agnostic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose agile framework training agents perform instructions examples respective goal states\n",
            "Predicted Summary>>> propose identifies transfer instructions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper investigates target acquisition handheld virtual panels vr shows target width distance direction approach respect gravity angle approach impact user performance\n",
            "Predicted Summary>>> propose asynchronous set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> stability scattering transform representations graph data deformations underlying graph support\n",
            "Predicted Summary>>> propose scattering transform \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tcn multimodal semi supervised learning ablation study mechanisms interpretations latent representations\n",
            "Predicted Summary>>> paper class encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aim improve upon mcmc vi novel hybrid method based idea reducing simulation bias finite length mcmc chains using gradient based optimisation\n",
            "Predicted Summary>>> aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim aim\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> strokenet novel architecture agent trained draw strokes differentiable simulation environment could effectively exploit power back propagation\n",
            "Predicted Summary>>> strokenet domain domain trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use non negative rank relu activation matrices complexity measure show negatively correlates good generalization\n",
            "Predicted Summary>>> train generative \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop end end trainable approach skimming rereading early stopping applicable classification tasks\n",
            "Predicted Summary>>> provide trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> important consider optimization function space parameter space introduce learning rule reduces distance traveled function space like sgd limits distance traveled parameter space\n",
            "Predicted Summary>>> propose new optimization distance tasks distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel approach improve given cross surface mapping local refinement new iterative method deform mesh order meet user constraints\n",
            "Predicted Summary>>> propose proposes variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> modern deep cnns invariant translations scalings realistic image transformations lack invariance related subsampling operation biases contained image datasets\n",
            "Predicted Summary>>> propose real used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gans benefit scaling\n",
            "Predicted Summary>>> gans scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling benefit scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling scaling benefit scaling scaling\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> exploring learnability learned neural networks\n",
            "Predicted Summary>>> propose learnability method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop point based value iteration solver pomdps active perception planning tasks\n",
            "Predicted Summary>>> propose alternative tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose architecture search method identify distribution architectures use construct bayesian ensemble outlier detection\n",
            "Predicted Summary>>> propose rl architecture search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces domain independent compilations user questions constraints contrastive explanations\n",
            "Predicted Summary>>> propose bayesian compilations compilations compilations compilations compilations compilations compilations compilations compilations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> employing quantum entanglement measures quantifying correlations deep learning using connection fit deep network architecture correlations data\n",
            "Predicted Summary>>> propose grammar grammar grammar gan algorithm algorithm grammar tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> automatically construct explore small abstract markov decision process enabling us achieve state art results montezuma revenge pitfall private eye significant margin\n",
            "Predicted Summary>>> automatically proposes abstract abstract \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> variational inference infering discrete distribution low precision neural network derived\n",
            "Predicted Summary>>> propose search infering infering infering infering infering infering infering infering infering infering infering infering infering \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> pairwise learned capsule network performs well face verification tasks given limited labeled data\n",
            "Predicted Summary>>> pairwise capsule used tasks policy set tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep representations combined gradient descent approximate learning algorithm\n",
            "Predicted Summary>>> propose problem descent descent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> fully connected architecture used produce word embeddings character representations outperforms traditional embeddings provides insight sparsity dropout\n",
            "Predicted Summary>>> propose connected used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed novel framework graph similarity learning inductive unsupervised scenario\n",
            "Predicted Summary>>> propose rl algorithm rl propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sort encoder undo sorting decoder avoid responsibility problem set auto encoders\n",
            "Predicted Summary>>> sort set sorting set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dqn ddpg hybrid algorithm proposed deal discrete continuous hybrid action space\n",
            "Predicted Summary>>> dqn ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg ddpg\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable general purpose factorization algorithm also helps circumvent cold start problem\n",
            "Predicted Summary>>> identify propose rl factorization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> considering neural network optimization process model selection problem introduce biological plausible normalization method extracts statistical regularity mdl principle tackle imbalanced limited data issue\n",
            "Predicted Summary>>> considering considering layer layer considering layer considering layer layer layer layer layer layer layer considering layer layer layer layer layer layer layer layer layer way layer layer way layer layer layer layer layer layer layer layer layer layer layer layer way layer layer layer layer way layer layer way layer layer way layer layer layer way layer way layer way layer layer layer layer layer layer way layer layer way layer way layer layer way layer way layer layer way layer layer layer layer way layer layer layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> joint method learning cross lingual embeddings state art performance cross lingual tasks mono lingual quality\n",
            "Predicted Summary>>> unified unified blurred \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generalization strongly correlated bayesian evidence gradient noise drives sgd towards minima whose evidence large\n",
            "Predicted Summary>>> propose strongly correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated correlated \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe two end end autoencoding parsers semi supervised graph based dependency parsing\n",
            "Predicted Summary>>> describe two use memory use two use two use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> experimental paper proves amount redundant weights freezed third epoch slight drop accuracy\n",
            "Predicted Summary>>> experimental proves search proves \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adaptation rl agent target environment unknown dynamics fast safe transfer prior experience variety environments select risk averse actions adaptation\n",
            "Predicted Summary>>> propose adaptation method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes advanced policy optimization method hindsight experience sparse reward reinforcement learning\n",
            "Predicted Summary>>> propose proposes advanced \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present hierarchical learning framework navigation within embodied learning setting\n",
            "Predicted Summary>>> propose deep transfer need algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove activation functions satisfying conditions deep network gets wide lengths vectors hidden variables converge length map\n",
            "Predicted Summary>>> prove proposes functions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first principled weight initialization method hypernetworks\n",
            "Predicted Summary>>> propose several tasks high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate strong regularization fails propose method achieve strong regularization\n",
            "Predicted Summary>>> propose new strong \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theoretical study multi task learning practical implications improving multi task training transfer learning\n",
            "Predicted Summary>>> propose theoretical matrix transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose learn dialogue system independently parameterizes different dialogue skills learns select combine attention parameters aop\n",
            "Predicted Summary>>> paper propose variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze gradient descent deep linear neural networks providing guarantee convergence global optimum linear rate\n",
            "Predicted Summary>>> propose entropy create \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study rate distortion approximations evaluating deep generative models show rate distortion curves provide insights model log likelihood alone requiring roughly computational cost\n",
            "Predicted Summary>>> propose rate rate tasks distortion rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate rate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new anytime neural network allows partial evaluation subnetworks different widths well depths\n",
            "Predicted Summary>>> train matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel architecture traverses image pyramid top fashion visits informative regions along way\n",
            "Predicted Summary>>> propose architecture traverses method traverses traverses traverses traverses traverses traverses traverses traverses traverses \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> artificial neural networks evolved structures present olfactory systems flies mice trained classify odors\n",
            "Predicted Summary>>> propose several layer layer layer layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> children use mutual exclusivity bias learn new words standard neural nets show opposite bias hindering learning naturalistic scenarios lifelong learning\n",
            "Predicted Summary>>> children general method general \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> important consider optimization function space parameter space introduce learning rule reduces distance traveled function space like sgd limits distance traveled parameter space\n",
            "Predicted Summary>>> propose new optimization distance optimization tasks distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new value function enables better learning gaussian policies\n",
            "Predicted Summary>>> propose theoretical domain method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce novel larger context language model simultaneously captures syntax semantics making capable generating highly interpretable sentences paragraphs\n",
            "Predicted Summary>>> propose theoretical used gans larger \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> image classification via iteratively querying reference image candidate class rnn use cnn compare input image\n",
            "Predicted Summary>>> propose rl functions functions functions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> add method deep learning detect outliers prediction time\n",
            "Predicted Summary>>> propose method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> feature vectors soundnet predict brain activity subjects watching movie auditory language related brain regions\n",
            "Predicted Summary>>> propose studies learning gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed double neural framework solve large scale imperfect information game\n",
            "Predicted Summary>>> propose double double \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generate effective hash codes efficient cold start recommendation meanwhile provide feasible marketing strategy\n",
            "Predicted Summary>>> propose lightweight architecture codes codes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> practical proposal ethical responsive nlp technology operationalizing transparency test training data\n",
            "Predicted Summary>>> system novel nlp nlp nlp nlp \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first principled weight initialization method hypernetworks\n",
            "Predicted Summary>>> propose several tasks high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose cnn neuron ranking two different methods show consistency producing result allows interpret network deems important compress network keeping relevant nodes\n",
            "Predicted Summary>>> propose rl variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> set modifications loc get policy actor critic outperforms performs similarly acer modifications large batchsizes aggressive clamping policy forcing gumbel noise\n",
            "Predicted Summary>>> set modifications set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> techniques combining generalized policies search algorithms exploit strengths overcome weaknesses solving probabilistic planning problems\n",
            "Predicted Summary>>> techniques proposes overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome overcome techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired trial trial variability brain result multiple noise sources introduce variability noise knowledge distillation framework studied effect generalization robustness\n",
            "Predicted Summary>>> propose trial \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep networks sensitive task irrelevant changes input also invariant wide range task relevant changes thus making vast regions input space vulnerable adversarial attacks\n",
            "Predicted Summary>>> propose theoretical sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive sensitive\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> max pooled word vectors fuzzy jaccard set similarity extremely competitive baseline semantic similarity propose simple dynamic variant performs even better\n",
            "Predicted Summary>>> max generator memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> multimodal transformer multimodal sequential learning strong empirical results multimodal language metrics multimodal sentiment analysis emotion recognition personality traits recognition\n",
            "Predicted Summary>>> multimodal goal multimodal task goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual connections really perform iterative inference\n",
            "Predicted Summary>>> propose problem learning training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extracting finite state machine recurrent neural network via quantization purpose interpretability experiments atari\n",
            "Predicted Summary>>> propose sparsity sparsity sparsity theoretical sparsity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate large pruned models large sparse outperform smaller dense small dense counterparts identical memory footprint\n",
            "Predicted Summary>>> propose large layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed model free policy il algorithm continuous control experimental results showed algorithm achieves competitive results gail significantly reducing environment interactions\n",
            "Predicted Summary>>> paper search method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform depth investigation suitability self attention models character level neural machine translation\n",
            "Predicted Summary>>> investigation depth investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing network architecture set syntax trees optimizing structure leads accurate concise regression models\n",
            "Predicted Summary>>> propose new set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> robust bayesian deep learning algorithm infer complex posteriors latent variables\n",
            "Predicted Summary>>> propose adversarial bayesian \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model reconciliation established framework plan explanations easily hijacked produce lies\n",
            "Predicted Summary>>> propose reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation reconciliation\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gan based extreme image compression method using less half bits sota engineered codec preserving visual quality\n",
            "Predicted Summary>>> propose scaling scaling \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address end end learning energy based representations signal image observation dataset irregular sampling patterns\n",
            "Predicted Summary>>> address unsupervised matrix end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn neural network uniformizes input distribution leads competitive indexing performance high dimensional space\n",
            "Predicted Summary>>> propose first analyze trained trained trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe two end end autoencoding parsers semi supervised graph based dependency parsing\n",
            "Predicted Summary>>> describe two use memory use two use use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> personalized propagation neural predictions ppnp improves graph neural networks separating prediction propagation via personalized pagerank\n",
            "Predicted Summary>>> personalized propagation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sparse reward reinforcement learning ensemble multiple dynamics models used generate intrinsic reward designed minimum surprise\n",
            "Predicted Summary>>> propose introduces search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule tasks search search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search search rule search rule search search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search search rule search rule search search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search search rule search rule search search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search rule search search rule search rule search rule search rule search rule search rule search search rule search rule search rule search rule search rule search search rule search rule search search rule search rule search rule search rule search rule search rule search rule\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method active anomaly detection present new layer attached deep learning model designed unsupervised anomaly detection transform active method\n",
            "Predicted Summary>>> method transform method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide another novel explanation learning rate decay initially large learning rate suppresses network memorizing noisy data decaying learning rate improves learning complex patterns\n",
            "Predicted Summary>>> propose properly networks could train could \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approximate determinantal point processes neural nets justify model theoretically empirically\n",
            "Predicted Summary>>> propose determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> robust bayesian estimation via maximum mean discrepancy\n",
            "Predicted Summary>>> propose memory memory memory memory memory memory memory memory tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> handling uncertainty visual perception plan recognition\n",
            "Predicted Summary>>> handling perception perception perception \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present method adapting hyperparameters probabilistic models using optimal transport applications robotics\n",
            "Predicted Summary>>> present method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> effective regularization optimization strategies lstm based language models achieves sota ptb wt\n",
            "Predicted Summary>>> propose strategies regularization strategies regularization strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies strategies\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> memory augmented network plan partially observable environments\n",
            "Predicted Summary>>> propose augmented domain tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> better adversarial training learning map back data manifold autoencoders hidden states\n",
            "Predicted Summary>>> propose proposes theoretical domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn space motor primitives unannotated robot demonstrations show primitives semantically meaningful composed new robot tasks\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> logit regularization methods help explain improve state art adversarial defenses\n",
            "Predicted Summary>>> logit used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop efficient multi scale approximate attributed network embedding procedures provable properties\n",
            "Predicted Summary>>> paper method global extension \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method infers constraints task execution leveraging principle maximum entropy quantify demonstrations differ expected un constrained behavior\n",
            "Predicted Summary>>> introduce infers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> context adaptive entropy model use end end optimized image compression significantly improves compression performance\n",
            "Predicted Summary>>> investigate adaptive optimized optimized optimized adaptive optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized optimized \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide efficient convergence rate gradient descent complete orthogonal dictionary learning objective based geometric analysis\n",
            "Predicted Summary>>> train used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce flipout efficient method decorrelating gradients computed stochastic neural net weights within mini batch implicitly sampling pseudo independent weight perturbations example\n",
            "Predicted Summary>>> propose flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout flipout decorrelating \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> suggest smart batch selection technique called ada boundary\n",
            "Predicted Summary>>> suggest smart used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed model free policy il algorithm continuous control experimental results showed algorithm achieves competitive results gail significantly reducing environment interactions\n",
            "Predicted Summary>>> paper search method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose efficient robust asynchronous federated learning algorithm existence stragglers\n",
            "Predicted Summary>>> propose asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel approach improve given cross surface mapping local refinement new iterative method deform mesh order meet user constraints\n",
            "Predicted Summary>>> propose proposes variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introducing notion optimal representation space provide theoretical argument experimental validation unsupervised model sentences perform well supervised similarity unsupervised transfer tasks\n",
            "Predicted Summary>>> train theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose method incrementally learn embedding space domain network architectures enable careful selection architectures evaluation compressed architecture search\n",
            "Predicted Summary>>> paper incrementally \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> goal recognition approach based operator counting heuristics used account noise dataset\n",
            "Predicted Summary>>> paper method recognition \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compare deep model based model free rl algorithms studying approximability functions policies dynamics neural networks\n",
            "Predicted Summary>>> train rl set asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> diagnosed problem stoa vaes theoretically qualitatively\n",
            "Predicted Summary>>> propose vaes new used search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> weakly supervised text based video moment retrieval\n",
            "Predicted Summary>>> propose search search text search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose assessment framework analyze learn graph convolutional filter\n",
            "Predicted Summary>>> train theoretical recurrent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> understand transferability perspectives improved generalization optimization feasibility transferability\n",
            "Predicted Summary>>> improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved improved perspectives \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> query based black box attacks deep neural networks adversarial success rates matching white box attacks\n",
            "Predicted Summary>>> query new box \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reframe generation problem one editing existing points result extrapolate better traditional gans\n",
            "Predicted Summary>>> reframe proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> presents information theoretic training objective co training demonstrates power unsupervised learning phonetics\n",
            "Predicted Summary>>> present presents \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> language generation using seq seq models produce word embeddings instead softmax based distribution vocabulary step enabling much faster training maintaining generation quality\n",
            "Predicted Summary>>> propose search domain models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new sparse structured attention mechanism tvmax promotes sparsity encourages weight related adjacent locations\n",
            "Predicted Summary>>> propose matrix matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combine search reinforcement learning speed machine learning code\n",
            "Predicted Summary>>> identify search search search search search search search search search search search search search search search networks search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy learning bandit feedbacks propose new variance regularized counterfactual learning algorithm theoretical foundations superior empirical performance\n",
            "Predicted Summary>>> develop tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> pooling achieved using wavelets instead traditional neighborhood approaches max average etc\n",
            "Predicted Summary>>> pooling achieved using instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead instead \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> attempt model drawing process fonts building sequential generative models vector graphics svgs highly structured representation font characters\n",
            "Predicted Summary>>> attempt drawing drawing drawing networks fonts method maximum \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> plan syntactic structural translation using codes\n",
            "Predicted Summary>>> plan plan plan plan plan plan plan plan plan structural plan plan structural plan plan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose agile framework training agents perform instructions examples respective goal states\n",
            "Predicted Summary>>> propose identifies transfer instructions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach detects outliers image data preserving classification accuracy image classification\n",
            "Predicted Summary>>> novel proposes detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new pretraining method establishes new state art results glue race squad benchmarks fewer parameters compared bert large\n",
            "Predicted Summary>>> novel pretraining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper analyses tremendous representational power networks especially skip connections may used method better generalization\n",
            "Predicted Summary>>> train analyses data datasets datasets \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique learning deep generative models shared latent variables applied omniglot pixelcnn decoder\n",
            "Predicted Summary>>> propose search object machine \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep innovation protection allows evolving complex world models end end tasks\n",
            "Predicted Summary>>> paper novel variational protection protection protection protection protection protection protection protection protection protection \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze determine precision requirements training neural networks tensors including back propagated signals weight accumulators quantized fixed point format\n",
            "Predicted Summary>>> analyze determine precision networks precision \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present long time scale musical audio style transfer algorithm synthesizes audio time domain uses time frequency representations audio\n",
            "Predicted Summary>>> propose domain transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduced novel gradient estimator using stein method compared methods learning implicit models approximate inference image generation\n",
            "Predicted Summary>>> scalable novel used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> hebbian plastic weights behave compressed episodic memory storage neural networks combination task specific synaptic consolidation improve ability alleviate catastrophic forgetting continual learning\n",
            "Predicted Summary>>> hebbian plastic storage plastic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce model human question asking combines neural networks symbolic programs learn generate good questions without supervised examples\n",
            "Predicted Summary>>> introduce proposes human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human human \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new algorithm based optimal transport train cnn ssl fashion\n",
            "Predicted Summary>>> propose variational various variational used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> parametric adversarial divergences implicitly define meaningful task losses generative modeling make parallels structured prediction study properties divergences ability encode task interest\n",
            "Predicted Summary>>> propose memory tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> see abstract revision paper identical except page supplementary material serve stand along technical report version paper\n",
            "Predicted Summary>>> see abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract abstract rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose generative method multisource domain adaptation based decomposition content style domain factors\n",
            "Predicted Summary>>> propose rl train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sgd adam single spiked model tensor pca\n",
            "Predicted Summary>>> propose new spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked sgd spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show deep learning network derivatives low rank structure structure allows us use second order derivative information calculate learning rates adaptively computationally feasible manner\n",
            "Predicted Summary>>> propose branch memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem continuous control agents deep rl adversarial attacks proposed two step algorithm based learned model dynamics\n",
            "Predicted Summary>>> unified used search train regression \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose zero centered gradient penalty improving generalization stability gans\n",
            "Predicted Summary>>> propose gan centered centered centered centered centered centered centered centered centered centered centered centered centered centered centered centered centered centered centered \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce dataset models training evaluation protocols collaborative drawing task allows studying goal driven perceptually actionably grounded language generation understanding\n",
            "Predicted Summary>>> train propose tasks two \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> impact helps rl agents train faster decreasing training wall clock time increasing sample efficiency simultaneously\n",
            "Predicted Summary>>> propose variational rl represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new model making generalizable diverse retrosynthetic reaction predictions\n",
            "Predicted Summary>>> propose text robustness text text text transfer text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce mist rnns exhibit superior vanishing gradient properties comparison lstm improve performance substantially lstm clockwork rnns tasks requiring long term dependencies much efficient previously proposed narx rnns even fewer parameters operations lstm\n",
            "Predicted Summary>>> present mist mist mist \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> control variate based stochastic training algorithm graph convolutional networks receptive field two neighbors per node\n",
            "Predicted Summary>>> use variate \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> estimation training data distribution trained classifier using gan\n",
            "Predicted Summary>>> propose novel trained trained trained trained trained trained trained trained trained trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new theoretical explanation existence adversarial examples\n",
            "Predicted Summary>>> propose identifies transfer adversarial examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples transfer examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples transfer examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural logic machine nlm neural symbolic architecture inductive learning logic reasoning\n",
            "Predicted Summary>>> propose proposes logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training convnets mixed image size improve results across multiple sizes evaluation\n",
            "Predicted Summary>>> propose extends tasks method tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> point important problems common practice using best single model performance comparing deep learning architectures propose method corrects flaws\n",
            "Predicted Summary>>> paper search combination \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> plan syntactic structural translation using codes\n",
            "Predicted Summary>>> plan plan plan plan plan plan plan plan plan structural plan plan plan plan plan plan plan plan plan plan plan plan plan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present simple modification alternating sgd method called prediction step improves stability adversarial networks\n",
            "Predicted Summary>>> unsupervised modification unsupervised modification sgd \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed method end end neural svm optimized shot learning\n",
            "Predicted Summary>>> propose memory memory transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper uses principles field calibration machine learning logits neural network defend adversarial attacks\n",
            "Predicted Summary>>> used used used used used used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> best knowledge deepa first deep learning framework controls optimizes parallelism cnns parallelizable dimensions granularity layer\n",
            "Predicted Summary>>> propose proposes deepa deepa deepa deepa tasks deepa deepa deep best deepa deepa \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical evaluation generative adversarial networks\n",
            "Predicted Summary>>> empirical set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose interpretable model detecting user chosen wakewords learns user examples\n",
            "Predicted Summary>>> propose proposes tuning interpretable wakewords interpretable interpretable interpretable interpretable interpretable interpretable interpretable interpretable interpretable interpretable interpretable layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use unrolled simulator end end differentiable model protein structure show sometimes hierarchically generalize unseen fold topologies\n",
            "Predicted Summary>>> use unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled networks unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled unrolled\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning sample via lower bounding acceptance rate metropolis hastings algorithm\n",
            "Predicted Summary>>> propose domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel algorithm incremental learning vae fixed architecture\n",
            "Predicted Summary>>> propose sparsity generation used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new framework data dependent dnn regularization prevent dnns overfitting random data random labels\n",
            "Predicted Summary>>> propose vaes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method enriching combining features improve classification accuracy\n",
            "Predicted Summary>>> propose enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method assessing quaility similarity evaluators showing potential transformer based language models replacing bleu rouge\n",
            "Predicted Summary>>> propose assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing representations assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing representations assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing representations assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing representations assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing assessing\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply model agnostic defense strategy adversarial examples achieve white box accuracy black box accuracy major attack algorithms\n",
            "Predicted Summary>>> unsupervised easy trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper analyzes latent space learned model free approaches miniature incomplete information game trains forward model latent space apply monte carlo tree search yielding positive performance\n",
            "Predicted Summary>>> propose functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural phrase based machine translation linear decoding time\n",
            "Predicted Summary>>> represent phrase architecture tasks represent like \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show posterior collapse linear vaes caused entirely marginal log likelihood elbo experiments deep vaes suggest similar phenomenon play\n",
            "Predicted Summary>>> propose new used search used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address end end learning energy based representations signal image observation dataset irregular sampling patterns\n",
            "Predicted Summary>>> address unsupervised matrix image unsupervised learning end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new objective function neural sequence generation integrates ml based rl based objective functions\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> mathematically analyze effect batch normalization simple model obtain key new insights applies general supervised learning\n",
            "Predicted Summary>>> mathematically analyze general \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose light weight enhancement attention neural architecture fusionnet achieve sota squad adversarial squad\n",
            "Predicted Summary>>> propose light learning tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes new approach incorporating desired invariance representations learning based observations current state art afl practical issues\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes proposes invariant proposes proposes invariant provides proposes invariant proposes proposes gan proposes invariant proposes gan proposes gan proposes gan proposes invariant proposes gan proposes gan proposes gan proposes proposes invariant proposes gan proposes gan proposes gan proposes invariant proposes gan proposes gan proposes gan proposes gan proposes invariant proposes gan proposes proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provably recover span deep multi layered neural network latent structure empirically apply efficient span recovery algorithms attack networks obfuscating inputs\n",
            "Predicted Summary>>> paper theoretical image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose model able perform physical parameter estimation systems video differential equations governing scene dynamics known labeled states objects available\n",
            "Predicted Summary>>> propose novel new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn efficient lossy image codec optimized facilitate reliable photo manipulation detection fractional cost payload quality even low bitrates\n",
            "Predicted Summary>>> propose proposes lossy lossy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show autoregressive flows used improve sequential latent variable models\n",
            "Predicted Summary>>> propose extension tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using supervised latent variable modeling framework determine reward inverse reinforcement learning task\n",
            "Predicted Summary>>> propose gan variable provides \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep learning structured tabular data machine learning using pre trained cnn model imagenet\n",
            "Predicted Summary>>> address novel tabular \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generating new chemical materials using novel cross domain gans\n",
            "Predicted Summary>>> novel chemical chemical chemical method chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical chemical\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnvolutional neural networks characterization backdoored classifier detection understanding\n",
            "Predicted Summary>>> cnvolutional propose classifier transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed comprehensive approach unsupervised embedding learning basis algorithm\n",
            "Predicted Summary>>> propose comprehensive generator \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical investigation gan based alignment word vector spaces focusing cases linear transformations provably exist training unstable\n",
            "Predicted Summary>>> investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> meta learning methods used vision directly applied nlp perform worse nearest neighbors new classes better distributional signatures\n",
            "Predicted Summary>>> paper proposes used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> system rewriting text conditioned multiple controllable attributes\n",
            "Predicted Summary>>> first rewriting rewriting rewriting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> invent novel cluster cluster framework nmt training better understand source target language diversity\n",
            "Predicted Summary>>> invent cluster gans cluster \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address problem unsupervised shot object recognition training images unlabeled share classes test images\n",
            "Predicted Summary>>> address problem object classes classes classes classes classes classes classes classes classes classes object classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> ensuring models learned federated fashion reveal client participation\n",
            "Predicted Summary>>> ensuring policy learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned policy learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned learned\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical comparison bayesian deep networks thompson sampling\n",
            "Predicted Summary>>> empirical empirical empirical empirical empirical training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces network architecture solve structure motion sfm problem via feature bundle adjustment ba\n",
            "Predicted Summary>>> use search search features cases \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> user level differential privacy recurrent neural network language models possible sufficiently large dataset\n",
            "Predicted Summary>>> paper differential matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method handle image degradations different levels learning diffusion terminal time model generalize unseen degradation level different noise statistic\n",
            "Predicted Summary>>> train text evaluating text representations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed models external knowledge improve state art snli dataset\n",
            "Predicted Summary>>> present rl train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach detects outliers image data preserving classification accuracy image classification\n",
            "Predicted Summary>>> novel proposes detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects detects\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> describe biologically plausible learning algorithm fixed point recurrent networks without tied weights\n",
            "Predicted Summary>>> propose plausible \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> identify prototypical outlier examples machine learning quantifiably different make use improve many aspects neural networks\n",
            "Predicted Summary>>> identify prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical prototypical outlier prototypical outlier prototypical outlier prototypical prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier outlier prototypical outlier outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier outlier outlier outlier outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier prototypical outlier outlier\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study functioning autoencoders simple setting advise new strategies regularisation order obtain bettre generalisation latent interpolation mind image sythesis\n",
            "Predicted Summary>>> propose functioning unsupervised policy unsupervised level unsupervised policy unsupervised policy unsupervised level \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new way compress neural networks using probabilistic data structures\n",
            "Predicted Summary>>> propose gan gan way gan way gan way gan way gan way \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> directional message passing incorporates spatial directional information improve graph neural networks\n",
            "Predicted Summary>>> directional directional directional message directional directional directional directional directional directional directional directional directional directional directional directional directional \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce searnn novel algorithm rnn training inspired learning search approach structured prediction order avoid limitations mle training\n",
            "Predicted Summary>>> address searnn memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present principled approach problem federated domain adaptation aims align representations learned among different nodes data distribution target node\n",
            "Predicted Summary>>> unsupervised new domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new application seq seq modelling automating sciene journalism highly abstractive dataset transfer learning tricks automatic evaluation measure\n",
            "Predicted Summary>>> propose application transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose active multitask learning algorithm achieves knowledge transfer tasks\n",
            "Predicted Summary>>> propose active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active active\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn quantize speech signal apply algorithms requiring discrete inputs audio data bert\n",
            "Predicted Summary>>> propose quantize search used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce extra data dependent gaussian prior objective augment current mle training designed capture prior knowledge ground truth data\n",
            "Predicted Summary>>> propose proposes general image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose learn synthesizing shot classifiers many shot classifiers using one single objective function gfsl\n",
            "Predicted Summary>>> propose alternative shot synthesizing shot synthesizing shot shot shot shot shot shot shot shot shot shot shot shot shot shot shot shot shot \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> represent entity based histogram contexts wasserstein need\n",
            "Predicted Summary>>> represent theoretical need memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> bridge gap soft computing\n",
            "Predicted Summary>>> bridge gap bridge architectures architectures architectures \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative model temporal data builds online belief state operates latent space jumpy predictions rollouts states\n",
            "Predicted Summary>>> propose method algorithm method method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find movement function space proportional movement parameter space optimization propose new natural gradient style optimizer address\n",
            "Predicted Summary>>> find movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn task agnostic world graph abstraction environment show using structured exploration significantly accelerate downstream task specific rl\n",
            "Predicted Summary>>> propose differentiable transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate implicit syntactic knowledge sentence embeddings using new analysis set grammatically annotated sentences acceptability judgments\n",
            "Predicted Summary>>> propose filter tasks sentences tasks sentences sentences tasks knowledge tasks sentences tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks sentences tasks sentences tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks sentences tasks tasks tasks tasks sentences tasks sentences tasks tasks tasks sentences tasks tasks tasks sentences tasks sentences tasks tasks tasks sentences tasks sentences tasks tasks tasks tasks sentences tasks tasks tasks sentences tasks sentences tasks tasks sentences tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks sentences tasks sentences tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks sentences tasks sentences tasks tasks tasks tasks sentences tasks sentences tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks tasks tasks sentences tasks tasks sentences tasks tasks tasks tasks sentences tasks sentences tasks tasks sentences tasks tasks tasks sentences tasks sentences tasks tasks sentences tasks tasks sentences tasks tasks tasks tasks sentences tasks tasks tasks tasks tasks\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> techniques combining generalized policies search algorithms exploit strengths overcome weaknesses solving probabilistic planning problems\n",
            "Predicted Summary>>> techniques proposes overcome overcome overcome overcome overcome overcome overcome techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques techniques\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> experimentally show transfer learning makes sparse features network thereby produces compressible network\n",
            "Predicted Summary>>> experimentally transfer transfer deep makes transfer transfer text experimentally transfer transfer makes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> increase efficiency neural network dependency parsers teacher student distillation\n",
            "Predicted Summary>>> increase need need need need need need need need need need need need need need need need need need need need need need need need need need need need need need need need \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extend gan architecture obtain control locations identities multiple objects within generated images\n",
            "Predicted Summary>>> propose proposes estimates \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> automatic search multi task architectures reduce per task feature use\n",
            "Predicted Summary>>> propose search task search architectures search architectures search task \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents exploration imitation learning based agent capable state art performance playing text based computer games\n",
            "Predicted Summary>>> work exploration latent clustering operations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model control generation images gan beta vae regard scale position objects\n",
            "Predicted Summary>>> represent generation gan generation generation tasks gan generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation generation\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> revisit idea master slave architecture multi agent deep reinforcement learning outperforms state arts\n",
            "Predicted Summary>>> propose proposes asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel interpretation mixup belonging class highly analogous adversarial training basis introduce simple generalization outperforms mixup\n",
            "Predicted Summary>>> propose belonging belonging belonging belonging belonging belonging belonging adversarial belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging belonging \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improving performance rl agent continuous action state space domain using prioritised experience replay parameter noise\n",
            "Predicted Summary>>> train search encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed model free policy il algorithm continuous control experimental results showed algorithm achieves competitive results gail significantly reducing environment interactions\n",
            "Predicted Summary>>> paper search method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> practical proposal ethical responsive nlp technology operationalizing transparency test training data\n",
            "Predicted Summary>>> system novel nlp nlp nlp nlp nlp nlp nlp nlp nlp \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents scalable solution continuous visual speech recognition\n",
            "Predicted Summary>>> propose presents continuous transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present new weight encoding scheme enables high compression ratio fast sparse dense matrix conversion\n",
            "Predicted Summary>>> propose new tasks task could could \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> semi supervised transfer learning packet flow classification via system cooperative adversarial neural blocks\n",
            "Predicted Summary>>> propose rl transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural module approach continual learning using unified visual environment large action space\n",
            "Predicted Summary>>> propose continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose bayesian quantized networks learn posterior distribution quantized parameters\n",
            "Predicted Summary>>> propose proposes memory quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized quantized\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dynamic bagging methods approach avoiding negatve transfer neural network shot transfer learning\n",
            "Predicted Summary>>> paper transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present agent uses beta vae extract visual features attention mechanism ignore irrelevant features visual observations enable robust transfer visual domains\n",
            "Predicted Summary>>> operations gans models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use monte carlo tree search homoglyphs generate indistinguishable adversarial samples text data\n",
            "Predicted Summary>>> propose proposes algorithm networks problems \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper aims leverage good properties robust visual features like sift renovate cnn architectures towards better accuracy robustness\n",
            "Predicted Summary>>> paper aims augmentation representations augmentation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose algorithm automatically adjusts parameters simulation engine generate training data neural network validation accuracy maximized\n",
            "Predicted Summary>>> propose proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> models generate singing voices without lyrics scores take accompaniment input output singing voices\n",
            "Predicted Summary>>> propose new singing singing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning sample via lower bounding acceptance rate metropolis hastings algorithm\n",
            "Predicted Summary>>> propose domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model agnostic regularization scheme neural network based conditional density estimation\n",
            "Predicted Summary>>> unsupervised agnostic networks tasks scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel dynamic ridesharing framework form trips optimizes operational value service provider user value passengers factoring users social preferences decision making process\n",
            "Predicted Summary>>> propose proposes architecture goal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present provable easily computable evaluation function estimates performance transferred representations one learning task another task transfer learning\n",
            "Predicted Summary>>> propose proposes alternative method easily architecture easily easily easily easily easily easily easily easily easily easily easily easily alternative operations easily easily easily easily easily easily easily easily easily easily \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve tasks involving vision guided humanoid locomotion reusing locomotion behavior motion capture data\n",
            "Predicted Summary>>> propose involving involving involving involving \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> explore neural architecture search language tasks recurrent cell search challenging nmt attention mechanism search works result attention search translation transferable reading comprehension\n",
            "Predicted Summary>>> explore tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate theoretical practical evidence policy reinforcement learning improvement reusing data several consecutive policies\n",
            "Predicted Summary>>> investigate search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce attention mechanism improve feature extraction deep active learning al semi supervised setting\n",
            "Predicted Summary>>> introduce propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce several datasets cyrillic ocr method recognition\n",
            "Predicted Summary>>> propose several cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic ocr cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic cyrillic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning rank using transformer architecture\n",
            "Predicted Summary>>> paper architecture transformer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show individual units cnn representations learned nlp tasks selectively responsive natural language concepts\n",
            "Predicted Summary>>> propose individual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate eigenvalues linear layers deep networks show distributions develop heavy tail behavior training\n",
            "Predicted Summary>>> propose eigenvalues linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear linear\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose generative neural network approach temporally coherent point clouds\n",
            "Predicted Summary>>> propose used search variable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised method detect adversarial samples autoencoder activations reconstruction error space\n",
            "Predicted Summary>>> paper differentially method denoising \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address active learning batch setting noisy oracles use model uncertainty encode decision quality active learning algorithm acquisition\n",
            "Predicted Summary>>> address active oracles oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles oracles oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles oracles oracles setting oracles setting oracles setting oracles setting setting oracles setting oracles oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles oracles oracles setting oracles oracles oracles oracles oracles oracles oracles setting oracles oracles oracles setting oracles oracles oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles oracles setting oracles setting oracles oracles setting oracles oracles oracles oracles oracles oracles oracles oracles setting oracles setting oracles setting oracles oracles setting oracles oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles oracles oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles oracles oracles oracles oracles oracles oracles oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles oracles setting oracles setting oracles oracles oracles setting oracles\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> system rewriting text conditioned multiple controllable attributes\n",
            "Predicted Summary>>> first rewriting rewriting rewriting rewriting \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate implicit syntactic knowledge sentence embeddings using new analysis set grammatically annotated sentences acceptability judgments\n",
            "Predicted Summary>>> propose filter set set set set tasks set tasks set set tasks set set set set set set set tasks knowledge tasks tasks knowledge tasks tasks tasks tasks tasks tasks tasks tasks set tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks set tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual ebm text whose formulation equivalent discriminating human machine generated text study generalization behavior\n",
            "Predicted Summary>>> residual ebm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> insight reason adversarial vulnerability effective defense method adversarial attacks\n",
            "Predicted Summary>>> insight reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason reason method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sparsification fine tuning language models\n",
            "Predicted Summary>>> sparsification used tuning used tuning used tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new framework preconditioner learning derive new forms preconditioners learning methods reveal relationship methods like rmsprop adam adagrad esgd kfac batch normalization etc\n",
            "Predicted Summary>>> paper theoretical metrics tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gan representations examined detail sets representation units found control generation semantic concepts output\n",
            "Predicted Summary>>> show extension show tasks descent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show right loss architecture view predictive learning improves object detection\n",
            "Predicted Summary>>> propose proposes adversarial gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> important consider optimization function space parameter space introduce learning rule reduces distance traveled function space like sgd limits distance traveled parameter space\n",
            "Predicted Summary>>> propose new optimization distance tasks distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approximate determinantal point processes neural nets justify model theoretically empirically\n",
            "Predicted Summary>>> propose determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> short proof equivalence soft learning policy gradients\n",
            "Predicted Summary>>> propose novel memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents empirical analysis role different types image representations probes properties representations task image captioning\n",
            "Predicted Summary>>> propose variants \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce type neural network structurally resistant adversarial attacks even trained unaugmented training sets resistance due stability network units wrt input perturbations\n",
            "Predicted Summary>>> propose several method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose weakly supervised learning method classification localization cancers extremely high resolution histopathology whole slide images using image wide labels\n",
            "Predicted Summary>>> propose proposes adversarial layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural simulation universal turing machine\n",
            "Predicted Summary>>> propose proposes estimates policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> view exploration rl problem matching marginal distribution states\n",
            "Predicted Summary>>> propose proposes problem training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extension gans combining optimal transport primal form energy distance defined adversarially learned feature space\n",
            "Predicted Summary>>> extension extension extension combining optimal feature optimal feature optimal feature optimal feature optimal feature optimal feature optimal feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature optimal feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature feature \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposing new counterfactual based methodology evaluate hypotheses generated saliency maps deep rl agent behavior\n",
            "Predicted Summary>>> propose semi bayesian solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed new task datasets baselines conv cyclegan preserves object properties across frames batch structure frame level methods matters\n",
            "Predicted Summary>>> paper proposes bottleneck \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new metric evaluating conditional gans captures image quality conditional consistency intra conditioning diversity single measure\n",
            "Predicted Summary>>> identify memory tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method uses statistical leverage score information measure importance data samples every task adopts frequent directions approach enable life long learning property\n",
            "Predicted Summary>>> use statistical uses frequent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze impact latent space fully trained generators pseudo inverting\n",
            "Predicted Summary>>> propose theoretical semi used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> take step towards measuring learning task difficulty demonstrate practice performance strongly depends match representation information model interpreting\n",
            "Predicted Summary>>> take networks step models bottom \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn conditionally generate protein sequences given structures model captures sparse long range dependencies\n",
            "Predicted Summary>>> empirical batch batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn convert hand drawn sketch high level program\n",
            "Predicted Summary>>> represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent represent\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show variants importance weighted autoencoders derived principled manner special cases adaptive importance sampling approaches like reweighted wake sleep algorithm\n",
            "Predicted Summary>>> propose variants \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present open loop brain machine interface whose performance unconstrained traditionally used bag words approach\n",
            "Predicted Summary>>> propose novel bottleneck bottleneck method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> game theoretic solution adversarial attacks defenses\n",
            "Predicted Summary>>> propose theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theoretical study multi task learning practical implications improving multi task training transfer learning\n",
            "Predicted Summary>>> propose theoretical matrix transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel gan training method considering certain fake samples real alleviate mode collapse stabilize training process\n",
            "Predicted Summary>>> propose rl used search used search used search used search used search used search used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> self training different views input gives excellent results semi supervised image recognition sequence tagging dependency parsing\n",
            "Predicted Summary>>> propose theoretical propose generator \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel approach spike sorting using neural clustering process ncp recently introduced neural architecture performs scalable amortized approximate bayesian inference efficient probabilistic clustering\n",
            "Predicted Summary>>> addition proposes blurred operations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> general framework creating covariant graph neural networks\n",
            "Predicted Summary>>> propose truly creating \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate framework discovery curating large collection predictions used construct agent representation partially observable domains\n",
            "Predicted Summary>>> investigate framework curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating curating\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> variable capacity input word embeddings sota wikitext billion word benchmarks\n",
            "Predicted Summary>>> propose proposes set set set set set set set set networks set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce online meta learning problem setting better capture spirit practice continual lifelong learning\n",
            "Predicted Summary>>> propose novel method computer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work proves non acceleration nesterov sgd hyper parameters proposes new algorithm provably accelerates sgd parameterized setting\n",
            "Predicted Summary>>> introduce rl gans \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new agi architecture trans sapient performance high level overview omega agi architecture basis data science automation system submitted workshop\n",
            "Predicted Summary>>> propose agi \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> revisit idea master slave architecture multi agent deep reinforcement learning outperforms state arts\n",
            "Predicted Summary>>> propose asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advocate random features theory biological neural networks focusing sparsely connected networks\n",
            "Predicted Summary>>> advocate theoretical features advocate networks learning features features features features features features features features features features features features features features features features features features features features features features features features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose imagenet measure classifier corruption robustness imagenet measure perturbation robustness\n",
            "Predicted Summary>>> propose imagenet measure measure measure measure measure measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure corruption measure\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove large class functions exists interval certified robust network approximating arbitrary precision\n",
            "Predicted Summary>>> propose architecture together together tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> patch based bottleneck formulation vae framework learns unsupervised representations better suited visual recognition\n",
            "Predicted Summary>>> train information information bottleneck method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present bayesian inference model infer contrastive explanations ltl specifications describing two sets plan traces differ\n",
            "Predicted Summary>>> propose transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> asymptotic convergence stochastic subgradien method momentum general parallel asynchronous computation general nonconvex nonsmooth optimization\n",
            "Predicted Summary>>> asymptotic proposes stochastic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply model agnostic defense strategy adversarial examples achieve white box accuracy black box accuracy major attack algorithms\n",
            "Predicted Summary>>> unsupervised easy trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed specific back propagation method via proper spectral sub gradient integrate determinantal point process deep learning framework\n",
            "Predicted Summary>>> train propose use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning preferences plan traces using active learning\n",
            "Predicted Summary>>> propose preferences preferences train method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> safety becoming critical notion machine learning believe work act foundation number research directions safety aware learning algorithms\n",
            "Predicted Summary>>> safety becoming safety becoming safety becoming safety becoming safety safety becoming safety becoming safety safety becoming safety becoming \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop efficient multi scale approximate attributed network embedding procedures provable properties\n",
            "Predicted Summary>>> paper method global \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> consider problem learning optimal policies time limited time unlimited domains using time limited interactions\n",
            "Predicted Summary>>> propose rl propose generator transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel bit format eliminates need loss scaling stochastic rounding low precision techniques\n",
            "Predicted Summary>>> propose eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates eliminates\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose simple self supervised data augmentation technique improves performance fully supervised scenarios including shot learning imbalanced classification\n",
            "Predicted Summary>>> propose augmentation augmentation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarial nets attention mechanism positron images data scarcity\n",
            "Predicted Summary>>> method gan text data gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce three generic point cloud processing blocks improve accuracy memory consumption multiple state art networks thus allowing design deeper accurate networks\n",
            "Predicted Summary>>> inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired inspired\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> simple generative approach solve word analogy problem yields insights word relationships problems estimating\n",
            "Predicted Summary>>> propose new solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> estimation training data distribution trained classifier using gan\n",
            "Predicted Summary>>> propose gan trained data trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn unsupervised learning algorithm produces useful representations set supervised tasks test time apply algorithm new tasks without supervision show performance comparable vae\n",
            "Predicted Summary>>> learned learned tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> residual ebm text whose formulation equivalent discriminating human machine generated text study generalization behavior\n",
            "Predicted Summary>>> residual ebm residual ebm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generate wikipedia articles abstractively conditioned source document text\n",
            "Predicted Summary>>> propose method adversarial layer layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposed novel algorithm gendice general stationary distribution correction estimation handle discounted average policy evaluation multiple behavior agnostic samples\n",
            "Predicted Summary>>> propose novel new used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach graph classification based spectral graph convolutional networks extension multigraphs learnable relations hierarchical structure show state art results chemical social image datasets\n",
            "Predicted Summary>>> propose matrix architecture matrix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using novel representation symmetric linear dynamical systems latent state formulate optimal control convex program giving first polynomial time algorithm solves optimal control sample complexity polylogarithmic time horizon\n",
            "Predicted Summary>>> propose proposes symmetric symmetric continual symmetric symmetric continual symmetric continual symmetric \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dl model rna secondary structure prediction uses unrolled algorithm architecture enforce constraints\n",
            "Predicted Summary>>> dl represent unrolled enforce unrolled enforce set enforce enforce enforce set enforce set enforce enforce unrolled enforce enforce set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> closed form results deep learning layer decoupling limit applicable residual networks\n",
            "Predicted Summary>>> closed form \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method inferring model estimating entropy rate predicting continuous time discrete event processes\n",
            "Predicted Summary>>> propose proposes entropy entropy entropy inferring \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> finding correspondences domains performing matching mapping iterations\n",
            "Predicted Summary>>> propose correspondences correspondences domain correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences correspondences noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspiration local dendritic processes neocortical learning make unsupervised learning great\n",
            "Predicted Summary>>> inspiration inspiration local local used local local local local local local local local local local local used local local dendritic dendritic local local local used local used local used local used local used local used local local used local used local local local local local local local local local used local local local local used local used local local local local local local local local local local local local local local used local local local local local local local local local local local local local local local local used local local local local local local local local local local local local local local local local local local local local local local local used local local local local local local local local local local local local local local local local local local local local local local local local local local local local local used local local local local used local used local used local local local local local local local local used local local local used local local local local local local local local local local local local local local local local local local local local local local local local local local local local local local local local used local used local used local local used local used local local local local local local local local local used local used local used local local local local local local local local local local local local local used local local used local local local local local local local local local local local local local local used local local used local\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop simple general approach avoiding interference gradients different tasks improves performance multi task learning supervised reinforcement learning domains\n",
            "Predicted Summary>>> develop novel method general \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining imitation learning reinforcement learning learn outperform expert\n",
            "Predicted Summary>>> stochastic proposes stochastic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce machine learning model uses domain independent features estimate criticality current state cause known undesirable state\n",
            "Predicted Summary>>> propose first uses uses uses trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> semi supervised multi modal classification framework tcn outperforms various benchmarks\n",
            "Predicted Summary>>> use proposes used policy used policy used policy used policy used used policy used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique automatically labeling large unlabeled datasets train source models transfer learning experimental evaluation\n",
            "Predicted Summary>>> propose augmented transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present sign based rather magnitude based gradient estimation approach shifts gradient estimation continuous binary black box optimization\n",
            "Predicted Summary>>> combine deep shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose reinforcement learning based variable swapping recomputation algorithm reduce memory cost\n",
            "Predicted Summary>>> propose branch tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> intuitive empirical visual exploration generalization properties deep neural networks\n",
            "Predicted Summary>>> propose proposes based generation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combination multi task learning self attention training model attend parents syntactic parse tree achieves state art conll conll srl results models using predicted predicates\n",
            "Predicted Summary>>> propose combination \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new method training deep hashing image retrieval using relational distance metric samples\n",
            "Predicted Summary>>> propose method tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative adversarial network style modeling text speech system\n",
            "Predicted Summary>>> data generative models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generalized bert continuous cross modal inputs state art self supervised video representations\n",
            "Predicted Summary>>> generalized simple layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> redistributing growing weights according momentum magnitude enables training sparse networks random initializations reach dense performance levels weights accelerating training\n",
            "Predicted Summary>>> propose momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel practically effective method adapt pretrained neural networks new tasks retraining minimal less number parameters\n",
            "Predicted Summary>>> propose effective method tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> smooth regularization sample graph unpaired image image translation results significantly improved consistency\n",
            "Predicted Summary>>> empirical sample sample sample sample sample sample \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sequence model dynamically adjusts amount computation input\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generative memory model combines slow learning neural networks fast adapting linear gaussian model memory\n",
            "Predicted Summary>>> propose new used slow tasks search slow slow slow slow slow slow slow slow slow slow \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use deep reinforcement learning design physical attributes robot jointly control policy\n",
            "Predicted Summary>>> analyze memory represent represent represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce continuous logic network cln novel neural architecture automatically learning loop invariants general smt formulas\n",
            "Predicted Summary>>> propose several logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic logic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> meta learning methods used vision directly applied nlp perform worse nearest neighbors new classes better distributional signatures\n",
            "Predicted Summary>>> paper used architecture used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing network architecture set syntax trees optimizing structure leads accurate concise regression models\n",
            "Predicted Summary>>> propose use set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learned data augmentation instills algorithm favoring inductive biases let rnns learn list processing algorithms fewer examples\n",
            "Predicted Summary>>> propose proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theoretical framework deep relu network explains multiple puzzling phenomena like parameterization implicit regularization lottery tickets etc\n",
            "Predicted Summary>>> propose rl train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose suite metrics capture desired properties explainability algorithms use objectively compare evaluate methods\n",
            "Predicted Summary>>> present suite high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose four new ways collecting nli data help slightly pretraining data help reduce annotation artifacts\n",
            "Predicted Summary>>> propose new four trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce large scale receipt dataset post ocr parsing tasks\n",
            "Predicted Summary>>> propose asynchronous set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper aims leverage good properties robust visual features like sift renovate cnn architectures towards better accuracy robustness\n",
            "Predicted Summary>>> paper aims augmentation augmentation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient dictionary learning minimization via novel analysis non convex non smooth geometry\n",
            "Predicted Summary>>> paper novel minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> large scale multi task architecture solves imagenet translation together shows transfer learning\n",
            "Predicted Summary>>> propose tasks multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> give method generating type safe programs java like language given small amount syntactic information desired code\n",
            "Predicted Summary>>> propose proposes used method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> action dependent baselines bias free yield greater variance reduction state dependent baselines policy gradient methods\n",
            "Predicted Summary>>> propose rl asynchronous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces domain independent compilations user questions constraints contrastive explanations\n",
            "Predicted Summary>>> propose bayesian compilations compilations compilations compilations compilations compilations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> data augmentation adversarial training effective disentangling correlated speaker noise enabling independent control attribute text speech synthesis\n",
            "Predicted Summary>>> propose training adversarial training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> query based black box attacks deep neural networks adversarial success rates matching white box attacks\n",
            "Predicted Summary>>> query new box \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique automatically labeling large unlabeled datasets train source models transfer learning experimental evaluation\n",
            "Predicted Summary>>> propose augmented transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel algorithm hierarchical subtask discovery leverages multitask linear markov decision process framework\n",
            "Predicted Summary>>> propose proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use transformer encoder translation training style masked translation model\n",
            "Predicted Summary>>> propose studies create learning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> ground language commands high dimensional visual environment learning language conditioned rewards using inverse reinforcement learning\n",
            "Predicted Summary>>> paper novel commands \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural module approach continual learning using unified visual environment large action space\n",
            "Predicted Summary>>> propose continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new combination evolution strategy deep reinforcement learning takes best worlds\n",
            "Predicted Summary>>> propose proposes solve solve solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning detect objects without image labels minutes video\n",
            "Predicted Summary>>> unsupervised detect detect detect detect detect detect detect detect objects detect objects video tasks detect objects detect objects detect objects detect detect objects detect objects detect objects detect detect detect objects detect objects detect tasks detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect detect detect tasks networks tasks detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects tasks detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect objects detect\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> intuitive empirical visual exploration generalization properties deep neural networks\n",
            "Predicted Summary>>> propose proposes based generation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> multi relational graph embedding riemannian manifolds transe like loss function\n",
            "Predicted Summary>>> paper proposes tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> build artificial agents solve social dilemmas situations individuals face temptation increase payoffs cost total welfare\n",
            "Predicted Summary>>> build agents scaling \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model agnostic regularization scheme neural network based conditional density estimation\n",
            "Predicted Summary>>> unsupervised agnostic networks tasks scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme scheme train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sequence model dynamically adjusts amount computation input\n",
            "Predicted Summary>>> propose rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve tasks involving vision guided humanoid locomotion reusing locomotion behavior motion capture data\n",
            "Predicted Summary>>> propose involving involving \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel multi task learning framework extracts multi view dependency relationship automatically use guide knowledge transfer among different tasks\n",
            "Predicted Summary>>> propose special domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new auto encoder based wasserstein distance improves sampling properties vae\n",
            "Predicted Summary>>> propose proposes modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules modules \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present software framework transforming distributions demonstrate flexibility relaxing mean field assumptions variational inference use coupling flows replicate structure target generative model\n",
            "Predicted Summary>>> propose software software transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> design adversarial training method bayesian neural networks showing much stronger defense white box adversarial attacks\n",
            "Predicted Summary>>> propose search search algorithm computation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> meta learn learning algorithm capable causal reasoning\n",
            "Predicted Summary>>> use theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical theoretical learn theoretical theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> found adversarial training speeds gan training also increases image quality\n",
            "Predicted Summary>>> propose novel gan also \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> byte level recurrent language models learn high quality domain specific representations text\n",
            "Predicted Summary>>> byte level models tasks sequence sequence sequence sequence sequence sequence \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neural network pruning zeroing pruned weights important sign initialization key masking thought training\n",
            "Predicted Summary>>> propose lp lp cells \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use vaes learn shared latent space embedding image features attributes thereby achieve state art results generalized zero shot learning\n",
            "Predicted Summary>>> propose studies latent domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning imitate expert absence optimal actions learning dynamics model exploring environment\n",
            "Predicted Summary>>> imitate imitate method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> weakly supervised text based video moment retrieval\n",
            "Predicted Summary>>> propose search search search search search search search search search search search search text search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using adaptive sampling methods accelerate rare event probability evaluation estimate probability accident base distribution governing standard traffic behavior\n",
            "Predicted Summary>>> propose rl based solve tasks solve solve solve two solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> outputs modern nlp apis nonsensical text provide strong signals model internals allowing adversaries steal apis\n",
            "Predicted Summary>>> outputs modern nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp nlp\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new approach conditional generation constraining latent space unconditional generative model\n",
            "Predicted Summary>>> propose deep method generation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduce training method called look table quantization lut learns dictionary assigns weight one dictionary values\n",
            "Predicted Summary>>> propose novel set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> faster method generating node embeddings employs number permutations node immediate neighborhood context generate representation\n",
            "Predicted Summary>>> faster generate generating generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show inclusion extra gradient step first order gan training methods improve stability lead improved convergence results\n",
            "Predicted Summary>>> inclusion extra inclusion networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents scalable algorithm non linear offline system identification partial observations\n",
            "Predicted Summary>>> propose linear models linear \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper describes strategic intrinsically motivated learning algorithm tackles learning complex motor policies\n",
            "Predicted Summary>>> train describes describes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> extend recent insights related softmax consistency achieve state art results continuous control\n",
            "Predicted Summary>>> extend recent recent recent recent recent recent recent recent recent solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel architecture traverses image pyramid top fashion visits informative regions along way\n",
            "Predicted Summary>>> propose architecture traverses method traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses traverses\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> modern deep cnns invariant translations scalings realistic image transformations lack invariance related subsampling operation biases contained image datasets\n",
            "Predicted Summary>>> propose real used used used used used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present rl agent minerva learns walk knowledge graph answer queries\n",
            "Predicted Summary>>> propose rl minerva rl minerva rl minerva rl minerva rl minerva rl minerva rl minerva \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improved pretraining analysing encoder output attention\n",
            "Predicted Summary>>> improved pretraining pretraining pretraining analysing output pretraining pretraining analysing output pretraining pretraining pretraining analysing output pretraining pretraining pretraining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present kg reinforcement learning agent builds dynamic knowledge graph exploring generates natural language using template based action space outperforming current agents wide set text based games\n",
            "Predicted Summary>>> train kg \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> lossless compression large image datasets using vae beat existing compression algorithms\n",
            "Predicted Summary>>> compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression compression \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposing new score based approach structure causal learning leveraging neural networks recent continuous constrained formulation problem\n",
            "Predicted Summary>>> propose score transfer score transfer score transfer score tasks transfer score tasks transfer score score score score score score score score score score score score score \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show working memory input reservoir network makes local reward modulated hebbian rule perform well recursive least squares aka force\n",
            "Predicted Summary>>> propose method memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces domain independent compilations user questions constraints contrastive explanations\n",
            "Predicted Summary>>> propose novel compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations compilations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> handling uncertainty visual perception plan recognition\n",
            "Predicted Summary>>> handling perception \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel ensemble retrieval based generation based open domain conversation systems\n",
            "Predicted Summary>>> ensemble introduces transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce approach allow agents learn ppddl action models incrementally multiple planning problems framework reinforcement learning\n",
            "Predicted Summary>>> propose presents \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce machine learning model uses domain independent features estimate criticality current state cause known undesirable state\n",
            "Predicted Summary>>> propose first uses uses uses uses trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> conventional memory networks generate many redundant latent vectors resulting overfitting need larger memories introduce memory dropout automatic technique encourages diversity latent space\n",
            "Predicted Summary>>> conventional memory memory memory memory memory memory memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> accurate forecasting long time horizons using tensor train rnns\n",
            "Predicted Summary>>> use memory use forecasting horizons tasks horizons \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce extra data dependent gaussian prior objective augment current mle training designed capture prior knowledge ground truth data\n",
            "Predicted Summary>>> propose proposes general image \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural cascades simple trivially parallelizable approach reading comprehension consisting feed forward nets attention achieves state art performance triviaqa dataset\n",
            "Predicted Summary>>> unsupervised introduces variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training agents adaptive computation based information bottleneck promote generalization\n",
            "Predicted Summary>>> propose adaptive computation tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> view exploration rl problem matching marginal distribution states\n",
            "Predicted Summary>>> propose proposes factorization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train predictive models proprioceptive information show represent properties external objects\n",
            "Predicted Summary>>> propose predictive models adversarial models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new form attention works well distant supervision setting multitask learning approach add sentence level annotations\n",
            "Predicted Summary>>> adding form tasks well improve well well set well well well well well well set well set well well set well set well set well set well set well set well set well set well set well set well set well set well set well set well set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply ordinary differential equation model graph structured data\n",
            "Predicted Summary>>> apply differential tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper use sliced wasserstein distance shape latent distribution auto encoder samplable prior distribution\n",
            "Predicted Summary>>> goal propose sliced sliced samplable distribution samplable distribution samplable distribution samplable sliced distribution samplable samplable samplable distribution samplable distribution samplable \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new pretraining method establishes new state art results glue race squad benchmarks fewer parameters compared bert large\n",
            "Predicted Summary>>> novel pretraining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose use meta learning efficient language learning via kind domain randomization\n",
            "Predicted Summary>>> use theoretical use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces clustering based active learning algorithm graphs\n",
            "Predicted Summary>>> paper novel text \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop engaging image captioning models conditioned personality also state art regular captioning tasks\n",
            "Predicted Summary>>> develop engaging captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning captioning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present mixed media assembly tutorial authoring system streamlines creation videos images text dynamic instructions situ\n",
            "Predicted Summary>>> media media media media media media media media \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work presents kronecker factorization recurrent weight matrices parameter efficient well conditioned recurrent neural networks\n",
            "Predicted Summary>>> propose kronecker transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper develops framework integrating user feedback identity uncertainty knowledge bases\n",
            "Predicted Summary>>> paper develops networks noise integrating policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> bayesian optimization based online hyperparameter optimization\n",
            "Predicted Summary>>> paper architecture networks task \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scale generative classifiers complex datasets evaluate effectiveness reject illegal inputs including distribution samples adversarial examples\n",
            "Predicted Summary>>> propose adversarial examples examples perturbation examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples examples \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> graph neural network assisted monte carlo tree search approach traveling salesman problem\n",
            "Predicted Summary>>> propose rl tree tree tree tree tree tree \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> algorithm unifying sgd adam empirical study performance\n",
            "Predicted Summary>>> train matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> initial findings intersection network neuroscience deep learning elegans mouse visual cortex learn recognize handwritten digits\n",
            "Predicted Summary>>> initial findings method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel adversarial learning framework structured prediction discriminative models used refine structured prediction models inference stage\n",
            "Predicted Summary>>> unsupervised proposes unsupervised used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> spatial information last layers necessary good classification accuracy\n",
            "Predicted Summary>>> propose last last last last last layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers last last layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers layers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce dcn deep residual coattention mixed objective rl achieves state art performance stanford question answering dataset\n",
            "Predicted Summary>>> propose provides create \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> variation network generative model able learn high level attributes without supervision used controlled input manipulation\n",
            "Predicted Summary>>> propose variational multiple variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose structure generator gan consider objects relations explicitly generate images means composition\n",
            "Predicted Summary>>> propose generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator generator\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show question answer matching particularly good pre training task question similarity release dataset medical question similarity\n",
            "Predicted Summary>>> propose question question answer question answer question answer question answer question question question question question question particularly question particularly question particularly particularly particularly particularly particularly question question particularly question question question question question question question question question question question particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly question particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly particularly\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> built physical simulation rodent trained solve set tasks analyzed resulting networks\n",
            "Predicted Summary>>> propose first physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical physical\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> comparison detailed analysis various sentence embedding models real world task automatic summarization\n",
            "Predicted Summary>>> propose several method train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new module improves resnet like architectures enforcing channel selective behavior convolutional layers\n",
            "Predicted Summary>>> propose resnet tasks functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> joint method learning cross lingual embeddings state art performance cross lingual tasks mono lingual quality\n",
            "Predicted Summary>>> unified represent proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate strong regularization fails propose method achieve strong regularization\n",
            "Predicted Summary>>> propose new strong \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop task agnosticlly compressed bert smaller faster bert base achieving competitive performance glue squad\n",
            "Predicted Summary>>> develop bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert bert \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new form attention works well distant supervision setting multitask learning approach add sentence level annotations\n",
            "Predicted Summary>>> adding form training well set well tasks well set well well well well well set well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well set form well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well well\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn lstm generate markup like code describing graphical user interface images\n",
            "Predicted Summary>>> cnn lstm lstm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> trust neural network explanation prediction examine robustness several popular notions interpretability neural networks including saliency maps influence functions design adversarial examples\n",
            "Predicted Summary>>> trust method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide first time rigorous proof orthogonal initialization speeds convergence relative gaussian initialization deep linear networks\n",
            "Predicted Summary>>> train rigorous \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> backward model previous state action given next state used simulate additional trajectories terminating states interest improves rl learning efficiency\n",
            "Predicted Summary>>> propose proposes noise \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model data generator gan means high order polynomial represented high order tensors\n",
            "Predicted Summary>>> propose generator generator generator generator generator generator generator generator generator generator gan generator generator gan generator generator gan generator gan generator generator generator generator gan generator high means \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new order decoder neural machine translation\n",
            "Predicted Summary>>> propose sparsity encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove exist relu networks whose parameters almost uniquely determined function implement\n",
            "Predicted Summary>>> propose exist exist exist \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new auto encoder incorporated multiway delay embedding transform toward interpreting deep image prior\n",
            "Predicted Summary>>> propose proposes incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated incorporated \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel ensemble retrieval based generation based open domain conversation systems\n",
            "Predicted Summary>>> ensemble novel transfer tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel multi task framework learns table detection semantic component recognition cell type classification spreadsheet tables promising results\n",
            "Predicted Summary>>> propose new transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose algorithm automatically adjusts parameters simulation engine generate training data neural network validation accuracy maximized\n",
            "Predicted Summary>>> propose novel \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural hyperlink predictor nhp nhp adapts graph convolutional networks link prediction hypergraphs\n",
            "Predicted Summary>>> paper novel proposes predictor predictor predictor predictor predictor predictor predictor \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generate effective hash codes efficient cold start recommendation meanwhile provide feasible marketing strategy\n",
            "Predicted Summary>>> propose lightweight architecture codes codes codes codes codes codes codes codes codes codes codes codes codes codes codes codes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy gradient backpropagation time using learned models functions sota results reinforcement learning benchmark environments\n",
            "Predicted Summary>>> policy backpropagation backpropagation backpropagation learned backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation backpropagation learned backpropagation backpropagation backpropagation learned backpropagation backpropagation backpropagation backpropagation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> semi supervised multi modal classification framework tcn outperforms various benchmarks\n",
            "Predicted Summary>>> use proposes used policy used policy used policy used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> implementing evaluating episodic memory rl\n",
            "Predicted Summary>>> implementing clustering clustering train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present open loop brain machine interface whose performance unconstrained traditionally used bag words approach\n",
            "Predicted Summary>>> propose bottleneck bottleneck bottleneck bottleneck bottleneck bottleneck bottleneck bottleneck method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> train combination neural networks predict optimal trajectories complex physical systems\n",
            "Predicted Summary>>> train combination \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper presents theoretical framework models data distribution explicitly deep locally connected relu network\n",
            "Predicted Summary>>> identify proposes theoretical relu tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proves skinny neural networks cannot approximate certain functions matter deep\n",
            "Predicted Summary>>> propose skinny skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny functions skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny functions skinny functions skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny skinny functions skinny functions functions functions functions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce method train models provable robustness wrt norms geq simultaneously\n",
            "Predicted Summary>>> paper theoretical train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> architecture enables cnn trained video sequences converging rapidly\n",
            "Predicted Summary>>> propose proposes called \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> convert subgraphs structured images classify using deep learning transfer learning caffe achieve stunning results\n",
            "Predicted Summary>>> propose subgraphs algorithm regression \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compressing word embeddings without hurting performance\n",
            "Predicted Summary>>> compressing compressing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present hierarchical learning framework navigation within embodied learning setting\n",
            "Predicted Summary>>> propose deep transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy learning bandit feedbacks propose new variance regularized counterfactual learning algorithm theoretical foundations superior empirical performance\n",
            "Predicted Summary>>> develop tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> biologically plausible learning algorithms particularly sign symmetry work well imagenet\n",
            "Predicted Summary>>> propose characterizes transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> memory augmented network plan partially observable environments\n",
            "Predicted Summary>>> propose augmented domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> apply reinforcement learning score based causal discovery achieve promising results synthetic real datasets\n",
            "Predicted Summary>>> paper proposes high models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> directional message passing incorporates spatial directional information improve graph neural networks\n",
            "Predicted Summary>>> directional message directional directional directional directional directional directional directional directional directional \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> omniglot miniimagenet simple shot learning solve without using labels meta evaluation demonstrated method called centroid networks\n",
            "Predicted Summary>>> omniglot method create \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> node sequence embedding mechanism captures graph text properties\n",
            "Predicted Summary>>> node sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new pooling layer gnns learns pool nodes according features graph connectivity dowstream task objective\n",
            "Predicted Summary>>> propose rl method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first differentially private estimate survival function\n",
            "Predicted Summary>>> paper differentially private differentially private \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> prove gradient descent robust label corruption despite parameterization rich dataset model\n",
            "Predicted Summary>>> prove theoretical label \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> estimation training data distribution trained classifier using gan\n",
            "Predicted Summary>>> propose gan trained data trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained trained\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> logit regularization methods help explain improve state art adversarial defenses\n",
            "Predicted Summary>>> logit used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using dsl grammar reinforcement learning improve synthesis programs complex control flow\n",
            "Predicted Summary>>> good dsl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approach combine variational inference bayesian optimisation solve complicated inverse problems\n",
            "Predicted Summary>>> propose method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> comparison siamese neural networks gans vat shot learning\n",
            "Predicted Summary>>> comparison vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat vat\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new objective measurement evaluating explanations based notion adversarial robustness evaluation criteria allows us derive new explanations capture pertinent features qualitatively quantitatively\n",
            "Predicted Summary>>> propose large tasks policy networks tasks policy tasks policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose learn dialogue system independently parameterizes different dialogue skills learns select combine attention parameters aop\n",
            "Predicted Summary>>> paper propose system functions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem alleviating instability issue gan training procedure via new architecture design theoretical guarantees\n",
            "Predicted Summary>>> goal instability \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> conventional memory networks generate many redundant latent vectors resulting overfitting need larger memories introduce memory dropout automatic technique encourages diversity latent space\n",
            "Predicted Summary>>> conventional memory memory memory memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> perform depth investigation suitability self attention models character level neural machine translation\n",
            "Predicted Summary>>> investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation investigation\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces neuromodulation artificial neural networks\n",
            "Predicted Summary>>> paper deep algorithm neuromodulation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised networks learn bottom machines infants acquire visual classes different orders\n",
            "Predicted Summary>>> propose provable provable machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines machines\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> identify decision states agent take actions matter without reward supervision use transfer\n",
            "Predicted Summary>>> identify memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose neural framework learn solve circuit satisfiability problem unlabeled circuit instances\n",
            "Predicted Summary>>> propose solve domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new methods evaluating quantifying quality synthetic gan distributions perspective classification tasks\n",
            "Predicted Summary>>> train space \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approximate inference algorithm deep learning\n",
            "Predicted Summary>>> propose several techniques \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose arbitrarily conditioned data imputation framework built upon variational autoencoders normalizing flows\n",
            "Predicted Summary>>> propose arbitrarily conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned conditioned\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> solve gradient vanishing exploding problems proprose efficient parametrization transition matrix rnn loses expressive power converges faster good generalization\n",
            "Predicted Summary>>> solve novel solve solve solve \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose memory efficient learning procedure exploits reversibility network layers enable data driven design large scale computational imaging\n",
            "Predicted Summary>>> propose pretraining learning graphs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introducing notion optimal representation space provide theoretical argument experimental validation unsupervised model sentences perform well supervised similarity unsupervised transfer tasks\n",
            "Predicted Summary>>> train theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose novel regularized adversarial training framework atlpa namely adversarial tolerant logit pairing attention\n",
            "Predicted Summary>>> method training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show simplified learning task parameterization improves generalization convnet trained gradient descent\n",
            "Predicted Summary>>> propose simplified learning simplified batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose swap distributed algorithm large batch training neural networks\n",
            "Predicted Summary>>> propose bayesian batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose self adversarial learning sal paradigm improves generator self play fashion improving gans performance text generation\n",
            "Predicted Summary>>> propose self gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> skip connection resnet batch normalization improve data separation ability help train deep neural network\n",
            "Predicted Summary>>> skip proposes train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose adversarial training approach problem clarification question generation uses answer question model reward\n",
            "Predicted Summary>>> paper overcomes overcomes representations overcomes overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes representations overcomes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel adaptive instance normalization based gan framework non parallel many many zero shot vc\n",
            "Predicted Summary>>> instance adaptive instance instance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel method leverages gradients differentiable simulators improve performance rl robotics control\n",
            "Predicted Summary>>> propose novel improve leverages leverages leverages leverages \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate deep representation untrained random weight cnn dcn architectures show image reconstruction quality possible applications\n",
            "Predicted Summary>>> investigate memory domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aiming boosting existing pruning mimic method\n",
            "Predicted Summary>>> propose aiming aiming aiming aiming aiming need \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> incorporating model latent variables encode future content improves long term prediction accuracy critical better planning model based rl\n",
            "Predicted Summary>>> propose studies interactions interactions transfer interactions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> insights domain adaptation challenge predicting user intent enterprise email\n",
            "Predicted Summary>>> novel tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn model pruning method using ista rescaling trick enforce sparsity scaling parameters batch normalization\n",
            "Predicted Summary>>> cnn scaling pruning pruning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show removing constant terms cnn architectures provides interpretability denoising method via linear algebra techniques also boosts generalization performance across noise levels\n",
            "Predicted Summary>>> propose removing removing removing \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose self attention based gan architecture unconditional text generation improve previous adversarial code based results\n",
            "Predicted Summary>>> propose self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self self\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces network architecture solve structure motion sfm problem via feature bundle adjustment ba\n",
            "Predicted Summary>>> use search search features search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analysis solve non convergence issue adam\n",
            "Predicted Summary>>> address search rule rule rule rule rule rule rule rule rule rule rule \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> evaluate new ml learning algorithms biological plausibility abstract based mathematical operations needed\n",
            "Predicted Summary>>> propose domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> regularization based approach continual learning using bayesian neural networks predict parameters importance\n",
            "Predicted Summary>>> improved proposes regularization classification \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel adversarial learning framework structured prediction discriminative models used refine structured prediction models inference stage\n",
            "Predicted Summary>>> unsupervised proposes used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> strokenet novel architecture agent trained draw strokes differentiable simulation environment could effectively exploit power back propagation\n",
            "Predicted Summary>>> strokenet domain architecture \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new model latently invertible autoencoder proposed solve problem variational inference vae using invertible network two stage adversarial training\n",
            "Predicted Summary>>> propose variational autoencoder variational stage stage variational stage variational stage stage stage stage stage variational stage variational stage variational stage variational stage variational stage stage stage stage variational stage variational stage stage stage stage stage variational stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> high object detection accuracy obtained training domain specific compact models training short\n",
            "Predicted Summary>>> high high high high high high high high high high tasks high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose matrix completion based task clustering algorithm deep multi task shot learning settings large numbers diverse tasks\n",
            "Predicted Summary>>> train rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose hippo stable hierarchical reinforcement learning algorithm train several levels hierarchy simultaneously giving good performance skill discovery adaptation\n",
            "Predicted Summary>>> use rl single \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> safety becoming critical notion machine learning believe work act foundation number research directions safety aware learning algorithms\n",
            "Predicted Summary>>> safety becoming safety safety becoming safety becoming safety becoming safety becoming safety \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present ontology based neural network architectures sound event classification\n",
            "Predicted Summary>>> develop ontology \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> grid based document representation contextualized embedding vectors documents layouts\n",
            "Predicted Summary>>> grid propose deep grid \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> classification problems classes show gradient tends live tiny slowly evolving subspace spanned eigenvectors corresponding largest eigenvalues hessian\n",
            "Predicted Summary>>> propose method transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show creatively designed trained rnn architectures decode well known sequential codes achieve close optimal performances\n",
            "Predicted Summary>>> propose creatively creatively deep measure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose variational inference based approach encouraging inference disentangled latents also propose new metric quantifying disentanglement\n",
            "Predicted Summary>>> propose general general general general general general general general general general general general general general general general general general general general general general layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> quantum algorithm expectation maximization fast runtime depends polylogarithmically number elements dataset\n",
            "Predicted Summary>>> paper method maximization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work proves non acceleration nesterov sgd hyper parameters proposes new algorithm provably accelerates sgd parameterized setting\n",
            "Predicted Summary>>> introduce rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> policy learning bandit feedbacks propose new variance regularized counterfactual learning algorithm theoretical foundations superior empirical performance\n",
            "Predicted Summary>>> develop tuning tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study deep ensembles lens loss landscape space predictions demonstrating decorrelation power random initializations unmatched subspace sampling explores single mode\n",
            "Predicted Summary>>> propose proposes lens \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate space efficiency memory augmented neural nets learning set membership\n",
            "Predicted Summary>>> propose generator algorithm memory generator variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new pretraining method establishes new state art results glue race squad benchmarks fewer parameters compared bert large\n",
            "Predicted Summary>>> novel pretraining \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing melodies images semantic units aligned generate using dcgan without recurrent components\n",
            "Predicted Summary>>> propose melodies melodies melodies aligned melodies aligned \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gans successful adversarial training use convnets show convnet generator trained simple reconstruction loss learnable noise vectors leads many desirable properties gan\n",
            "Predicted Summary>>> represent proposes modeling \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> pointer network architecture ranking items learned click logs\n",
            "Predicted Summary>>> pointer novel method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present sign based rather magnitude based gradient estimation approach shifts gradient estimation continuous binary black box optimization\n",
            "Predicted Summary>>> combine deep estimation estimation estimation estimation estimation estimation estimation estimation estimation shifts shifts shifts shifts shifts shifts shifts shifts shifts shifts \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel distillation techniques enable training student models different vocabularies compress bert minor performance drop\n",
            "Predicted Summary>>> goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal goal\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use transformer encoder translation training style masked translation model\n",
            "Predicted Summary>>> propose augmentation learning image create \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel network architecture learning compact efficient deep neural networks\n",
            "Predicted Summary>>> propose semi training semi semi semi semi semi training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> meta learning curiosity algorithms searching rich space programs yields novel mechanisms generalize across different reinforcement learning domains\n",
            "Predicted Summary>>> propose curiosity curiosity searching \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce diagnostic task variation shot learning introduce dataset\n",
            "Predicted Summary>>> paper proposes proposes proposes proposes proposes proposes proposes proposes proposes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduces extreme value theory means measure similarity proposes novel algorithm called extreme value means clustering\n",
            "Predicted Summary>>> paper conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational conversational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> deep rl policies attacked agents taking actions create natural observations adversarial\n",
            "Predicted Summary>>> create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create tasks create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> continental philosophy inspired approach learn data\n",
            "Predicted Summary>>> continental improves models \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> detecting overlapping communities graphs using graph neural networks\n",
            "Predicted Summary>>> propose overlapping communities graphs graphs tasks transfer using architecture transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce amortized proximal optimization apo method adapt variety optimization hyperparameters online training including learning rates damping coefficients gradient variance exponents\n",
            "Predicted Summary>>> train memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method encouraging axiomatic feature attributions deep model match human intuition\n",
            "Predicted Summary>>> propose encouraging used axiomatic attributions attributions attributions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> multi task learning improves word character level speech recognition interpolating preference biases components frequency word length preference\n",
            "Predicted Summary>>> propose pretraining step preference preference preference preference preference preference preference policy step \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reinforcement learning based conversational search assistant provides contextual assistance subjective search like digital assets\n",
            "Predicted Summary>>> propose search search search search conversational search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search search\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new framework using dual space generating images corresponding multiclass labels number class large\n",
            "Predicted Summary>>> propose proposes computational sgd \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> neumann networks end end sample efficient learning approach solving linear inverse problems imaging compatible mse optimal approach admit extension patch based learning\n",
            "Predicted Summary>>> neumann end networks sample \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper study new graph learning problem learning count subgraph isomorphisms\n",
            "Predicted Summary>>> study study study problem learning adversarial set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> view exploration rl problem matching marginal distribution states\n",
            "Predicted Summary>>> propose proposes training \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> design simple efficient model free policy method image based reinforcement learning matches state art model based methods sample efficiency\n",
            "Predicted Summary>>> propose rl techniques \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present generative model proves state art results gray scale natural images\n",
            "Predicted Summary>>> present transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> handling uncertainty visual perception plan recognition\n",
            "Predicted Summary>>> handling perception \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose approach generate realistic high fidelity stock market data based generative adversarial networks\n",
            "Predicted Summary>>> generate generate realistic realistic realistic \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel architecture memory based attention mechanism multi agent communication\n",
            "Predicted Summary>>> develop memory step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose ae based gan alleviates mode collapse gans\n",
            "Predicted Summary>>> propose ae used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> combining auxiliary adversarial training interrogate help physical understanding\n",
            "Predicted Summary>>> auxiliary proposes adversarial interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate interrogate\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop novel approach model object compositionality images gan framework\n",
            "Predicted Summary>>> propose agent transfer agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent agent networks used transfer used used transfer used transfer used transfer used object used transfer used used transfer used used used transfer used transfer used transfer used transfer used used transfer used transfer used used transfer used transfer used transfer used transfer used used used transfer used transfer used transfer used used transfer used used transfer used used transfer used transfer used transfer used transfer used transfer used transfer used used transfer used used transfer used transfer used transfer used used transfer used used transfer used used transfer used used transfer used transfer used transfer\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> connections predictive coding vaes new frontiers\n",
            "Predicted Summary>>> propose coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding coding\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adaptive gradient methods done right incur generalization penalty\n",
            "Predicted Summary>>> paper done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done done\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> generate effective hash codes efficient cold start recommendation meanwhile provide feasible marketing strategy\n",
            "Predicted Summary>>> propose lightweight architecture codes codes codes codes codes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present software framework transforming distributions demonstrate flexibility relaxing mean field assumptions variational inference use coupling flows replicate structure target generative model\n",
            "Predicted Summary>>> propose software software transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper propose new model combines multi scale information sequence sequence learning\n",
            "Predicted Summary>>> propose new method new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new attack taking full control neural policies realistic settings\n",
            "Predicted Summary>>> propose studies multiple \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> constructively prove even slightest nonlinear activation functions introduce spurious local minima general datasets activation functions\n",
            "Predicted Summary>>> constructively novel slightest slightest slightest slightest slightest slightest slightest novel slightest novel slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest novel slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest slightest novel \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel architecture memory based attention mechanism multi agent communication\n",
            "Predicted Summary>>> develop memory step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel unified architecture restores video frames single motion blurred image end end manner\n",
            "Predicted Summary>>> unified proposes navigation \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> theory connecting hessian solution generalization power model\n",
            "Predicted Summary>>> propose connecting connecting connecting connecting connecting connecting connecting system system system system system system system system connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting connecting system system \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> end end trainable model compression method optimizing accuracy jointly expected model size\n",
            "Predicted Summary>>> propose trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> bregman dilemma shown deep learning improvement margins parameterized models may result overfitting dynamics normalized margin distributions proposed predict generalization error identify dilemma\n",
            "Predicted Summary>>> bregman dilemma used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose framework learn confidence calibrated networks designing novel loss function incorporates predictive uncertainty estimated stochastic inferences\n",
            "Predicted Summary>>> introduce bayesian framework tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> gan based method joint image per pixel annotation synthesis\n",
            "Predicted Summary>>> address proposes end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> incorporating model latent variables encode future content improves long term prediction accuracy critical better planning model based rl\n",
            "Predicted Summary>>> propose studies transfer interactions transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present dreamer agent learns long horizon behaviors purely latent imagination using analytic value gradients\n",
            "Predicted Summary>>> propose dreamer method optimal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> interactive technique improve brushing dense trajectory datasets taking account shape brush\n",
            "Predicted Summary>>> interactive brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing brushing\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed progressive learning method improve learning disentangling latent representations different levels abstraction\n",
            "Predicted Summary>>> propose progressive \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose quantization based method regularizes cnn learned representations automatically aligned trainable concept matrix hence effectively filtering adversarial perturbations\n",
            "Predicted Summary>>> propose quantization trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable trainable\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised classification via deep generative modeling controllable feature learning evaluated difficult real world task\n",
            "Predicted Summary>>> unsupervised classification unsupervised classification feature \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel method create dense descriptors time time embeddings make simple models understand temporal structures\n",
            "Predicted Summary>>> create create create create create create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create create create create create create create create create create create create create create create create create create create create create create create create dense create create create create create create create create create create create create create\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> investigate hidden state activations transformer models question answering tasks\n",
            "Predicted Summary>>> investigate variants \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper develops framework integrating user feedback identity uncertainty knowledge bases\n",
            "Predicted Summary>>> paper develops networks method policy noise policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy policy integrating policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> defense gan uses generative adversarial network defend white box black box attacks classification models\n",
            "Predicted Summary>>> propose proposes predictions \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed sesamebert generalized fine tuning method enables extraction global information among layers squeeze excitation enriches local information capturing neighboring contexts via gaussian blurring\n",
            "Predicted Summary>>> propose sesamebert tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning tuning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable accurate deep multi label learning millions labels\n",
            "Predicted Summary>>> propose accurate train set accurate train accurate set train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> data augmented relation extraction gpt\n",
            "Predicted Summary>>> propose augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented augmented augmented relation augmented augmented augmented augmented relation augmented relation augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented relation augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented augmented\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address end end learning energy based representations signal image observation dataset irregular sampling patterns\n",
            "Predicted Summary>>> address unsupervised matrix end \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present open loop brain machine interface whose performance unconstrained traditionally used bag words approach\n",
            "Predicted Summary>>> propose novel bottleneck bottleneck \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proves universal approximability quantized relu neural networks puts forward complexity bound given arbitrary error\n",
            "Predicted Summary>>> paper analyze tasks networks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce lightweight architecture named entity recognition carry incremental active learning able match state art performance original training data\n",
            "Predicted Summary>>> method gan \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> model based meta rl algorithm enables real robot adapt online dynamic environments\n",
            "Predicted Summary>>> prove gans domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approximate determinantal point processes neural nets justify model theoretically empirically\n",
            "Predicted Summary>>> propose determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal determinantal\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address training gans discrete data formulating policy gradient generalizes across divergences\n",
            "Predicted Summary>>> propose provides provides gans random \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn feature maps invariant translation equivariant rotation scale\n",
            "Predicted Summary>>> propose method top networks standard \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> applying softmax function training leads indirect unexpected supervision features propose new training objective explicitly induce dense feature regions locally sufficient samples benefit adversarial robustness\n",
            "Predicted Summary>>> applying novel rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide information theoretic experimental analysis state art variational autoencoders\n",
            "Predicted Summary>>> paper theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> obtain state art robustness data shifts maintain calibration data shift even though even accuracy drops\n",
            "Predicted Summary>>> propose state even \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> querying black box neural network reveals lot information propose novel metamodels effectively extracting information black box\n",
            "Predicted Summary>>> propose proposes transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> compare deep model based model free rl algorithms studying approximability functions policies dynamics neural networks\n",
            "Predicted Summary>>> train rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> principled framework model quantization using proximal gradient method\n",
            "Predicted Summary>>> propose quantization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use model free algorithms like dqn trpo solve short horizon problems model free iteratively policy value iteration fashion\n",
            "Predicted Summary>>> develop new represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper compares statistical tests rl comparisons false positive statistical power checks robustness assumptions using simulated distributions empirical distributions sac td provides guidelines rl students researchers\n",
            "Predicted Summary>>> propose compares statistical statistical statistical empirical statistical statistical statistical empirical statistical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose alternative measure determining effectiveness adversarial attacks nlp models according distance measure based method like incremental gain control theory\n",
            "Predicted Summary>>> present alternative measure \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose architecture search method identify distribution architectures use construct bayesian ensemble outlier detection\n",
            "Predicted Summary>>> propose rl propose rl propose search propose rl identify \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> nuqsgd closes gap theoretical guarantees qsgd empirical performance qsgdinf\n",
            "Predicted Summary>>> nuqsgd closes theoretical closes \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present scalable approximation wide range ebm objectives applications implicit vaes waes\n",
            "Predicted Summary>>> scalable used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate pruning methods introduce greater instability loss also confer improved generalization explore mechanisms underlying effect\n",
            "Predicted Summary>>> propose tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods recurrent methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods recurrent methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks methods tasks trained methods tasks methods \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find movement function space proportional movement parameter space optimization propose new natural gradient style optimizer address\n",
            "Predicted Summary>>> find movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement movement\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn temporal point processes modeling conditional density conditional intensity\n",
            "Predicted Summary>>> propose proposes algorithm algorithm model algorithm algorithm \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> unsupervised learning method uses meta learning enable efficient learning downstream image classification tasks outperforming state art methods\n",
            "Predicted Summary>>> propose novel training rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical study provides novel perspective shot learning fine tuning method shows comparable accuracy complex state art methods several classification tasks\n",
            "Predicted Summary>>> gan provides maximum \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposing new score based approach structure causal learning leveraging neural networks recent continuous constrained formulation problem\n",
            "Predicted Summary>>> propose score transfer score transfer score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score score tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> functional approach reveals flat initialization preserved gradient descent leads generalization ability\n",
            "Predicted Summary>>> propose reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals reveals \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> scalable accurate deep multi label learning millions labels\n",
            "Predicted Summary>>> propose accurate train policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present state space lstm models combination state space models lstms propose inference algorithm based sequential monte carlo\n",
            "Predicted Summary>>> propose proposes transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer nlp transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study generalization neural networks gradient based meta learning analyzing various properties objective landscape\n",
            "Predicted Summary>>> propose study set various set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> using novel representation symmetric linear dynamical systems latent state formulate optimal control convex program giving first polynomial time algorithm solves optimal control sample complexity polylogarithmic time horizon\n",
            "Predicted Summary>>> propose proposes symmetric continual \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new simple dynamic system introduced generates pretty patterns properties proved possibilities explored\n",
            "Predicted Summary>>> propose dynamic optimization \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduced algorithm learn connectivity deep multi branch networks approach evaluated image categorization consistently yields accuracy gains state art models use fixed connectivity\n",
            "Predicted Summary>>> propose branch concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept concept method connectivity \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study impact using different kinds subword units quality resulting representations used model syntax semantics morphology\n",
            "Predicted Summary>>> represent splines used represent \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present novel approach spike sorting using neural clustering process ncp recently introduced neural architecture performs scalable amortized approximate bayesian inference efficient probabilistic clustering\n",
            "Predicted Summary>>> addition proposes blurred operations \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduction new optimization method application deep learning\n",
            "Predicted Summary>>> introduction new new new new new new new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn conditional autoregressive flow propose perturbations induce simulator failure improving inference performance\n",
            "Predicted Summary>>> propose rule rule tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel domain adaptation method align manifolds source target domains using label propagation better accuracy\n",
            "Predicted Summary>>> propose method architecture \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> rearranging terms maximum mean discrepancy yields much better loss function discriminator generative adversarial nets\n",
            "Predicted Summary>>> rearranging propose alternative maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum maximum\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> representing programs graphs including semantics helps generating programs\n",
            "Predicted Summary>>> representing programs programs programs programs programs \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> important consider optimization function space parameter space introduce learning rule reduces distance traveled function space like sgd limits distance traveled parameter space\n",
            "Predicted Summary>>> propose new optimization distance optimization distance tasks distance distance distance distance distance distance \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> marthe new method fit task specific learning rate schedules perspective hyperparameter optimization\n",
            "Predicted Summary>>> propose method train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analyze gradient propagation deep rnns analysis propose new multi layer deep rnn\n",
            "Predicted Summary>>> propose sparsity trained \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> sgd adam single spiked model tensor pca\n",
            "Predicted Summary>>> propose new spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked sgd spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked sgd spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked spiked\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> improve training stability semi supervised generative adversarial networks collaborative training\n",
            "Predicted Summary>>> propose rl transfer transfer transfer transfer transfer algorithm transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learning based algorithms improve upon performance classical algorithms low rank approximation problem retaining worst case guarantee\n",
            "Predicted Summary>>> propose problem used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> tackling inverse design via genetic algorithms augmented deep neural networks\n",
            "Predicted Summary>>> propose tackling new design design \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method infers constraints task execution leveraging principle maximum entropy quantify demonstrations differ expected un constrained behavior\n",
            "Predicted Summary>>> introduce infers \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce continual learning setup based language modelling explicit task segmentation signal given propose neural network model growing long term memory tackle\n",
            "Predicted Summary>>> propose proposes setup set setup set set \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel architecture memory based attention mechanism multi agent communication\n",
            "Predicted Summary>>> develop memory step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step step\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel approach using mode connectivity loss landscapes mitigate adversarial effects repair tampered models evaluate adversarial robustness\n",
            "Predicted Summary>>> novel method used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper proposes advanced policy optimization method hindsight experience sparse reward reinforcement learning\n",
            "Predicted Summary>>> propose proposes advanced \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce model generalizes quickly observations storing surprising information attending relevant data time point\n",
            "Predicted Summary>>> propose rl observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations surprising observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations surprising observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations representations observations observations observations observations representations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations representations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations observations representations observations observations observations observations observations representations observations observations observations observations observations observations observations representations observations observations observations observations observations observations observations observations observations observations representations observations observations observations observations observations observations observations observations observations observations observations observations representations observations observations observations observations observations observations observations observations observations observations\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose new dnn architecture deep learning tabular data\n",
            "Predicted Summary>>> propose use dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn use dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn dnn \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> work aims provide quantitative answers relative importance concepts interest via concept activation vectors cav particular framework enables non machine learning experts express concepts interest test hypotheses using examples set pictures illustrate concept show cav learned given relatively small set examples hypothesis testing cav answer whether particular concept gender important predicting given class doctor sets concepts interpreting networks cav require retraining modification network\n",
            "Predicted Summary>>> train theoretical \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> goal driven approach model four mouse visual areas lm al rl based deep neural networks trained static object recognition unveil functional organization visual cortex unlike primates\n",
            "Predicted Summary>>> propose adaptive memory learning tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> meta learning methods used vision directly applied nlp perform worse nearest neighbors new classes better distributional signatures\n",
            "Predicted Summary>>> paper proposes used used used used used used used used used used used used used used architecture \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> applying softmax function training leads indirect unexpected supervision features propose new training objective explicitly induce dense feature regions locally sufficient samples benefit adversarial robustness\n",
            "Predicted Summary>>> applying novel rl \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> address trade caused dependency classes domains improving domain adversarial nets\n",
            "Predicted Summary>>> address trade caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> demonstrate large pruned models large sparse outperform smaller dense small dense counterparts identical memory footprint\n",
            "Predicted Summary>>> propose large large layer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> novel cluster based algorithm curriculum learning proposed solve robust training generative models\n",
            "Predicted Summary>>> propose theoretical policy learning policy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use representations trained without parallel data creating word alignments\n",
            "Predicted Summary>>> propose novel variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> represent entity based histogram contexts wasserstein need\n",
            "Predicted Summary>>> represent theoretical need memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce new pointwise convolution layers equipped extremely fast conventional transforms deep neural network\n",
            "Predicted Summary>>> propose pointwise tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present cnn inference based reconstruction algorithm address extremely view ct\n",
            "Predicted Summary>>> propose rl train tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> lowering precision bits bits even binary widening filter banks gives accurate network obtained fp weights activations\n",
            "Predicted Summary>>> lowering proposes bits bits bits bits bits bits bits bits bits bits bits bits bits bits bits bits \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> approach perform htn planning using external procedures evaluate predicates runtime semantic attachments\n",
            "Predicted Summary>>> propose htn external htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn htn\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> addition diversity criterion inspired dpp gan objective avoids mode collapse leads better generations\n",
            "Predicted Summary>>> addition memory inspired \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduce agent makes efficient use demonstrations solve hard exploration problems partially observable environments highly variable initial conditions\n",
            "Predicted Summary>>> use memory makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes memory makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes makes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> provide new framework maml es blackbox setting show allows deterministic linear policies better exploration non differentiable adaptation operators\n",
            "Predicted Summary>>> unsupervised unsupervised unsupervised estimation unsupervised \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new model latently invertible autoencoder proposed solve problem variational inference vae using invertible network two stage adversarial training\n",
            "Predicted Summary>>> propose variational stage variational stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage variational stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage stage\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop framework find modular internal representations generative models manipulate generate counterfactual examples\n",
            "Predicted Summary>>> develop novel method find find find \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> method active anomaly detection present new layer attached deep learning model designed unsupervised anomaly detection transform active method\n",
            "Predicted Summary>>> method transform method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method method anomaly method method method method method method method method method method method method method method method method anomaly method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advocate random features theory biological neural networks focusing sparsely connected networks\n",
            "Predicted Summary>>> advocate theoretical features learning networks features features features features features features features features features features features models features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> derive low variance unbiased gradient estimator expectations discrete random variables based sampling without replacement\n",
            "Predicted Summary>>> propose learning gan detectors detectors detectors detectors detectors detectors detectors detectors detectors detectors \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn efficient lossy image codec optimized facilitate reliable photo manipulation detection fractional cost payload quality even low bitrates\n",
            "Predicted Summary>>> propose proposes lossy lossy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> inspired capsnet propose novel architecture graph embeddings basis node features extracted gnn\n",
            "Predicted Summary>>> use capsnet transfer tasks transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use reinforcement learning query reformulation two tasks surprisingly find training multiple agents diversity reformulations important specialisation\n",
            "Predicted Summary>>> train memory \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> variational bayes scheme recurrent neural networks\n",
            "Predicted Summary>>> variational recurrent recurrent scheme \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> present ontology based neural network architectures sound event classification\n",
            "Predicted Summary>>> develop ontology \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show robust gan priors work better gan priors limited angle ct reconstruction highly determined inverse problem\n",
            "Predicted Summary>>> propose gan gan used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> technique automatically labeling large unlabeled datasets train source models transfer learning experimental evaluation\n",
            "Predicted Summary>>> propose augmented transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose novel architecture traverses image pyramid top fashion visits informative regions along way\n",
            "Predicted Summary>>> propose architecture traverses method traverses traverses traverses \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> new method unsupervised representation learning graphs relying maximizing mutual information local global representations graph state art results competitive supervised learning\n",
            "Predicted Summary>>> propose method optimal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> introduced novel gradient estimator using stein method compared methods learning implicit models approximate inference image generation\n",
            "Predicted Summary>>> scalable novel rl used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used used \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> first principled weight initialization method hypernetworks\n",
            "Predicted Summary>>> propose several tasks high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show training student teacher network iteratively rather jointly produce emergent interpretable teaching strategies\n",
            "Predicted Summary>>> propose rl problem step \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> study problem alleviating instability issue gan training procedure via new architecture design theoretical guarantees\n",
            "Predicted Summary>>> goal instability instability \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> general easy use framework improves adversarial robustness deep classification models embedding regularization\n",
            "Predicted Summary>>> introduce easy easy method easy easy easy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> efficient lifelong learning algorithm provides better trade accuracy time memory complexity compared algorithms\n",
            "Predicted Summary>>> propose lifelong lifelong lifelong lifelong lifelong tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> reward estimation game videos\n",
            "Predicted Summary>>> reward features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> cnn model pruning method using ista rescaling trick enforce sparsity scaling parameters batch normalization\n",
            "Predicted Summary>>> cnn pruning pruning pruning pruning \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> devise mechanism called competition among pixels allows approximately complete saliency methods pass sanity checks\n",
            "Predicted Summary>>> devise proposes pixels training among competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition matching competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition competition\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> jointly train multilingual skip gram model cross lingual sentence similarity model learn high quality multilingual text embeddings perform well low resource scenario\n",
            "Predicted Summary>>> jointly train jointly train search jointly jointly jointly \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use cross entropy loss zero shot learning soft labeling unseen classes simple effective solution achieves state art performance five zsl benchmark datasets\n",
            "Predicted Summary>>> use encoder method entropy \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> training agents adaptive computation based information bottleneck promote generalization\n",
            "Predicted Summary>>> propose adaptive tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> learn high quality denoising using single instances corrupted images training data\n",
            "Predicted Summary>>> propose theoretical high generation set set high set set high \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose imitation learning method learn diverse quality demonstrations collected demonstrators different level expertise\n",
            "Predicted Summary>>> propose studies domain latent problems \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> analysis deep convolutional networks terms associated arrangement hyperplanes\n",
            "Predicted Summary>>> propose provides tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks tasks\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> goal recognition approach based operator counting heuristics used account noise dataset\n",
            "Predicted Summary>>> paper method recognition \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> understand information stored latent space train gan style decoder constrained produce images vae encoder map region latent space\n",
            "Predicted Summary>>> paper provides cells tasks \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> empirical study variational inference based chi square divergence minimization showing minimizing cubo trickier maximizing elbo\n",
            "Predicted Summary>>> propose proposes adversarial transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper focuses synthetic generation human mobility data urban areas using gans\n",
            "Predicted Summary>>> propose focuses encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder encoder \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> use connection gradient based meta learning hierarchical bayes learn mixture meta learners appropriate heterogeneous evolving task distribution\n",
            "Predicted Summary>>> propose proposes set matrix \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> iterative temporal differencing fixed random feedback alignment support spike time dependent plasticity vanilla backpropagation deep learning\n",
            "Predicted Summary>>> propose method random \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> achieving strong adversarial robustness comparable adversarial training without training adversarial examples\n",
            "Predicted Summary>>> propose adversarial audio classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes classes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop vaes encoder takes model parameter vector input rapid inference many models\n",
            "Predicted Summary>>> propose vaes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes takes\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> develop new likelihood free parameter estimation method equivalent maximum likelihood conditions\n",
            "Predicted Summary>>> develop likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood likelihood\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dynamically generate filters conditioned input image cnns forward pass\n",
            "Predicted Summary>>> dynamically proposes used conditioned transfer \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> proposed unified generative adversarial networks gan framework learn noise aware knowledge graph embedding\n",
            "Predicted Summary>>> propose variational data \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> adversarial attacks unsupervised node embeddings based eigenvalue perturbation theory\n",
            "Predicted Summary>>> propose sparsity variational \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> dropout based bayesian inference extended deal multi modality evaluated scene anticipation tasks\n",
            "Predicted Summary>>> dropout deal used deal deal evaluated deal evaluated deal evaluated deal evaluated deal deal \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose gradient estimator selection algorithm aim improving optimization efficiency\n",
            "Predicted Summary>>> fine proposes space selection \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> show transformer architecture neural gpu turing complete\n",
            "Predicted Summary>>> propose new gpu gpu \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> fix classifier neural networks without losing accuracy\n",
            "Predicted Summary>>> fix train \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> give algorithm learning two layer neural network symmetric input distribution\n",
            "Predicted Summary>>> give propose domain \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> advocate random features theory biological neural networks focusing sparsely connected networks\n",
            "Predicted Summary>>> advocate theoretical features learning networks features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features features models features features features features features features features \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose model able perform physical parameter estimation systems video differential equations governing scene dynamics known labeled states objects available\n",
            "Predicted Summary>>> propose novel new \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> modular approach consisting sentence selector module followed qa model made robust adversarial attacks comparison qa model trained full context\n",
            "Predicted Summary>>> propose new variational search \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> information whether neural network output correct incorrect somewhat present outputs network intermediate layers\n",
            "Predicted Summary>>> propose provides method \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> progressively growing available action space great curriculum learning agents\n",
            "Predicted Summary>>> progressively growing growing growing growing growing tasks action \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper analyzes latent space learned model free approaches miniature incomplete information game trains forward model latent space apply monte carlo tree search yielding positive performance\n",
            "Predicted Summary>>> propose functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions functions\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> paper introduce evalne python toolbox automating evaluation network embedding methods link prediction ensuring reproducibility results\n",
            "Predicted Summary>>> use memory use memory use dense use \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> notion order learning proposed applied regression problems computer vision\n",
            "Predicted Summary>>> notion order regression \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> find deep networks generalize poorly reliant single directions generalize well evaluate impact dropout batch normalization well class selectivity single direction reliance\n",
            "Predicted Summary>>> propose single search batch \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose unsupervised way learn multiple embeddings sentences phrases\n",
            "Predicted Summary>>> propose rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl rl\n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> safety becoming critical notion machine learning believe work act foundation number research directions safety aware learning algorithms\n",
            "Predicted Summary>>> safety becoming safety becoming safety becoming safety \n",
            "-----------------------------------------------------------------------\n",
            "original Summary>>> propose repeated reference benchmark task regularized continual learning approach adaptive communication humans unfamiliar domains\n",
            "Predicted Summary>>> humans repeated \n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_rogue(src_trg, pred_trg):\n",
        "\n",
        "  #cut off  token\n",
        "  pred_trg = pred_trg[:-6]\n",
        "\n",
        "\n",
        "  if (len(pred_trg) == 0):\n",
        "    rogue_score = 0.0\n",
        "  else:\n",
        "    s = rouge.get_scores(pred_trg, src_trg, avg= True)\n",
        "    rogue_score = s['rouge-1']['f']\n",
        "\n",
        "  return s"
      ],
      "metadata": {
        "id": "l98eHzhYg41A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_plot_threshold = 0.45\n",
        "\n",
        "def evaluateRandomlyprint_1(encoder, decoder, n=5):\n",
        "    text=list()\n",
        "    headline=list()\n",
        "    pred_headline=list()\n",
        "\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "\n",
        "        if(len(pair[0].split())>=150):\n",
        "          continue\n",
        "        else:\n",
        "          #if(i%1000==0):\n",
        "           # print(i*100/n,\"% complete\")\n",
        "\n",
        "          tokenized_input = nltk.word_tokenize(pair[0])\n",
        "          #print(len(tokenized_input))\n",
        "          output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "\n",
        "          output_sentence = ' '.join(output_words)\n",
        "\n",
        "          #get rogue f-score -- need to pass tokenized version here\n",
        "          #print(pair[0])\n",
        "          #print(output_sentence)\n",
        "          score = calculate_rogue(pair[0], output_sentence)\n",
        "          print(score)\n",
        "\n",
        "          print('pair: ', pair[0])\n",
        "          print('output sentence: ', output_sentence)\n",
        "          print('')\n",
        "    return(text,headline,pred_headline)\n"
      ],
      "metadata": {
        "id": "u60CC2X8g5X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from rouge import Rouge\n",
        "\n",
        "rouge = Rouge()\n",
        "\n",
        "\n",
        "evaluateRandomlyprint_1(encoder1, attn_decoder1,15000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BiFy-ymU5Jva",
        "outputId": "081cbae4-5564-4f0d-c027-1425f886462e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge-1': {'r': 0.011904761904761904, 'p': 0.25, 'f': 0.022727271859504163}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.011904761904761904, 'p': 0.25, 'f': 0.022727271859504163}}\n",
            "pair:  inspired combination feedforward iterative computations visual cortex taking advantage ability denoising autoencoders estimate score joint distribution propose novel approach iterative inference capturing exploiting complex joint distribution output variables conditioned input variables approach applied image pixel wise segmentation estimated conditional score used perform gradient ascent towards mode estimated conditional distribution extends previous work score estimation denoising autoencoders case conditional distribution novel use corrupted feedforward predictor replacing gaussian corruption advantage approach classical ways perform iterative inference structured outputs like conditional random fields crfs necessary define explicit energy function linking output variables keep computations tractable energy function parametrizations typically fairly constrained involving neighbors output variables clique experimentally find proposed iterative inference conditional score estimation conditional denoising autoencoders performs better comparable models based crfs using explicit modeling conditional joint distribution outputs\n",
            "output sentence:  refining used proposals used proposals used used proposals \n",
            "\n",
            "{'rouge-1': {'r': 0.0273972602739726, 'p': 0.5, 'f': 0.051948050963062924}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0273972602739726, 'p': 0.5, 'f': 0.051948050963062924}}\n",
            "pair:  consider problem generating plausible diverse video sequences given start end frame task also known inbetweening belongs broader area stochastic video generation generally approached means recurrent neural networks rnn paper propose instead fully convolutional model generate video sequences directly pixel domain first obtain latent video representation using stochastic fusion mechanism learns incorporate information start end frames model learns produce latent representation progressively increasing temporal resolution decode spatiotemporal domain using convolutions model trained end end minimizing adversarial loss experiments several widely used benchmark datasets show able generate meaningful diverse video sequences according quantitative qualitative evaluations\n",
            "output sentence:  propose presents frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames frames \n",
            "\n",
            "{'rouge-1': {'r': 0.02631578947368421, 'p': 0.4, 'f': 0.049382714891022736}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02631578947368421, 'p': 0.4, 'f': 0.049382714891022736}}\n",
            "pair:  domain time series forecasting extensively studied fundamental importance many real life applications weather prediction traffic flow forecasting sales compelling examples sequential phenomena predictive models generally make use relations past future values however case stationary time series observed values also drastically depend number exogenous features used improve forecasting quality work propose change paradigm consists learning features embeddings vectors within recurrent neural networks apply framework forecast smart cards tap logs parisian subway network results show context embedded models perform quantitatively better one step ahead multi step ahead forecasting\n",
            "output sentence:  propose forecast using set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set set\n",
            "\n",
            "{'rouge-1': {'r': 0.013888888888888888, 'p': 0.25, 'f': 0.02631578847645433}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.013888888888888888, 'p': 0.25, 'f': 0.02631578847645433}}\n",
            "pair:  information bottleneck principle shwartz ziv tishby suggests sgd based training deep neural networks results optimally compressed hidden layers information theoretic perspective however claim established toy data goal work present test claims realistic setting using larger deeper convolutional architecture resnet model trained pixelcnn models inverse representation decoders measure mutual information hidden layers resnet input image data trained classification autoencoding find two stages learning happen training regimes compression occur even autoencoder sampling images conditioning hidden layers activations offers intuitive visualisation understand resnets learns forget\n",
            "output sentence:  propose method bottleneck applied \n",
            "\n",
            "{'rouge-1': {'r': 0.023255813953488372, 'p': 0.4, 'f': 0.04395604291752206}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.011627906976744186, 'p': 0.2, 'f': 0.02197802093950011}}\n",
            "pair:  distributed optimization vital solving large scale machine learning problems widely shared feature distributed optimization techniques requirement nodes complete assigned tasks computational epoch system proceed next epoch settings slow nodes called stragglers greatly slow progress mitigate impact stragglers propose online distributed optimization method called anytime minibatch approach nodes given fixed time compute gradients many data samples possible result variable per node minibatch size workers get fixed communication time average minibatch gradients via several rounds consensus used update primal variables via dual averaging anytime minibatch prevents stragglers holding system without wasting work stragglers complete present convergence analysis analyze wall time performance numerical results show approach times faster amazon ec five times faster greater variability compute node performance\n",
            "output sentence:  propose distributed distributed distributed high bayesian distributed bayesian distributed distributed \n",
            "\n",
            "{'rouge-1': {'r': 0.015873015873015872, 'p': 0.5, 'f': 0.030769230172781076}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.015873015873015872, 'p': 0.5, 'f': 0.030769230172781076}}\n",
            "pair:  modern deep neural networks achieve high accuracy training distribution test distribution identically distributed assumption frequently violated practice train test distributions mismatched accuracy plummet currently techniques improve robustness unforeseen data shifts encountered deployment work propose technique improve robustness uncertainty estimates image classifiers propose augmix data processing technique simple implement adds limited computational overhead helps models withstand unforeseen corruptions augmix significantly improves robustness uncertainty measures challenging image classification benchmarks closing gap previous methods best possible performance cases half\n",
            "output sentence:  propose state even \n",
            "\n",
            "{'rouge-1': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}}\n",
            "pair:  paper concerns dictionary learning sparse coding fundamental representation learning problem show subgradient descent algorithm random initialization recover orthogonal dictionaries natural nonsmooth nonconvex minimization formulation problem mild statistical assumption data contrast previous provable methods require either expensive computation delicate initialization schemes analysis develops several tools characterizing landscapes nonsmooth functions might independent interest provable training deep networks nonsmooth activations relu among applications preliminary synthetic real experiments corroborate analysis show algorithm works well empirically recovering orthogonal dictionaries\n",
            "output sentence:  paper dictionary minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization layer minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization minimization\n",
            "\n",
            "{'rouge-1': {'r': 0.015384615384615385, 'p': 0.3333333333333333, 'f': 0.029411763862456773}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.015384615384615385, 'p': 0.3333333333333333, 'f': 0.029411763862456773}}\n",
            "pair:  batch normalization bn become cornerstone deep learning across diverse architectures appearing help optimization well generalization idea makes intuitive sense theoretical analysis effectiveness lacking theoretical support provided one conjectured properties namely ability allow gradient descent succeed less tuning learning rates shown even fix learning rate scale invariant parameters weights layer bn constant say gradient descent still approaches stationary point solution gradient zero rate iterations asymptotically matching best bound gradient descent well tuned learning rates similar result convergence rate also shown stochastic gradient descent\n",
            "output sentence:  give theoretical normalization \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  analyze joint probability distribution lengths vectors hidden variables different layers fully connected deep network weights biases chosen randomly according gaussian distributions input binary valued show activation function satisfies minimal set assumptions satisfied activation functions know used practice width network gets large length process converges probability length map determined simple function variances random weights biases activation function also show convergence may fail activation functions violate assumptions\n",
            "output sentence:  prove proposes functions \n",
            "\n",
            "{'rouge-1': {'r': 0.039473684210526314, 'p': 0.42857142857142855, 'f': 0.07228915508201483}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02631578947368421, 'p': 0.2857142857142857, 'f': 0.048192769539846185}}\n",
            "pair:  describe kernel rnn learning kernl reduced rank temporal eligibility trace based approximation backpropagation time bptt training recurrent neural networks rnns gives competitive performance bptt long time dependence tasks approximation replaces rank gradient learning tensor describes past hidden unit activations affect current state simple reduced rank product sensitivity weight temporal eligibility trace structured approximation motivated node perturbation sensitivity weights eligibility kernel time scales learned applying perturbations rule represents another step toward biologically plausible neurally inspired ml lower complexity terms relaxed architectural requirements symmetric return weights smaller memory demand unfolding storage states time shorter feedback time\n",
            "output sentence:  propose plausible set plausible rule architecture plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible plausible rule tasks set plausible plausible plausible plausible set plausible \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  present novel network pruning algorithm called dynamic sparse training jointly nd optimal network parameters sparse network structure uni ed optimization process trainable pruning thresholds thresholds ne grained layer wise adjustments dynamically via backpropagation demonstrate dynamic sparse training algorithm easily train sparse neural network models little performance loss using training epochs dense models dynamic sparse training achieves prior art performance compared sparse training algorithms various network architectures additionally several surprising observations provide strong evidence effectiveness ef ciency algorithm observations reveal underlying problems traditional three stage pruning algorithms present potential guidance provided algorithm design compact network architectures\n",
            "output sentence:  propose characterizes transfer \n",
            "\n",
            "{'rouge-1': {'r': 0.012195121951219513, 'p': 0.3333333333333333, 'f': 0.02352941108373704}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.012195121951219513, 'p': 0.3333333333333333, 'f': 0.02352941108373704}}\n",
            "pair:  many attempts explain trade accuracy adversarial robustness however clear understanding behaviors robust classifier human like robustness argue need consider adversarial robustness varying magnitudes perturbations focusing fixed perturbation threshold need use different method generate adversarially perturbed samples used train robust classifier measure robustness classifiers need prioritize adversarial accuracies different magnitudes introduce lexicographical genuine robustness lgr classifiers combines requirements also suggest candidate oracle classifier called optimal lexicographically genuinely robust classifier olgrc prioritizes accuracy meaningful adversarially perturbed examples generated smaller magnitude perturbations training algorithm estimating olgrc requires lexicographical optimization unlike existing adversarial training methods apply lexicographical optimization neural network utilize gradient episodic memory gem originally developed continual learning preventing catastrophic forgetting\n",
            "output sentence:  try generate classifier \n",
            "\n",
            "{'rouge-1': {'r': 0.018867924528301886, 'p': 0.3333333333333333, 'f': 0.03571428470025513}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.018867924528301886, 'p': 0.3333333333333333, 'f': 0.03571428470025513}}\n",
            "pair:  inference models replace optimization based inference procedure learned model fundamental advancing bayesian deep learning notable example variational auto encoders vaes paper propose iterative inference models learn optimize variational lower bound repeatedly encoding gradients approach generalizes vaes certain conditions viewing vaes context iterative inference provide insight several recent empirical findings demonstrate inference optimization capabilities iterative inference models explore unique aspects models show outperform standard inference models typical benchmark data sets\n",
            "output sentence:  propose augmented memory \n",
            "\n",
            "{'rouge-1': {'r': 0.013513513513513514, 'p': 0.3333333333333333, 'f': 0.025974025225164468}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.013513513513513514, 'p': 0.3333333333333333, 'f': 0.025974025225164468}}\n",
            "pair:  recurrent models sequences recently successful many tasks especially language modeling machine translation nevertheless remains challenging extract good representations models instance even though language clear hierarchical structure going characters words sentences apparent current language models propose improve representation sequence models augmenting current approaches autoencoder forced compress sequence intermediate discrete latent space order propagate gradients though discrete representation introduce improved semantic hashing technique show technique performs well newly proposed quantitative efficiency measure also analyze latent codes produced model showing correspond words phrases finally present application autoencoder augmented model generating diverse translations\n",
            "output sentence:  propose new text text text \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  describe three approaches enabling extremely computationally limited embedded scheduler consider small number alternative activities based resource availability consider case scheduler computationally limited cannot backtrack search first two approaches precompile resource checks called guards enable selection preferred alternative activity sufficient resources estimated available schedule remaining activities final approach mimics backtracking invoking scheduler multiple times alternative activities present evaluation techniques mission scenarios called sol types nasa next planetary rover techniques evaluated inclusion onboard scheduler\n",
            "output sentence:  propose describes models tasks \n",
            "\n",
            "{'rouge-1': {'r': 0.01818181818181818, 'p': 1.0, 'f': 0.035714285363520414}, 'rouge-2': {'r': 0.007142857142857143, 'p': 1.0, 'f': 0.014184397022282583}, 'rouge-l': {'r': 0.01818181818181818, 'p': 1.0, 'f': 0.035714285363520414}}\n",
            "pair:  counterfactual regret minimization cfr fundamental effective technique solving imperfect information games iig however original cfr algorithm works discrete states action spaces resulting strategy maintained tabular representation tabular representation limits method directly applied large games paper propose double neural representation iigs one neural network represents cumulative regret represents average strategy neural representations allow us avoid manual game abstraction carry end end optimization make learning efficient also developed several novel techniques including robust sampling method mini batch monte carlo counterfactual regret minimization mccfr method may independent interests empirically games tractable tabular approaches neural strategies trained algorithm converge comparably tabular counterparts significantly outperform based deep reinforcement learning extremely large games billions decision nodes approach achieved strong performance using hundreds times less memory tabular cfr head head matches hands limit texas hold em neural agent beat strong agent abs cfr pm chips per game successful application neural cfr large games\n",
            "output sentence:  propose double step \n",
            "\n",
            "{'rouge-1': {'r': 0.017543859649122806, 'p': 0.25, 'f': 0.032786884020424664}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.017543859649122806, 'p': 0.25, 'f': 0.032786884020424664}}\n",
            "pair:  present novel multi task training approach learning multilingual distributed representations text system learns word sentence embeddings jointly training multilingual skip gram model together cross lingual sentence similarity model construct sentence embeddings processing word embeddings lstm taking average outputs architecture transparently use monolingual sentence aligned bilingual corpora learn multilingual embeddings thus covering vocabulary significantly larger vocabulary bilingual corpora alone model shows competitive performance standard cross lingual document classification task also show effectiveness method low resource scenario\n",
            "output sentence:  jointly train search jointly \n",
            "\n",
            "{'rouge-1': {'r': 0.02857142857142857, 'p': 1.0, 'f': 0.05555555501543211}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02857142857142857, 'p': 1.0, 'f': 0.05555555501543211}}\n",
            "pair:  inverse problems ubiquitous natural sciences refer challenging task inferring complex potentially multi modal posterior distributions hidden parameters given set observations typically model physical process form differential equations available leads intractable inference parameters forward propagation parameters model simulates evolution system inverse problem finding parameters given sequence states unique work propose generalisation bayesian optimisation framework approximate inference resulting method learns approximations posterior distribution applying stein variational gradient descent top estimates gaussian process model preliminary results demonstrate method performance likelihood free inference reinforcement learning environments\n",
            "output sentence:  propose method used \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  misspecified settings posterior distribution bayesian statistics may lead inconsistent estimates fix issue suggested replace likelihood pseudo likelihood exponential loss function enjoying suitable robustness properties paper build pseudo likelihood based maximum mean discrepancy defined via embedding probability distributions reproducing kernel hilbert space show mmd bayes posterior consistent robust model misspecification posterior obtained way might intractable also prove reasonable variational approximations posterior enjoy properties provide details stochastic gradient algorithm compute variational approximations numerical simulations indeed suggest estimator robust misspecification ones based likelihood\n",
            "output sentence:  propose memory memory networks \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep reinforcement learning achieved great success many previously difficult reinforcement learning tasks yet recent studies show deep rl agents also unavoidably susceptible adversarial perturbations similar deep neural networks classification tasks prior works mostly focus model free adversarial attacks agents discrete actions work study problem continuous control agents deep rl adversarial attacks propose first two step algorithm based learned model dynamics extensive experiments various mujoco domains cartpole fish walker humanoid demonstrate proposed framework much effective efficient model free based attacks baselines degrading agent performance well driving agents unsafe states\n",
            "output sentence:  unified train regression \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  compare model free reinforcement learning model based approaches lens expressive power neural networks policies functions dynamics show theoretically empirically even one dimensional continuous state space many mdps whose optimal functions policies much complex dynamics hypothesize many real world mdps also similar property mdps model based planning favorable algorithm resulting policies approximate optimal policy significantly better neural network parameterization model free model based policy optimization rely policy parameterization motivated theory apply simple multi step model based bootstrapping planner boots bootstrap weak function stronger policy empirical results show applying boots top model based model free policy optimization algorithms test time improves performance mujoco benchmark tasks\n",
            "output sentence:  train rl completion \n",
            "\n",
            "{'rouge-1': {'r': 0.012195121951219513, 'p': 0.3333333333333333, 'f': 0.02352941108373704}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.012195121951219513, 'p': 0.3333333333333333, 'f': 0.02352941108373704}}\n",
            "pair:  currently techniques sharing governance deep learning model homomorphic encryption secure multiparty computation unfortunately neither techniques applicable training large neural networks due large computational communication overheads scalable technique shared model governance propose splitting deep learning model multiple parties paper empirically investigates security guarantee technique introduced problem model completion given entire training data set environment simulator subset parameters trained deep learning model much training required recover model original performance define metric evaluating hardness model completion problem study empirically supervised learning imagenet reinforcement learning atari deepmind lab experiments show model completion problem harder reinforcement learning supervised learning unavailability trained agent trajectories hardness depends primarily number parameters missing part type location results suggest model splitting might feasible technique shared model governance settings training expensive\n",
            "output sentence:  propose domain representations \n",
            "\n",
            "{'rouge-1': {'r': 0.011764705882352941, 'p': 0.3333333333333333, 'f': 0.022727272068698366}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.011764705882352941, 'p': 0.3333333333333333, 'f': 0.022727272068698366}}\n",
            "pair:  first order methods stochastic gradient descent sgd currently standard algorithm training deep neural networks second order methods despite better convergence rate rarely used practice due pro hibitive computational cost calculating second order information paper propose novel gram gauss newton ggn algorithm train deep neural networks regression problems square loss method draws inspiration connection neural network optimization kernel regression neural tangent kernel ntk different typical second order methods heavy computational cost iteration ggn minor overhead compared first order methods sgd also give theoretical results show sufficiently wide neural networks convergence rate ggn quadratic furthermore provide convergence guarantee mini batch ggn algorithm knowledge first convergence result mini batch version second order method overparameterized neural net works preliminary experiments regression tasks demonstrate training standard networks ggn algorithm converges much faster achieves better performance sgd\n",
            "output sentence:  unsupervised theoretical scaling \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  neural conversational models widely used applications like personal assistants chat bots models seem give better performance operating word level however fusion languages like french russian polish vocabulary size sometimes become infeasible since words lots word forms propose neural network architecture transforming normalized text grammatically correct one model efficiently employs correspondence normalized target words significantly outperforms character level models faster training faster evaluation also propose new pipeline building conversational models first generate normalized answer transform grammatically correct one using network proposed pipeline gives better performance character level conversational models according assessor testing\n",
            "output sentence:  train agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement agreement \n",
            "\n",
            "{'rouge-1': {'r': 0.02631578947368421, 'p': 0.5, 'f': 0.049999999050000014}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02631578947368421, 'p': 0.5, 'f': 0.049999999050000014}}\n",
            "pair:  deep neural networks shown incredible performance inference tasks variety domains unfortunately current deep networks enormous cloud based structures require significant storage space limits scaling deep learning service dlaas use device augmented intelligence paper finds algorithms directly use lossless compressed representations deep feedforward networks synaptic weights drawn discrete sets perform inference without full decompression basic insight allows less rate naive approaches recognition bipartite graph layers feedforward networks kind permutation invariance labeling nodes terms inferential operation inference operation depends locally edges directly connected also provide experimental results approach mnist dataset\n",
            "output sentence:  propose new tasks representations tasks \n",
            "\n",
            "{'rouge-1': {'r': 0.014084507042253521, 'p': 0.2, 'f': 0.02631578824445989}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014084507042253521, 'p': 0.2, 'f': 0.02631578824445989}}\n",
            "pair:  modern neural network architectures take advantage increasingly deeper layers various advances structure achieve better performance traditional explicit regularization techniques like dropout weight decay data augmentation still used new models little regularization generalization effects new structures studied besides deeper predecessors could newer architectures like resnet densenet also benefit structures implicit regularization properties work investigate skip connection effect network generalization features experiments show certain neural network architectures contribute generalization abilities specifically study effect low level features generalization performance introduced deeper layers densenet resnet well networks skip connections show low level representations help generalization multiple settings quality quantity training data decreased\n",
            "output sentence:  train analyses data datasets datasets datasets \n",
            "\n",
            "{'rouge-1': {'r': 0.015873015873015872, 'p': 0.25, 'f': 0.02985074514591227}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.015873015873015872, 'p': 0.25, 'f': 0.02985074514591227}}\n",
            "pair:  propose bayesian hypernetworks framework approximate bayesian inference neural networks bayesian hypernetwork neural network learns transform simple noise distribution distribution parameters another neural network primary network train variational inference using invertible enable efficient estimation variational lower bound posterior via sampling contrast methods bayesian deep learning bayesian hypernets represent complex multimodal approximate posterior correlations parameters enabling cheap iid sampling practice bayesian hypernets provide better defense adversarial examples dropout also exhibit competitive performance suite tasks evaluate model uncertainty including regularization active learning anomaly detection\n",
            "output sentence:  propose pretraining method empirical \n",
            "\n",
            "{'rouge-1': {'r': 0.05660377358490566, 'p': 0.42857142857142855, 'f': 0.09999999793888893}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.03773584905660377, 'p': 0.2857142857142857, 'f': 0.06666666460555562}}\n",
            "pair:  learning optimize recently proposed framework learning optimization algorithms using reinforcement learning paper explore learning optimization algorithm training shallow neural nets high dimensional stochastic optimization problems present interesting challenges existing reinforcement learning algorithms develop extension suited learning optimization algorithms setting demonstrate learned optimization algorithm consistently outperforms known optimization algorithms even unseen tasks robust changes stochasticity gradients neural net architecture specifically show optimization algorithm trained proposed method problem training neural net mnist generalizes problems training neural nets toronto faces dataset cifar cifar\n",
            "output sentence:  propose optimization tasks search networks search unseen unseen unseen unseen unseen \n",
            "\n",
            "{'rouge-1': {'r': 0.0425531914893617, 'p': 0.5, 'f': 0.07843137110342178}, 'rouge-2': {'r': 0.018867924528301886, 'p': 0.2, 'f': 0.03448275704518438}, 'rouge-l': {'r': 0.0425531914893617, 'p': 0.5, 'f': 0.07843137110342178}}\n",
            "pair:  design reliable systems must guarantee stability input perturbations machine learning guarantee entails preventing overfitting ensuring robustness models corruption input data order maximize stability analyze develop computationally efficient implementation jacobian regularization increases classification margins neural networks stabilizing effect jacobian regularizer leads significant improvements robustness measured random adversarial input perturbations without severely degrading generalization properties clean data\n",
            "output sentence:  develop computationally caused caused tasks caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused caused\n",
            "\n",
            "{'rouge-1': {'r': 0.022222222222222223, 'p': 0.5, 'f': 0.042553190674513366}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.022222222222222223, 'p': 0.5, 'f': 0.042553190674513366}}\n",
            "pair:  deep generative modeling using flows gained popularity owing tractable exact log likelihood estimation efficient training synthesis process however flow models suffer challenge high dimensional latent space dimension input space effective solution challenge proposed dinh et al multi scale architecture based iterative early factorization part total dimensions regular intervals prior works generative flows involving multi scale architecture perform dimension factorization based static masking propose novel multi scale architecture performs data dependent factorization decide dimensions pass flow layers facilitate introduce heuristic based contribution dimension total log likelihood encodes importance dimensions proposed heuristic readily obtained part flow training process enabling versatile implementation likelihood contribution based multi scale architecture generic flow models present implementation original flow introduced dinh et al demonstrate improvements log likelihood score sampling quality standard image benchmarks also conduct ablation studies compare proposed method options dimension factorization\n",
            "output sentence:  paper dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions dependent dimensions\n",
            "\n",
            "{'rouge-1': {'r': 0.03571428571428571, 'p': 0.4, 'f': 0.06557376898683152}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.03571428571428571, 'p': 0.4, 'f': 0.06557376898683152}}\n",
            "pair:  recent advances illustrated often possible learn solve linear inverse problems imaging using training data outperform traditional regularized least squares solutions along lines present extensions neumann network recently introduced end end learned architecture inspired truncated neumann series expansion solution map regularized least squares problem summarize neumann network approach show form compatible optimal reconstruction function given inverse problem also investigate extension neumann network incorporates sample efficient patch based regularization approach\n",
            "output sentence:  neumann networks sample algorithm algorithm algorithm algorithm \n",
            "\n",
            "{'rouge-1': {'r': 0.009523809523809525, 'p': 0.25, 'f': 0.018348623146199842}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.009523809523809525, 'p': 0.25, 'f': 0.018348623146199842}}\n",
            "pair:  music relies heavily repetition build structure meaning self reference occurs multiple timescales motifs phrases reusing entire sections music pieces aba structure transformer vaswani et al sequence model based self attention achieved compelling results many generation tasks require maintaining long range coherence suggests self attention might also well suited modeling music musical composition performance however relative timing critically important existing approaches representing relative positional information transformer modulate attention based pairwise distance shaw et al impractical long sequences musical compositions since memory complexity quadratic sequence length propose algorithm reduces intermediate memory requirements linear sequence length enables us demonstrate transformer modified relative attention mechanism generate minute long thousands steps compositions compelling structure generate continuations coherently elaborate given motif seq seq setup generate accompaniments conditioned melodies evaluate transformer relative attention mechanism two datasets jsb chorales piano competition obtain state art results latter\n",
            "output sentence:  propose new successful successful successful successful successful \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep convolutional networks dcns shown sensitive universal adversarial perturbations uaps input agnostic perturbations fool model large portions dataset uaps exhibit interesting visual patterns phenomena yet poorly understood work shows visually similar procedural noise patterns also act uaps particular demonstrate different dcn architectures sensitive gabor noise patterns behaviour causes implications deserve depth study\n",
            "output sentence:  paper several memory tasks image \n",
            "\n",
            "{'rouge-1': {'r': 0.04918032786885246, 'p': 0.75, 'f': 0.09230769115266273}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.04918032786885246, 'p': 0.75, 'f': 0.09230769115266273}}\n",
            "pair:  introduce new memory architecture navigation previously unseen environments inspired landmark based navigation animals proposed semi parametric topological memory sptm consists non parametric graph nodes corresponding locations environment parametric deep network capable retrieving nodes graph based observations graph stores metric information connectivity locations corresponding nodes use sptm planning module navigation system given minutes footage previously unseen maze sptm based navigation agent build topological map environment use confidently navigate towards goals average success rate sptm agent goal directed navigation across test environments higher best performing baseline factor three\n",
            "output sentence:  introduce memory memory navigation navigation \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep ensembles empirically shown promising approach improving accuracy uncertainty distribution robustness deep learning models deep ensembles theoretically motivated bootstrap non bootstrap ensembles trained random initialization also perform well practice suggests could explanations deep ensembles work well bayesian neural networks learn distributions parameters network theoretically well motivated bayesian principles perform well deep ensembles practice particularly dataset shift one possible explanation gap theory practice popular scalable approximate bayesian methods tend focus single mode whereas deep ensembles tend explore diverse modes function space investigate hypothesis building recent work understanding loss landscape neural networks adding exploration measure similarity functions space predictions results show random initializations explore entirely different modes functions along optimization trajectory sampled subspace thereof cluster within single mode predictions wise often deviating significantly weight space demonstrate low loss connectors modes exist connected space predictions developing concept diversity accuracy plane show decorrelation power random initializations unmatched popular subspace sampling methods\n",
            "output sentence:  propose proposes lens \n",
            "\n",
            "{'rouge-1': {'r': 0.023255813953488372, 'p': 0.6666666666666666, 'f': 0.044943819573286206}, 'rouge-2': {'r': 0.009174311926605505, 'p': 0.5, 'f': 0.018018017664150645}, 'rouge-l': {'r': 0.023255813953488372, 'p': 0.6666666666666666, 'f': 0.044943819573286206}}\n",
            "pair:  molecular graph generation fundamental problem drug discovery attracting growing attention problem challenging since requires generating chemically valid molecular structures also optimizing chemical properties meantime inspired recent progress deep generative models paper propose flow based autoregressive model graph generation called graphaf graphaf combines advantages autoregressive flow based approaches enjoys high model flexibility data density estimation efficient parallel computation training iterative sampling process allows leveraging chemical domain knowledge valency checking experimental results show graphaf able generate chemically valid molecules even without chemical knowledge rules valid molecules chemical rules training process graphaf two times faster existing state art approach gcpn fine tuning model goal directed property optimization reinforcement learning graphaf achieves state art performance chemical property optimization constrained property optimization\n",
            "output sentence:  propose flow optimization \n",
            "\n",
            "{'rouge-1': {'r': 0.014084507042253521, 'p': 0.2, 'f': 0.02631578824445989}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014084507042253521, 'p': 0.2, 'f': 0.02631578824445989}}\n",
            "pair:  modern federated networks comprised wearable devices mobile phones autonomous vehicles generate massive amounts data day wealth data help learn models improve user experience device however scale heterogeneity federated data presents new challenges research areas federated learning meta learning multi task learning machine learning community begins tackle challenges critical time ensure developments made areas grounded realistic benchmarks end propose leaf modular benchmarking framework learning federated settings leaf includes suite open source federated datasets rigorous evaluation framework set reference implementations geared towards capturing obstacles intricacies practical federated environments\n",
            "output sentence:  propose search rl search search tasks search \n",
            "\n",
            "{'rouge-1': {'r': 0.012658227848101266, 'p': 0.25, 'f': 0.024096384624764152}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.012658227848101266, 'p': 0.25, 'f': 0.024096384624764152}}\n",
            "pair:  variational auto encoders vae capable generating realistic images sounds video sequences practitioners point view usually interested solving problems tasks learned sequentially way avoids revisiting previous data stage address problem introducing conceptually simple scalable end end approach incorporating past knowledge learning prior directly data consider scalable boosting like approximation intractable theoretical optimal prior provide empirical studies two commonly used benchmarks namely mnist fashion mnist disjoint sequential image generation tasks dataset proposed method delivers best results among comparable approaches avoiding catastrophic forgetting fully automatic way fixed model architecture\n",
            "output sentence:  propose sparsity generation generate used \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  achieving machine intelligence requires smooth integration perception reasoning yet models developed date tend specialize one sophisticated manipulation symbols acquired rich perceptual spaces far proved elusive consider visual arithmetic task goal carry simple arithmetical algorithms digits presented natural conditions hand written placed randomly propose two tiered architecture tackling kind problem lower tier consists heterogeneous collection information processing modules include pre trained deep neural networks locating extracting characters image well modules performing symbolic transformations representations extracted perception higher tier consists controller trained using reinforcement learning coordinates modules order solve high level task instance controller may learn contexts execute perceptual networks symbolic transformations apply outputs resulting model able solve variety tasks visual arithmetic domain several advantages standard architecturally homogeneous feedforward networks including improved sample efficiency\n",
            "output sentence:  use represent represent \n",
            "\n",
            "{'rouge-1': {'r': 0.015873015873015872, 'p': 0.3333333333333333, 'f': 0.03030302943526173}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.015873015873015872, 'p': 0.3333333333333333, 'f': 0.03030302943526173}}\n",
            "pair:  flow based models real nvp extremely powerful approach density estimation however existing flow based models restricted transforming continuous densities continuous input space similarly continuous distributions continuous latent variables makes poorly suited modeling representing discrete structures data distributions example class membership discrete symmetries address difficulty present normalizing flow architecture relies domain partitioning using locally invertible functions possesses real discrete valued latent variables real discrete rad approach retains desirable normalizing flow properties exact sampling exact inference analytically computable probabilities time allowing simultaneous modeling continuous discrete structure data distribution\n",
            "output sentence:  propose flow algorithm \n",
            "\n",
            "{'rouge-1': {'r': 0.013157894736842105, 'p': 0.25, 'f': 0.024999999050000037}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.013157894736842105, 'p': 0.25, 'f': 0.024999999050000037}}\n",
            "pair:  paper proposes demonstrates deep convolutional neural network dcnn architecture identify users disguised face attempting fraudulent atm transaction recent introduction disguised face identification dfi framework proves applicability deep neural networks problem atms nowadays incorporate hidden camera capture footage users however impossible police track impersonators disguised faces atm footage proposed deep convolutional neural network trained identify real time whether user captured image trying cloak identity output dcnn reported atm take appropriate steps prevent swindler completing transaction network trained using dataset images captured similar situations atm comparatively low background clutter images enables network demonstrate high accuracy feature extraction classification different disguises\n",
            "output sentence:  introduce novel impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators impersonators\n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  misspecified settings posterior distribution bayesian statistics may lead inconsistent estimates fix issue suggested replace likelihood pseudo likelihood exponential loss function enjoying suitable robustness properties paper build pseudo likelihood based maximum mean discrepancy defined via embedding probability distributions reproducing kernel hilbert space show mmd bayes posterior consistent robust model misspecification posterior obtained way might intractable also prove reasonable variational approximations posterior enjoy properties provide details stochastic gradient algorithm compute variational approximations numerical simulations indeed suggest estimator robust misspecification ones based likelihood\n",
            "output sentence:  propose memory memory tasks networks \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  introduce simple efficient algorithms computing minhash probability distribution suitable sparse dense data equivalent running times state art cases collision probability algorithms new measure similarity positive vectors investigate detail describe sense collision probability optimal locality sensitive hash based sampling argue similarity measure useful probability distributions similarity pursued algorithms weighted minhash natural generalization jaccard index\n",
            "output sentence:  minimum set \n",
            "\n",
            "{'rouge-1': {'r': 0.016666666666666666, 'p': 0.3333333333333333, 'f': 0.03174603083900229}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.016666666666666666, 'p': 0.3333333333333333, 'f': 0.03174603083900229}}\n",
            "pair:  deep neural networks recently demonstrated vulnerable backdoor attacks specifically altering small set training examples adversary able install backdoor used inference fully control model behavior attack powerful crucially relies adversary able introduce arbitrary often clearly mislabeled inputs training set thus detected even fairly rudimentary data filtering paper introduce new approach executing backdoor attacks utilizing adversarial examples gan generated data key feature resulting poisoned inputs appear consistent label thus seem benign even upon human inspection\n",
            "output sentence:  propose new backdoor \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  present new approach defining sequence loss function train summarizer using secondary encoder decoder loss function alleviating shortcoming word level training sequence outputs technique based intuition summary good one contain essential information original article therefore good input sequence lieu original summary generated present experimental results apply additional loss function general abstractive summarizer news summarization dataset result improvement rouge metric especially large improvement human evaluations suggesting enhanced performance competitive specialized state art models\n",
            "output sentence:  propose generative used models \n",
            "\n",
            "{'rouge-1': {'r': 0.021052631578947368, 'p': 0.6666666666666666, 'f': 0.04081632593710954}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.021052631578947368, 'p': 0.6666666666666666, 'f': 0.04081632593710954}}\n",
            "pair:  exploration sparse reward reinforcement learning remains open challenge many state art methods use intrinsic motivation complement sparse extrinsic reward signal giving agent opportunities receive feedback exploration commonly signals added bonus rewards results mixture policy neither conducts exploration task fulfillment resolutely paper instead learn separate intrinsic extrinsic task policies schedule different drives accelerate exploration stabilize learning moreover introduce new type intrinsic reward denoted successor feature control sfc general task specific takes account statistics complete trajectories thus differs previous methods use local information evaluate intrinsic motivation evaluate proposed scheduled intrinsic drive sid agent using three different environments pure visual inputs vizdoom deepmind lab deepmind control suite results show substantially improved exploration efficiency sfc hierarchical usage intrinsic drives video experimental results found https gofile io hpewtd\n",
            "output sentence:  reward intrinsic signal \n",
            "\n",
            "{'rouge-1': {'r': 0.009433962264150943, 'p': 1.0, 'f': 0.01869158859987772}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.009433962264150943, 'p': 1.0, 'f': 0.01869158859987772}}\n",
            "pair:  community detection graphs solved via spectral methods posterior inference certain probabilistic graphical models focusing random graph families stochastic block model recent research unified approaches identified statistical computational detection thresholds terms signal noise ratio recasting community detection node wise classification problem graphs also study learning perspective present novel family graph neural networks gnns solving community detection problems supervised learning setting show data driven manner without access underlying generative models match even surpass performance belief propagation algorithm binary multiclass stochastic block models believed reach computational threshold cases particular propose augment gnns non backtracking operator defined line graph edge adjacencies gnns achieved good performance real world datasets addition perform first analysis optimization landscape using linear gnns solve community detection problems demonstrating certain simplifications assumptions loss value local minimum close loss value global minimum minima\n",
            "output sentence:  propose train \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep neural networks provide state art performance image denoising goal recover near noise free image noisy image underlying principle neural networks trained large datasets empirically shown able generate natural images well low dimensional latent representation image given generator network prior noisy image denoised finding closest image range prior however little theory justify success let alone predict denoising performance function networks parameters paper consider problem denoising image additive gaussian noise assuming image well described deep neural network relu activations functions mapping dimensional latent space dimensional image state analyze simple gradient descent like iterative algorithm minimizes non convex loss function provably removes fraction noise energy also demonstrate numerical experiments denoising performance indeed achieved generative priors learned data\n",
            "output sentence:  analyzing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing minimizing\n",
            "\n",
            "{'rouge-1': {'r': 0.010869565217391304, 'p': 0.3333333333333333, 'f': 0.021052630967313038}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.010869565217391304, 'p': 0.3333333333333333, 'f': 0.021052630967313038}}\n",
            "pair:  core aspect human intelligence ability learn new tasks quickly switch flexibly describe modular continual reinforcement learning paradigm inspired abilities first introduce visual interaction environment allows many types tasks unified single framework describe reward map prediction scheme learns new tasks robustly large state action spaces required environment investigate properties module architecture influence efficiency task learning showing module motif incorporating specific design principles early bottlenecks low order polynomial nonlinearities symmetry significantly outperforms standard neural network motifs needing fewer training examples fewer neurons achieve high levels performance finally present meta controller architecture task switching based dynamic neural voting scheme allows new modules use information learned previously seen tasks substantially improve learning efficiency\n",
            "output sentence:  propose continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual continual \n",
            "\n",
            "{'rouge-1': {'r': 0.014084507042253521, 'p': 0.5, 'f': 0.027397259741039605}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014084507042253521, 'p': 0.5, 'f': 0.027397259741039605}}\n",
            "pair:  domain adaptation methods consider problem transferring knowledge target domain single source dataset however practical applications typically access multiple sources paper propose first approach multi source domain adaptation msda based generative adversarial networks method inspired observation appearance given image depends three factors domain style characterized terms low level features variations content reason propose project image features onto space dependence content kept project invariant representation onto pixel space using target domain style way new labeled images generated used train final target classifier test approach using common msda benchmarks showing outperforms state art methods\n",
            "output sentence:  propose rl train \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  investigate learned dynamical landscape recurrent neural network solving simple task requiring interaction two memory mechanisms long short term results show long term memory implemented asymptotic attractors sequential recall additionally implemented oscillatory dynamics transverse subspace basins attraction stable steady states based observations propose different types memory mechanisms coexist work together single neural network discuss possible applications fields artificial intelligence neuroscience\n",
            "output sentence:  introduce proposes memory \n",
            "\n",
            "{'rouge-1': {'r': 0.0136986301369863, 'p': 0.3333333333333333, 'f': 0.026315788715373982}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0136986301369863, 'p': 0.3333333333333333, 'f': 0.026315788715373982}}\n",
            "pair:  semantic structure extraction spreadsheets includes detecting table regions recognizing structural components classifying cell types automatic semantic structure extraction key automatic data transformation various table structures canonical schema enable data analysis knowledge discovery however challenged diverse table structures spatial correlated semantics cell grids learn spatial correlations capture semantics spreadsheets developed novel learning based framework spreadsheet semantic structure extraction first propose multi task framework learns table region structural components cell types jointly second leverage advances recent language model capture semantics cell value third build large human labeled dataset broad coverage table structures evaluation shows proposed multi task framework highly effective outperforms results training task separately\n",
            "output sentence:  propose new transfer \n",
            "\n",
            "{'rouge-1': {'r': 0.0196078431372549, 'p': 0.25, 'f': 0.036363635014876085}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0196078431372549, 'p': 0.25, 'f': 0.036363635014876085}}\n",
            "pair:  paper introduces framework solving combinatorial optimization problems learning input output examples optimization problems introduce new memory augmented neural model memory resettable information stored memory processing input example kept next seen examples used deep reinforcement learning train memory controller agent store useful memories model able outperform hand crafted solver binary linear programming binary lp proposed model tested different binary lp instances large number variables variables constrains constrains\n",
            "output sentence:  propose memory search memory search memory search memory search memory search \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  present method train self binarizing neural networks networks evolve weights activations training become binary obtain similar binary networks existing methods rely sign activation function function however gradients non zero values makes standard backpropagation impossible circumvent difficulty training network relying sign activation function methods alternate floating point binary representations network training sub optimal inefficient approach binarization task training unique representation involving smooth activation function iteratively sharpened training becomes binary representation equivalent sign activation function additionally introduce new technique perform binary batch normalization simplifies conventional batch normalization transforming simple comparison operation unlike existing methods forced retain conventional floating point based batch normalization binary networks apart displaying advantages lower memory computation compared conventional floating point binary networks also show higher classification accuracy existing state art methods multiple benchmark datasets\n",
            "output sentence:  use binarize distribution \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  learning tasks source code formal languages considered recently work tried transfer natural language methods capitalize unique opportunities offered code known syntax example long range dependencies induced using variable function distant locations often considered propose use graphs represent syntactic semantic structure code use graph based deep learning methods learn reason program structures work present construct graphs source code scale gated graph neural networks training large graphs evaluate method two tasks varnaming network attempts predict name variable given usage varmisuse network learns reason selecting correct variable used given program location comparison methods use less structured program representations shows advantages modeling known structure suggests models learn infer meaningful names solve varmisuse task many cases additionally testing showed varmisuse identifies number bugs mature open source projects\n",
            "output sentence:  programs structure \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deployment neural networks mobile devices necessity transmitting neural networks limited expensive channels file size trained model identified bottleneck propose codec compression neural networks based transform coding convolutional dense layers clustering biases normalizations codec achieve average compression factors accuracy compressed networks image classification decreases respectively\n",
            "output sentence:  provide policy policy policy policy policy policy \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  graph neural networks gnns received tremendous attention recently due power handling graph data different downstream tasks across different application domains key gnn graph convolutional filters recently various kinds filters designed however still lacks depth analysis whether exists best filter perform best graph data graph properties influence optimal choice graph filter design appropriate filter adaptive graph data paper focus addressing three questions first propose novel assessment tool evaluate effectiveness graph convolutional filters given graph using assessment tool find single filter silver bullet perform best possible graphs addition different graph structure properties influence optimal graph convolutional filter design choice based findings develop adaptive filter graph neural network afgnn simple powerful model adaptively learn task specific filter given graph leverages graph filter assessment regularization learns combine set base filters experiments synthetic real world benchmark datasets demonstrate proposed model indeed learn appropriate filter perform well graph tasks\n",
            "output sentence:  train analyze transfer transfer transfer transfer \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  knowledge graph embedding kge attracted attention recent years kge models learn time unaware triples however inclusion temporal information beside triples would improve performance kge model regard propose litse temporal kge model incorporates time information entity relation representations using linear time series decomposition moreover considering temporal uncertainty evolution entity relation representations time map representations temporal kgs space multi dimensional gaussian distributions mean entity relation embedding time step shows current expected position whereas covariance stationary time represents temporal uncertainty experiments show litse achieves state art link prediction temporal kgs also ability predict occurrence time facts missing time annotations well existence future events best knowledge model capable perform tasks\n",
            "output sentence:  learned method \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  random matrix theory rmt applied analyze weight matrices deep neural networks dnns including production quality pre trained models alexnet inception smaller models trained scratch lenet miniature alexnet empirical theoretical results clearly indicate empirical spectral density esd dnn layer matrices displays signatures traditionally regularized statistical models even absence exogenously specifying traditional forms regularization dropout weight norm constraints building recent results rmt notably extension universality classes heavy tailed matrices develop theory identify phases training corresponding increasing amounts implicit self regularization smaller older dnns implicit self regularization like traditional tikhonov regularization size scale separating signal noise state art dnns however identify novel form heavy tailed self regularization similar self organization seen statistical physics disordered systems implicit self regularization depend strongly many knobs training process exploiting generalization gap phenomena demonstrate cause small model exhibit phases training simply changing batch size\n",
            "output sentence:  see abstract abstract abstract abstract rl \n",
            "\n",
            "{'rouge-1': {'r': 0.014285714285714285, 'p': 0.3333333333333333, 'f': 0.02739725948583226}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014285714285714285, 'p': 0.3333333333333333, 'f': 0.02739725948583226}}\n",
            "pair:  open question deep learning community neural networks trained gradient descent generalize well real datasets even though capable fitting random data propose approach answering question based hypothesis dynamics gradient descent call coherent gradients gradients similar examples similar overall gradient stronger certain directions reinforce thus changes network parameters training biased towards locally simultaneously benefit many examples similarity exists support hypothesis heuristic arguments perturbative experiments outline explain several common empirical observations deep learning furthermore analysis descriptive prescriptive suggests natural modification gradient descent greatly reduce overfitting\n",
            "output sentence:  unsupervised hypothesis augment per \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  adversarial attacks convolutional neural networks cnn gained significant attention active research efforts defense mechanisms stochastic input transformation methods proposed idea recover image adversarial attack random transformation take majority vote consensus among random samples however transformation improves accuracy adversarial images expense accuracy clean images intuitive accuracy clean images would deteriorate exact mechanism occurs unclear paper study distribution softmax induced stochastic transformations observe random transformations clean images although mass softmax distribution could shift wrong class resulting distribution softmax could used correct prediction furthermore adversarial counterparts image transformation resulting shapes distribution softmax similar distributions clean images observations propose method improve existing transformation based defenses train separate lightweight distribution classifier recognize distinct features distributions softmax outputs transformed images empirical studies show distribution classifier training distributions obtained clean images outperforms majority voting clean adversarial images method generic integrated existing transformation based defenses\n",
            "output sentence:  enhance existing \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep networks realize complex mappings often understood locally linear behavior around points interest example use derivative mapping respect inputs sensitivity analysis explain obtain coordinate relevance prediction one key challenge derivatives inherently unstable paper propose new learning problem encourage deep networks stable derivatives larger regions problem challenging general focus networks piecewise linear activation functions algorithm consists inference step identifies region around point linear approximation provably stable optimization step expand regions propose novel relaxation scale algorithm realistic models illustrate method residual recurrent networks image sequence datasets\n",
            "output sentence:  establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish establish\n",
            "\n",
            "{'rouge-1': {'r': 0.010309278350515464, 'p': 0.16666666666666666, 'f': 0.019417474630973767}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.010309278350515464, 'p': 0.16666666666666666, 'f': 0.019417474630973767}}\n",
            "pair:  sequence prediction models learned example sequences variety training algorithms maximum likelihood learning simple efficient yet suffer compounding error test time reinforcement learning policy gradient addresses issue prohibitively poor exploration efficiency rich set algorithms data noising raml softmax policy gradient also developed different perspectives paper present formalism entropy regularized policy optimization show apparently distinct algorithms including mle reformulated special instances formulation difference characterized reward function two weight hyperparameters unifying interpretation enables us systematically compare algorithms side side gain new insights trade offs algorithm design new perspective also leads improved approach dynamically interpolates among family algorithms learns model scheduled way experiments machine translation text summarization game imitation learning demonstrate superiority proposed approach\n",
            "output sentence:  propose generation algorithm generation generation algorithm recurrent algorithm generation tasks generation \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  convergence rate final performance common deep learning models significantly benefited recently proposed heuristics learning rate schedules knowledge distillation skip connections normalization layers absence theoretical underpinnings controlled experiments aimed explaining efficacy strategies aid understanding deep learning landscapes training dynamics existing approaches empirical analysis rely tools linear interpolation visualizations dimensionality reduction limitations instead revisit empirical analysis heuristics lens recently proposed methods loss surface representation analysis viz mode connectivity canonical correlation analysis cca hypothesize reasons heuristics succeed particular explore knowledge distillation learning rate heuristics cosine restarts warmup using mode connectivity cca empirical analysis suggests reasons often quoted success cosine annealing evidenced practice effect learning rate warmup prevent deeper layers creating training instability latent knowledge shared teacher primarily disbursed deeper layers\n",
            "output sentence:  investigate svcca svcca \n",
            "\n",
            "{'rouge-1': {'r': 0.02564102564102564, 'p': 0.6666666666666666, 'f': 0.04938271533607682}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02564102564102564, 'p': 0.6666666666666666, 'f': 0.04938271533607682}}\n",
            "pair:  deep generative models advanced state art semi supervised classification however capacity deriving useful discriminative features completely unsupervised fashion classification difficult real world data sets adequate manifold separation required adequately explored methods rely defining pipeline deriving features via generative modeling applying clustering algorithms separating modeling discriminative processes propose deep hierarchical generative model uses mixture discrete continuous distributions learn effectively separate different data manifolds trainable end end show specifying form discrete variable distribution imposing specific structure model latent representations test model discriminative performance task cll diagnosis baselines field computational fc well variational autoencoder literature\n",
            "output sentence:  unsupervised classification unsupervised classification via \n",
            "\n",
            "{'rouge-1': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}}\n",
            "pair:  success reinforcement learning real world limited instrumented laboratory scenarios often requiring arduous human supervision enable continuous learning work discuss required elements robotic system continually autonomously improve data collected real world propose particular instantiation system subsequently investigate number challenges learning without instrumentation including lack episodic resets state estimation hand engineered rewards propose simple scalable solutions challenges demonstrate efficacy proposed system dexterous robotic manipulation tasks simulation real world also provide insightful analysis ablation study challenges associated learning paradigm\n",
            "output sentence:  propose search robotic based search tasks search tasks search tasks search tasks robotic tasks \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  learning framed trying encode mutual information input output discarding information input since distribution input output unknown also true mutual information quantify difficult learn task calculate observed mutual information score dividing estimated mutual information entropy input substantiate score analytically showing estimated mutual information error increases entropy data intriguingly depending data represented observed entropy mutual information vary wildly needs match data represented model encodes experimentally analyze image based input data representations demonstrate performance outcomes extensive network architectures searches well aligned calculated score therefore ensure better learning outcomes representations may need tailored task model align implicit distribution model\n",
            "output sentence:  take networks generating \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  data augmentation da fundamental overfitting large convolutional neural networks especially limited training dataset images da usually based heuristic transformations like geometric color transformations instead using predefined transformations work learns data augmentation directly training data learning transform images encoder decoder architecture combined spatial transformer network transformed images still belong class new complex samples classifier experiments show approach better previous generative data augmentation methods comparable predefined transformation methods training image classifier\n",
            "output sentence:  propose scaling search \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  counterfactual regret minimization cfr successful algorithm finding approximate nash equilibria imperfect information games however cfr reliance full game tree traversals limits scalability generality therefore game state action space often abstracted simplified cfr resulting strategy mapped back full game requires extensive expert knowledge practical many games outside poker often converges highly exploitable policies recently proposed method deep cfr applies deep learning directly cfr allowing agent intrinsically abstract generalize state space samples without requiring expert knowledge paper introduce single deep cfr sd cfr variant deep cfr lower overall approximation error avoiding training average strategy network show sd cfr attractive theoretical perspective empirically outperforms deep cfr respect exploitability one one play poker\n",
            "output sentence:  propose gans tasks better \n",
            "\n",
            "{'rouge-1': {'r': 0.03571428571428571, 'p': 0.5, 'f': 0.06666666542222224}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.03571428571428571, 'p': 0.5, 'f': 0.06666666542222224}}\n",
            "pair:  momentum based methods conjunction stochastic gradient descent widely used training machine learning models little theoretical understanding generalization error methods practice momentum parameter often chosen heuristic fashion little theoretical guidance work use framework algorithmic stability provide upper bound generalization error class strongly convex loss functions mild technical assumptions bound decays zero inversely size training set increases momentum parameter increased also develop upper bound expected true risk terms number training steps size training set momentum parameter\n",
            "output sentence:  stochastic momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum momentum networks stochastic \n",
            "\n",
            "{'rouge-1': {'r': 0.0136986301369863, 'p': 0.25, 'f': 0.025974024989036972}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0136986301369863, 'p': 0.25, 'f': 0.025974024989036972}}\n",
            "pair:  present information theoretic framework understanding trade offs unsupervised learning deep latent variables models using variational inference framework emphasizes need consider latent variable models along two dimensions ability reconstruct inputs distortion communication cost rate derive optimal frontier generative models two dimensional rate distortion plane show standard evidence lower bound objective insufficient select points along frontier however performing targeted optimization learn generative models different rates able learn many models achieve similar generative performance make vastly different trade offs terms usage latent variable experiments mnist omniglot variety architectures show framework sheds light many recent proposed extensions variational autoencoder family\n",
            "output sentence:  paper proposes theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic theoretic\n",
            "\n",
            "{'rouge-1': {'r': 0.019230769230769232, 'p': 0.25, 'f': 0.03571428438775515}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.019230769230769232, 'p': 0.25, 'f': 0.03571428438775515}}\n",
            "pair:  analyze joint probability distribution lengths vectors hidden variables different layers fully connected deep network weights biases chosen randomly according gaussian distributions input binary valued show activation function satisfies minimal set assumptions satisfied activation functions know used practice width network gets large length process converges probability length map determined simple function variances random weights biases activation function also show convergence may fail activation functions violate assumptions\n",
            "output sentence:  prove functions satisfying functions satisfying functions satisfying functions \n",
            "\n",
            "{'rouge-1': {'r': 0.038461538461538464, 'p': 0.75, 'f': 0.07317073077929805}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02564102564102564, 'p': 0.5, 'f': 0.04878048687685902}}\n",
            "pair:  representation learning one foundations deep learning allowed important improvements several machine learning tasks neural machine translation question answering speech recognition recent works proposed new methods learning representations nodes edges graphs several methods based skipgram algorithm usually process large number multi hop neighbors order produce context node representations learned paper propose effective also efficient method generating node embeddings graphs employs restricted number permutations immediate neighborhood node context generate representation thus ego centric representations present thorough evaluation showing method outperforms state art methods six different datasets related problems link prediction node classification one three orders magnitude faster baselines generating node embeddings large graphs\n",
            "output sentence:  faster generate generating generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate generate\n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  propose evaluate new techniques compressing speeding dense matrix multiplications found fully connected recurrent layers neural networks embedded large vocabulary continuous speech recognition lvcsr compression introduce study trace norm regularization technique training low rank factored versions matrix multiplications compared standard low rank training show method leads good accuracy versus number parameter trade offs used speed training large models speedup enable faster inference arm processors new open sourced kernels optimized small batch sizes resulting speed ups widely used gemmlowp library beyond lvcsr expect techniques kernels generally applicable embedded neural networks large fully connected recurrent layers\n",
            "output sentence:  paper state method \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  paper study implicit regularization gradient descent algorithm homogeneous neural networks including fully connected convolutional neural networks relu leakyrelu activations particular study gradient descent gradient flow gradient descent infinitesimal step size optimizing logistic loss cross entropy loss homogeneous model possibly non smooth show training loss decreases certain threshold define smoothed version normalized margin increases time also formulate natural constrained optimization problem related margin maximization prove normalized margin smoothed version converge objective value kkt point optimization problem results generalize previous results logistic regression one layer multi layer linear networks provide quantitative convergence results weaker assumptions previous results homogeneous smooth neural networks conduct several experiments justify theoretical finding mnist cifar datasets finally margin closely related robustness discuss potential benefits training longer improving robustness model\n",
            "output sentence:  propose solve solve solve solve solve solve solve solve solve \n",
            "\n",
            "{'rouge-1': {'r': 0.02, 'p': 0.5, 'f': 0.0384615377218935}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02, 'p': 0.5, 'f': 0.0384615377218935}}\n",
            "pair:  generative neural networks map standard possibly distribution complex high dimensional distribution represents real world data set however determinate input distribution well specific architecture neural networks may impose limitations capturing diversity high dimensional target space resolve difficulty propose training framework greedily produce series generative adversarial networks incrementally capture diversity target space show theoretically empirically training algorithm converges theoretically optimal distribution projection real distribution onto convex hull network distribution space\n",
            "output sentence:  propose rl train \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  despite empirical success theoretical underpinnings stability convergence acceleration properties batch normalization bn remain elusive paper attack problem modelling approach perform thorough theoretical analysis bn applied simplified model ordinary least squares ols discover gradient descent ols bn interesting properties including scaling law convergence arbitrary learning rates weights asymptotic acceleration effects well insensitivity choice learning rates demonstrate numerically findings specific ols problem hold qualitatively complex supervised learning problems points new direction towards uncovering mathematical principles underlies batch normalization\n",
            "output sentence:  mathematically analyze general \n",
            "\n",
            "{'rouge-1': {'r': 0.023255813953488372, 'p': 0.5, 'f': 0.044444443595061736}, 'rouge-2': {'r': 0.010101010101010102, 'p': 0.3333333333333333, 'f': 0.019607842566320664}, 'rouge-l': {'r': 0.023255813953488372, 'p': 0.5, 'f': 0.044444443595061736}}\n",
            "pair:  goal compressed sensing learn structured signal limited number noisy linear measurements approx ax traditional compressed sensing structure represented sparsity known basis inspired success deep learning modeling images recent work starting cite bdjp instead considered structure come generative model present two results establishing difficulty latter task showing existing bounds tight first provide lower bound matching cite bdjp upper bound compressed sensing lipschitz generative models particular exists function requires roughly omega log linear measurements sparse recovery possible holds even relaxed goal emph nonuniform recovery second show generative models generalize sparsity representation structure particular construct relu based neural network layers kn activations per layer range contains sparse vectors\n",
            "output sentence:  lower bound plan search \n",
            "\n",
            "{'rouge-1': {'r': 0.014705882352941176, 'p': 0.5, 'f': 0.02857142801632654}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014705882352941176, 'p': 0.5, 'f': 0.02857142801632654}}\n",
            "pair:  human annotation syntactic parsing expensive large resources available fraction languages question ask whether one leverage abundant unlabeled texts improve syntactic parsers beyond using texts obtain generalisable lexical features beyond word embeddings end propose novel latent variable generative model semi supervised syntactic dependency parsing exact inference intractable introduce differentiable relaxation obtain approximate samples compute gradients respect parser parameters method differentiable perturb parse relies differentiable dynamic programming stochastically perturbed edge scores demonstrate effectiveness approach experiments english french swedish\n",
            "output sentence:  differentiable proposes \n",
            "\n",
            "{'rouge-1': {'r': 0.014705882352941176, 'p': 0.25, 'f': 0.0277777767283951}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.014705882352941176, 'p': 0.25, 'f': 0.0277777767283951}}\n",
            "pair:  generative adversarial networks gans learn map samples noise distribution chosen data distribution recent work demonstrated gans consequently sensitive limited shape noise distribution example single generator struggles map continuous noise uniform distribution discontinuous output separate gaussians complex output intersecting parabolas address problem learning generate multiple models generator output actually combination several distinct networks contribute novel formulation multi generator models learn prior generators conditioned noise parameterized neural network thus network learns optimal rate sample generator also optimally shapes noise received generator resulting noise prior gan npgan achieves expressivity flexibility surpasses single generator models previous multi generator models\n",
            "output sentence:  propose generator architecture generator generator generator generator architecture generator generator generator generator generator generator generator generator generator generator architecture generator \n",
            "\n",
            "{'rouge-1': {'r': 0.01818181818181818, 'p': 0.5, 'f': 0.0350877186211142}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.01818181818181818, 'p': 0.5, 'f': 0.0350877186211142}}\n",
            "pair:  unsupervised domain adaptive object detection aims learn robust detector domain shift circumstance training source domain label rich bounding box annotations testing target domain label agnostic feature distributions training testing domains dissimilar even totally different paper propose gradient detach based stacked complementary losses scl method uses detection objective cross entropy smooth regression primary objective cuts several auxiliary losses different network stages utilize information complement data target images effective adapting model parameters source target domains gradient detach operation applied detection context sub networks training force networks learn discriminative representations argue conventional training primary objective mainly leverages information source domain maximizing likelihood ignores complement data shallow layers networks leads insufficient integration within different domains thus proposed method syncretic adaptation learning process conduct comprehensive experiments seven datasets results demonstrate method performs favorably better state art methods large margin instance cityscapes foggycityscapes achieve map outperforming previous art strong weak\n",
            "output sentence:  propose new detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach detach \n",
            "\n",
            "{'rouge-1': {'r': 0.018518518518518517, 'p': 0.5, 'f': 0.03571428502551022}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.018518518518518517, 'p': 0.5, 'f': 0.03571428502551022}}\n",
            "pair:  study problem safe adaptation given model trained variety past experiences task model learn perform task new situation avoiding catastrophic failure problem setting occurs frequently real world reinforcement learning scenarios vehicle adapting drive new city robotic drone adapting policy trained simulation learning without catastrophic failures exceptionally difficult prior experience allow us learn models make much easier models might directly transfer new settings enable cautious adaptation substantially safer na adaptation well learning scratch building intuition propose risk averse domain adaptation rada rada works two steps first trains probabilistic model based rl agents population source domains gain experience capture epistemic uncertainty environment dynamics dropped new environment employs pessimistic exploration policy selecting actions best worst case performance forecasted probabilistic model show simple maximin policy accelerates domain adaptation safety critical driving environment varying vehicle sizes compare approach approaches adapting new environments including meta reinforcement learning\n",
            "output sentence:  propose adaptation method transfer \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  stochastic gradient descent sgd dominant optimization method training deep neural networks due many desirable properties one remarkable least understood quality sgd generalizes relatively well unseen data even neural network millions parameters hypothesize certain cases desirable relax intrinsic generalization properties introduce extension sgd called deep gradient boosting dgb key idea dgb back propagated gradients inferred using chain rule viewed pseudo residual targets gradient boosting problem thus layer neural network weight update calculated solving corresponding boosting problem using linear base learner resulting weight update formula also viewed normalization procedure data arrives layer forward pass implemented separate input normalization layer inn new architecture shows improved performance image recognition tasks compared architecture without normalization layers opposed batch normalization bn inn learnable parameters however matches performance cifar imagenet classification tasks\n",
            "output sentence:  use proposes knowledgeable \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  automatic classification objects one important tasks engineering data mining applications although using complex advanced classifiers help improve accuracy classification systems done analyzing data sets features particular problem feature combination one improve quality features paper structure similar feed forward neural network ffnn used generate optimized linear non linear combination features classification genetic algorithm ga applied update weights biases since nature data sets features impact effectiveness combination classification system linear non linear activation functions transfer function used achieve reliable system experiments several uci data sets using minimum distance classifier simple classifier indicate proposed linear non linear intelligent ffnn based feature combination present reliable promising results using feature combination method need use powerful complex classifier anymore\n",
            "output sentence:  propose enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching enriching \n",
            "\n",
            "{'rouge-1': {'r': 0.011111111111111112, 'p': 0.5, 'f': 0.021739130009451806}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.011111111111111112, 'p': 0.5, 'f': 0.021739130009451806}}\n",
            "pair:  natural language processing nlp models often require massive number parameters word embeddings resulting large storage memory footprint deploying neural nlp models mobile devices requires compressing word embeddings without significant sacrifices performance purpose propose construct embeddings basis vectors word composition basis vectors determined hash code maximize compression rate adopt multi codebook quantization approach instead binary coding scheme code composed multiple discrete numbers value component limited fixed range propose directly learn discrete codes end end neural network applying gumbel softmax trick experiments show compression rate achieves sentiment analysis task machine translation tasks without performance loss tasks proposed method improve model performance slightly lowering compression rate compared approaches character level segmentation proposed method language independent require modifications network architecture\n",
            "output sentence:  compressing compressing \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  contextualized word representations elmo bert become de facto starting point incorporating pretrained representations downstream nlp tasks settings contextual representations largely made obsolete static embedding predecessors word vec glove however static embeddings advantages straightforward understand faster use additionally embedding analysis methods static embeddings far diverse mature available dynamic counterparts work introduce simple methods generating static lookup table embeddings existing pretrained contextual representations demonstrate outperform word vec glove embeddings variety word similarity word relatedness tasks results also reveal insights may useful subsequent downstream tasks using embeddings original contextual models demonstrate increased potential analysis applying existing approaches estimating social bias word embeddings analysis constitutes comprehensive study social bias contextual word representations via proxy distilled embeddings reveals number inconsistencies current techniques quantifying social bias word embeddings publicly release code distilled word embeddings support reproducible research broader nlp community\n",
            "output sentence:  propose proposes two models \n",
            "\n",
            "{'rouge-1': {'r': 0.028985507246376812, 'p': 0.5, 'f': 0.054794519512103596}, 'rouge-2': {'r': 0.010869565217391304, 'p': 0.2, 'f': 0.02061855572324375}, 'rouge-l': {'r': 0.028985507246376812, 'p': 0.5, 'f': 0.054794519512103596}}\n",
            "pair:  approached group healthcare providers involved care chronic patients looking potential technologies facilitate process reviewing patient generated data clinical visits aiming understanding healthcare providers attitudes towards reviewing patient generated data conducted focus group mixed group healthcare providers next gain patients perspectives interviewed eight chronic patients collected sample data designed series visualizations representing patient data collected last sought feedback visualization designs healthcare providers requested exploration found four factors shaping patient generated data data context patient motivation patient time commitment patient support circle informed results studies discussed importance designing patient generated visualizations individuals considering patient healthcare provider rather designing purpose generalization provided guidelines designing future patient generated data visualizations\n",
            "output sentence:  explored visualization visualization visualization visualization visualization designs visualization visualization visualization designs visualization \n",
            "\n",
            "{'rouge-1': {'r': 0.0196078431372549, 'p': 0.3333333333333333, 'f': 0.03703703598765435}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0196078431372549, 'p': 0.3333333333333333, 'f': 0.03703703598765435}}\n",
            "pair:  paper presents method explain knowledge encoded convolutional neural network cnn quantitatively semantically analyze specific rationale prediction made cnn presents one key issues understanding neural networks also significant practical values certain applications study propose distill knowledge cnn explainable additive model use explainable model provide quantitative explanation cnn prediction analyze typical bias interpreting problem explainable model develop prior losses guide learning explainable additive model experimental results demonstrated effectiveness method\n",
            "output sentence:  paper proposes novel new \n",
            "\n",
            "{'rouge-1': {'r': 0.021052631578947368, 'p': 0.4, 'f': 0.03999999905000002}, 'rouge-2': {'r': 0.008064516129032258, 'p': 0.2, 'f': 0.015503875223844757}, 'rouge-l': {'r': 0.021052631578947368, 'p': 0.4, 'f': 0.03999999905000002}}\n",
            "pair:  weight pruning introduced efficient model compression technique even though pruning removes significant amount weights network memory requirement reduction limited since conventional sparse matrix formats require significant amount memory store index related information moreover computations associated sparse matrix formats slow sequential sparse matrix decoding process utilize highly parallel computing systems efficiently attempt compress index information keeping decoding process parallelizable viterbi based pruning suggested decoding non zero weights however still sequential viterbi based pruning paper propose new sparse matrix format order enable highly parallel decoding process entire sparse matrix proposed sparse matrix constructed combining pruning weight quantization latest rnn models ptb wikitext corpus lstm parameter storage requirement compressed using proposed sparse matrix format compared baseline model compressed weight indices reconstructed dense matrix fast using viterbi encoders simulation results show proposed scheme feed parameters processing elements faster case dense matrix values directly come dram\n",
            "output sentence:  propose new tasks task could could could could could could could could could could \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  although word analogy problems become standard tool evaluating word vectors little known word vectors good solving problems paper attempt understanding subject developing simple highly accurate generative approach solve word analogy problem case terms involved problem nouns results demonstrate ambiguities associated learning relationship word pair role training dataset determining relationship gets highlighted furthermore results show ability model accurately solve word analogy problem may indicative model ability learn relationship word pair way human\n",
            "output sentence:  propose new solve \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  knowledge distillation kd common method transferring knowledge learned one machine learning model teacher another model student typically teacher greater capacity parameters higher bit widths knowledge existing methods overlook fact although student absorbs extra knowledge teacher models share input data data medium teacher knowledge demonstrated due difference model capacities student may benefit fully data points teacher trained hand human teacher may demonstrate piece knowledge individualized examples adapted particular student instance terms cultural background interests inspired behavior design data augmentation agents distinct roles facilitate knowledge distillation data augmentation agents generate distinct training data teacher student respectively focus specifically kd teacher network greater precision bit width student network find empirically specially tailored data points enable teacher knowledge demonstrated effectively student compare approach existing kd methods training popular neural architectures demonstrate role wise data augmentation improves effectiveness kd strong prior approaches code reproducing results made publicly available\n",
            "output sentence:  present whether shown inspired \n",
            "\n",
            "{'rouge-1': {'r': 0.010869565217391304, 'p': 0.2, 'f': 0.02061855572324375}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.010869565217391304, 'p': 0.2, 'f': 0.02061855572324375}}\n",
            "pair:  generative adversarial networks gans trained large datasets diverse modes known produce conflated images distinctly belong modes hypothesize problem occurs due interaction two facts datasets large variety likely modes lie separate manifolds generator formulated continuous function input noise derived connected set due output connected set covers modes must portion output connects corresponds undesirable conflated images develop theoretical arguments support intuitions propose novel method break second assumption via learnable discontinuities latent noise space equivalently viewed training several generators thus creating discontinuities function also augment gan formulation classifier predicts noise partition generator produced output images encouraging diversity partition generator experiment mnist celeba stl difficult dataset clearly distinct modes show noise partitions correspond different modes data distribution produce images superior quality\n",
            "output sentence:  propose proposes domain failure failure failure failure failure failure \n",
            "\n",
            "{'rouge-1': {'r': 0.021739130434782608, 'p': 0.3333333333333333, 'f': 0.04081632538109124}, 'rouge-2': {'r': 0.018867924528301886, 'p': 0.25, 'f': 0.03508771799322873}, 'rouge-l': {'r': 0.021739130434782608, 'p': 0.3333333333333333, 'f': 0.04081632538109124}}\n",
            "pair:  neural networks known produce unexpected results inputs far training distribution one approach tackle problem detect samples trained network answer reliably odin recently proposed method distribution detection modify trained network achieves good performance various image classification tasks paper adapt odin sentence classification word tagging tasks show scores produced odin used confidence measure predictions distribution distribution datasets\n",
            "output sentence:  recent recent distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution distribution\n",
            "\n",
            "{'rouge-1': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.047619047619047616, 'p': 0.6, 'f': 0.08823529275519032}}\n",
            "pair:  study problem training machine learning models incrementally using active learning access imperfect noisy oracles specifically consider setting batch active learning multiple samples selected opposed single sample classical settings reduce training overhead approach bridges uniform randomness score based importance sampling clusters selecting batch new samples experiments benchmark image classification datasets mnist svhn cifar shows improvement existing active learning strategies introduce extra denoising layer deep networks make active learning robust label noises show significant improvements\n",
            "output sentence:  address active oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles oracles oracles oracles setting oracles setting oracles setting oracles setting oracles oracles oracles oracles oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles oracles setting oracles oracles oracles oracles oracles oracles oracles oracles oracles oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles oracles oracles oracles oracles oracles oracles setting oracles oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles oracles setting oracles oracles oracles setting oracles setting oracles oracles oracles oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles oracles oracles oracles oracles setting oracles oracles setting oracles oracles setting oracles oracles setting oracles setting oracles oracles setting oracles setting oracles oracles setting oracles oracles oracles oracles oracles oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles setting oracles oracles oracles setting oracles setting oracles setting oracles oracles setting oracles setting oracles oracles setting oracles oracles setting oracles setting oracles setting oracles\n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  common way speed training large convolutional networks add computational units training performed using data parallel synchronous stochastic gradient descent sgd mini batch divided computational units increase number nodes batch size grows however training large batch often results lower model accuracy argue current recipe large batch training linear learning rate scaling warm general enough training may diverge overcome optimization difficulties propose new training algorithm based layer wise adaptive rate scaling lars using lars scaled alexnet resnet batch size\n",
            "output sentence:  unsupervised rl algorithm rl \n",
            "\n",
            "{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}\n",
            "pair:  deep neural networks achieved outstanding performance many real world applications expense huge computational resources densenet one recently proposed neural network architecture achieved state art performance many visual tasks however great redundancy due dense connections internal structure leads high computational costs training dense networks address issue design reinforcement learning framework search efficient densenet architectures layer wise pruning lwp different tasks retaining original advantages densenet feature reuse short paths etc framework agent evaluates importance connection two block layers prunes redundant connections addition novel reward shaping trick introduced make densenet reach better trade accuracy float point operations flops experiments show densenet lwp compact efficient existing alternatives\n",
            "output sentence:  propose precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision precision\n",
            "\n",
            "{'rouge-1': {'r': 0.011627906976744186, 'p': 0.16666666666666666, 'f': 0.021739129215501016}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.011627906976744186, 'p': 0.16666666666666666, 'f': 0.021739129215501016}}\n",
            "pair:  unsupervised semi supervised learning important problems especially challenging complex data like natural images progress problems would accelerate access appropriate generative models pose associated inference tasks inspired success convolutional neural networks cnns supervised prediction images design neural rendering model nrm new hierarchical probabilistic generative model whose inference calculations correspond cnn nrm introduces small set latent variables level model enforces dependencies among latent variables via conjugate prior distribution conjugate prior yields new regularizer learning based paths rendered generative model training cnns rendering path normalization rpn demonstrate regularizer improves generalization theory practice likelihood estimation nrm yields new max min cross entropy training loss suggests new deep network architecture max min network exceeds matches state art semi supervised supervised learning svhn cifar cifar\n",
            "output sentence:  propose optimization networks method space method \n",
            "\n",
            "{'rouge-1': {'r': 0.02631578947368421, 'p': 0.5, 'f': 0.049999999050000014}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.02631578947368421, 'p': 0.5, 'f': 0.049999999050000014}}\n",
            "pair:  employing deep neural networks natural image priors solve inverse problems either requires large amounts data sufficiently train expressive generative models succeed data via untrained neural networks however works considered interpolate high data regimes particular one use availability small amount data even examples one advantage solving inverse problems system performance increase amount data increases well work consider solving linear inverse problems given small number examples images drawn distribution image interest comparing untrained neural networks use data show one pre train neural network given examples improve reconstruction results compressed sensing semantic image recovery problems colorization approach leads improved reconstruction amount available data increases par fully trained generative models requiring less data needed train generative model\n",
            "output sentence:  system untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained tasks untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained untrained\n",
            "\n",
            "{'rouge-1': {'r': 0.015873015873015872, 'p': 0.25, 'f': 0.02985074514591227}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.015873015873015872, 'p': 0.25, 'f': 0.02985074514591227}}\n",
            "pair:  approaches generalized zero shot learning rely cross modal mapping image feature space class embedding space generating artificial image features however learning shared cross modal embedding aligning latent spaces modality specific autoencoders shown promising generalized zero shot learning following direction also take artificial feature generation one step propose model shared latent space image features class embeddings learned aligned variational autoencoders purpose generating latent features train softmax classifier evaluate learned latent features conventional benchmark datasets establish new state art generalized zero shot well shot learning moreover results imagenet various zero shot splits show latent features generalize well large scale settings\n",
            "output sentence:  propose studies domain latent \n",
            "\n",
            "{'rouge-1': {'r': 0.010869565217391304, 'p': 0.5, 'f': 0.02127659532820281}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.010869565217391304, 'p': 0.5, 'f': 0.02127659532820281}}\n",
            "pair:  hypothesize end end neural image captioning systems work seemingly well exploit learn distributional similarity multimodal feature space mapping test image similar training images space generating caption space validate hypothesis focus image side image captioning vary input image representation keep rnn text generation model cnn rnn constant propose sparse bag objects vector interpretable representation investigate distributional similarity hypothesis found image captioning models capable separating structure noisy input representations ii experience virtually significant performance loss high dimensional representation compressed lower dimensional space iii cluster images similar visual linguistic information together iv heavily reliant test sets similar distribution training set repeatedly generate captions matching images retrieving caption joint visual textual space experiments point one fact distributional similarity hypothesis holds conclude regardless image representation image captioning systems seem match images generate captions learned joint image text semantic subspace\n",
            "output sentence:  propose variants \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-123d9fb647b7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mevaluateRandomlyprint_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-44-f8ce969406f9>\u001b[0m in \u001b[0;36mevaluateRandomlyprint_1\u001b[0;34m(encoder, decoder, n)\u001b[0m\n\u001b[1;32m     24\u001b[0m           \u001b[0;31m#print(pair[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m           \u001b[0;31m#print(output_sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m           \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_rogue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-5c726fcd9c1c>\u001b[0m in \u001b[0;36mcalculate_rogue\u001b[0;34m(src_trg, pred_trg)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrogue_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rouge-1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 's' referenced before assignment"
          ]
        }
      ]
    }
  ]
}